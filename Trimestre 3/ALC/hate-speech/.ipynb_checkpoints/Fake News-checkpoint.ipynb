{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import tokenize\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "\n",
    "import re, string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.layers import Embedding, LSTM, Bidirectional\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "true = pd.read_csv('data/fake-and-real-news-dataset/True.csv')\n",
    "fake = pd.read_csv('data/fake-and-real-news-dataset/Fake.csv')\n",
    "\n",
    "true['category'] = 0\n",
    "fake['category'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### TrueNews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "true.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unknown_publishers = []\n",
    "for index,row in enumerate(true.text.values):\n",
    "    if \" -\" not in row[:260]:\n",
    "        unknown_publishers.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "true.iloc[unknown_publishers].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(true.iloc[8970])\n",
    "print(\"\\nText: \" + true.iloc[8970].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Seperating Publication info, from actual text\n",
    "publisher = []\n",
    "tmp_text = []\n",
    "c = 0\n",
    "for index,row in enumerate(true.text.values):\n",
    "    if index in unknown_publishers:\n",
    "        publisher.append(\"Unknown\")\n",
    "        tmp_text.append(row)\n",
    "    else:\n",
    "        \n",
    "        aux = row.split(\" -\", maxsplit=1)\n",
    "        publisher.append(aux[0])\n",
    "        tmp_text.append(aux[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "true[\"text\"] = tmp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8970]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index for index,text in enumerate(true.text.values) if str(text).strip() == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = [index for index,text in enumerate(fake.text.values) if str(text).strip() == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "true = true.drop(897\n",
    "                 0, axis=0) # Un-useful entry -> empty text value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### FakeNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "empty_fake_index = [index for index,text in enumerate(fake.text.values) if str(text).strip() == '']\n",
    "print(\"FakeNews without text:\", len(empty_fake_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fake.iloc[empty_fake_index[:7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Normalize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44897 entries, 0 to 44896\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      44897 non-null  object\n",
      " 1   category  44897 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 701.6+ KB\n"
     ]
    }
   ],
   "source": [
    "true[\"text\"] = true[\"title\"] + \" \" + true[\"text\"]\n",
    "fake[\"text\"] = fake[\"title\"] + \" \" + fake[\"text\"]\n",
    "\n",
    "true = true.drop([\"subject\", \"date\",\"title\"], axis=1)\n",
    "fake = fake.drop([\"subject\", \"date\", \"title\"], axis=1)\n",
    "\n",
    "df = pd.concat([true, fake], ignore_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('Normalized_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Normalized_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Text normalization\n",
    "stop = set(stopwords.words('english') + [\"would\"])\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def normalize_text(text):\n",
    "    \n",
    "    # Join semi-colon separated words\n",
    "    text = re.sub(\"(-)\", \"\", text)\n",
    "    \n",
    "    # Acronyms case sensitive\n",
    "    text = re.sub(\"(US)\", 'united states', text)\n",
    "    text = re.sub(\"(U\\.S\\.)\", 'united states', text)\n",
    "    text = re.sub(\"(N\\.Y\\.)\", 'new york', text)\n",
    "    text = re.sub(\"(U\\.K\\.)\", 'united kingdom', text)\n",
    "    text = re.sub(\"(U\\.N\\.)\", 'united nations', text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove urls and other links\n",
    "    text = re.sub('(www\\.[^\\s]+)', '', text)\n",
    "    text = re.sub('(https?://[^\\s]+)', '', text)\n",
    "    text = re.sub('(bit\\.ly[^\\s]+)', '', text)\n",
    "    text = re.sub('(pic\\.twitter\\.com/[^\\s]+)', '', text)\n",
    "    text = re.sub('(tmsnrt\\.rs[^\\s]+)', '', text)\n",
    "    text = re.sub('(polling\\.reuters\\.com[^\\s]+)', '', text)              \n",
    "    \n",
    "    # Remove non-text relevant content\n",
    "    text = text.replace(\"(video)\", '')\n",
    "    text = text.replace(\"(videos)\", '')    \n",
    "    text = text.replace(\"(tweet)\", '')\n",
    "    text = text.replace(\"(tweets)\", '')    \n",
    "    text = text.replace(\"(image)\", '')\n",
    "    text = text.replace(\"(images)\", '')\n",
    "    text = text.replace(\"(graphic images)\", '')\n",
    "\n",
    "    # Remove everything but lowercase, accounts and whitespaces\n",
    "    text = re.sub('([^a-z@ ]+)', ' ',text)\n",
    "    \n",
    "    # Remove extra white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "\n",
    "    temp = []\n",
    "    for word in text.split():\n",
    "        if word not in stop and len(word) > 1 and '@' not in word:\n",
    "            temp.append(wnl.lemmatize(word))\n",
    "\n",
    "    return \" \".join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['clean_text'] = df.text.apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Text normalization into 100 word texts\n",
    "stop = set(stopwords.words('english') + [\"would\"])\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def normalize_text_100(text, maxlen=100):\n",
    "    # Join semi-colon separated words\n",
    "    text = re.sub(\"(-)\", \"\", text)\n",
    "\n",
    "    # Acronyms case sensitive\n",
    "    text = re.sub(\"(US)\", 'united states', text)\n",
    "    text = re.sub(\"(U\\.S\\.)\", 'united states', text)\n",
    "    text = re.sub(\"(N\\.Y\\.)\", 'new york', text)\n",
    "    text = re.sub(\"(U\\.K\\.)\", 'united kingdom', text)\n",
    "    text = re.sub(\"(U\\.N\\.)\", 'united nations', text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove urls and other links\n",
    "    text = re.sub('(www\\.[^\\s]+)', '', text)\n",
    "    text = re.sub('(https?://[^\\s]+)', '', text)\n",
    "    text = re.sub('(bit\\.ly[^\\s]+)', '', text)\n",
    "    text = re.sub('(pic\\.twitter\\.com/[^\\s]+)', '', text)\n",
    "    text = re.sub('(tmsnrt\\.rs[^\\s]+)', '', text)\n",
    "    text = re.sub('(polling\\.reuters\\.com[^\\s]+)', '', text)              \n",
    "    \n",
    "    # Remove non-text relevant content\n",
    "    text = text.replace(\"(video)\", '')\n",
    "    text = text.replace(\"(videos)\", '')    \n",
    "    text = text.replace(\"(tweet)\", '')\n",
    "    text = text.replace(\"(tweets)\", '')    \n",
    "    text = text.replace(\"(image)\", '')\n",
    "    text = text.replace(\"(images)\", '')\n",
    "    text = text.replace(\"(graphic images)\", '')\n",
    "    \n",
    "    # Remove numbers so (Number). doesn't give problems\n",
    "    text = re.sub(\"[0-9]\", \" \", text)\n",
    "\n",
    "    ############## ANTERIOR LUGAR DE CONFLICTO\n",
    "    \n",
    "    # Divide into sentences\n",
    "    texts = tokenize.sent_tokenize(text)\n",
    "    aux = []\n",
    "    \n",
    "    ############## CONFLICTO\n",
    "    \n",
    "    for subtext in texts:\n",
    "        # Remove everything but lowercase, accounts and whitespaces\n",
    "        subtext = re.sub('([^a-z@ ]+)', ' ',subtext)\n",
    "\n",
    "        # Remove extra white spaces\n",
    "        subtext = re.sub(r'\\s+', ' ', subtext, flags=re.I)\n",
    "\n",
    "        temp = []\n",
    "        for word in subtext.split():\n",
    "            if word not in stop and len(word) > 1 and '@' not in word:\n",
    "                temp.append(wnl.lemmatize(word))\n",
    "\n",
    "        aux.append(\" \".join(temp))\n",
    "    \n",
    "    ############## CONFLICTO\n",
    "    \n",
    "    \n",
    "    # JOIN IN MAX 100 WORDS TEXTS\n",
    "    texts = []\n",
    "    temp = \"\"\n",
    "    currentlen = 0\n",
    "\n",
    "    for t in aux:\n",
    "        newlen = len(t.split())\n",
    "\n",
    "        #print(currentlen, newlen)\n",
    "\n",
    "        if (currentlen+newlen >= maxlen):\n",
    "\n",
    "            # Conservar 0.5 sino no meter\n",
    "            if (maxlen-currentlen)/newlen >= 0.5:\n",
    "                temp = temp + \" \" + t\n",
    "                temp = temp.split()\n",
    "                temp = temp[:maxlen]\n",
    "                temp = \" \".join(temp)        \n",
    "                texts.append(temp.strip())\n",
    "\n",
    "                temp = \"\"\n",
    "                currentlen = 0            \n",
    "\n",
    "            else:            \n",
    "                texts.append(temp.strip())\n",
    "\n",
    "                if len(t.split()) > maxlen:\n",
    "                    texts.append(\" \".join(t.split()[:maxlen]).strip())\n",
    "\n",
    "                    temp = \"\"\n",
    "                    currentlen = 0\n",
    "                else:\n",
    "                    temp = t\n",
    "                    currentlen = len(t.split())\n",
    "        else:\n",
    "            temp = temp + \" \" + t\n",
    "            currentlen = currentlen + newlen\n",
    "\n",
    "    if temp != \"\":\n",
    "        texts.append(temp.strip())\n",
    "\n",
    "    #for t in texts:\n",
    "    #    print(\"\\n\", len(t.split()), t)\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_100 = pd.DataFrame(columns=[\"clean_text\", \"news_id\", \"category\"])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    subtexts = normalize_text_100(row.text)    \n",
    "    for st in subtexts:        \n",
    "        new_row = pd.Series({\"clean_text\": st, \"news_id\": index, \"category\": row.category})\n",
    "        df_100 = df_100.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  20295\n",
      "Text:  32483\n",
      "Text:  67250\n",
      "Text:  86240\n",
      "Text:  88218\n",
      "Text:  90173\n",
      "Text:  91368\n",
      "Text:  91370\n",
      "Text:  91372\n",
      "Text:  92433\n",
      "Text:  96916\n",
      "Text:  106947\n",
      "Text:  109754\n",
      "Text:  111327\n",
      "Text:  114648\n",
      "Text:  114716\n",
      "Text:  120024\n",
      "Text:  120441\n",
      "Text:  121791\n",
      "Text:  123908\n",
      "Text:  124325\n",
      "Text:  125675\n"
     ]
    }
   ],
   "source": [
    "empty_text_indices = []\n",
    "\n",
    "for index, text in enumerate(df_100.clean_text.values):\n",
    "    if text == '': \n",
    "        empty_text_indices.append(index)\n",
    "        \n",
    "for i in empty_text_indices:\n",
    "    print('Text:', df_100.iloc[i].clean_text, i)\n",
    "\n",
    "for i in empty_text_indices:\n",
    "    df_100 = df_100.drop(i, axis=0) # Un-useful entry -> empty text value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_100.to_csv('data/fake-and-real-news-dataset/Processed_news_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux = pd.read_csv('data/fake-and-real-news-dataset/Processed_news_100.csv')\n",
    "print(aux.columns)\n",
    "print(\"Total:\", len(df_100))\n",
    "print(df_100.category.value_counts())\n",
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(text.split()) for text in df.text]\n",
    "df['length'] = lengths\n",
    "print(df.length.describe())\n",
    "\n",
    "plt.hist(lengths, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv('fake-and-real-news-dataset/Processed_news.csv')\n",
    "X = clean_data.clean_text.values\n",
    "y = np.array([[1, 0] if category==1 else [0, 1] for category in clean_data.category.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train 70% Validation 10% Test 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=21)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('data/fake-and-real-news-dataset/Processed_news.csv')\n",
    "liar = pd.read_csv('data/liar_dataset/Processed_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = news.clean_text.values\n",
    "y = np.array([[1, 0] if category==1 else [0, 1] for category in news.category.values])\n",
    "# Train 70% Validation 10% Test 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=21)\n",
    "news_corpus, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_corpus = liar.clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# load pre-trained word embeddings into an Embedding layer\\n# note that we set trainable = False so as to keep the embeddings fixed\\nembedding_layer = Embedding(num_words,\\n                            EMBEDDING_DIM,\\n                            embeddings_initializer=Constant(embedding_matrix),\\n                            input_length=MAX_SEQUENCE_LENGTH,\\n                            trainable=False)\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = liar_corpus\n",
    "'''\n",
    "Parameters:\n",
    "size - size of dense vector to represent each token/word\n",
    "window - max distance between target and neighbour word\n",
    "min_count - min frequency of count of words. Ignore below threshold\n",
    "workers - # of threads to run\n",
    "'''\n",
    "# sample - to downsample frequent words\n",
    "# sg - if skip-gram is used (=1) else CBOW\n",
    "# window - # of words looked before and after the analyzed one\n",
    "\n",
    "word_sequence = []\n",
    "\n",
    "for text in corpus:\n",
    "    word_sequence.append(text.split())\n",
    "\n",
    "w2v = Word2Vec(word_sequence,\n",
    "               sg=0,\n",
    "               size=150,\n",
    "               window=5,\n",
    "               min_count=1,\n",
    "               workers=4)\n",
    "#model.save(\"w2v.model\")\n",
    "\n",
    "\n",
    "max_words = 10000 # + 1 As padding is added as 0 pero no worries\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "# prepare embedding matrix\n",
    "embedding_matrix = np.zeros((max_words, 150))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= max_words:\n",
    "        break\n",
    "\n",
    "    if word in w2v.wv.vocab:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = w2v.wv[word]\n",
    "\n",
    "# embedding_matrix [variable clave]\n",
    "        \n",
    "'''\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(text) for text in X]\n",
    "clean_data['length'] = lengths\n",
    "print(clean_data.length.describe())\n",
    "\n",
    "plt.hist(lengths, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer -> dar un id a las palabras\n",
    "# <OOV>\n",
    "# <PAD>\n",
    "\n",
    "max_words = 10000 # + 1 As padding is added as 0\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "max_length = 700\n",
    "trunc_type = 'post'\n",
    "pad_type = 'post'\n",
    "\n",
    "# Assign id to tokens\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_sequences,\n",
    "                             maxlen=max_length,\n",
    "                             padding=pad_type,\n",
    "                             truncating=trunc_type)\n",
    "\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences,\n",
    "                            maxlen=max_length,\n",
    "                            padding=pad_type,\n",
    "                            truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "print('%s tokens used' % max_words)\n",
    "\n",
    "print(train_padded[0])\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_weight_matrix(model, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, 150))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = model[word]\n",
    "    return weight_matrix\n",
    "\n",
    "embedding_vectors = get_weight_matrix(w2v, word_index)\n",
    "'''\n",
    "vocab_size = max_words+1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,\n",
    "                    output_dim=150,\n",
    "                    #weights=[embedding_vectors],\n",
    "                    input_length=max_length,\n",
    "                    trainable=True))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(x=train_padded, \n",
    "                  y=y_train, \n",
    "                  epochs=5,\n",
    "                  batch_size=64\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Auxiliar Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    # Default learning rate is 0.001\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def fit_model(model):\n",
    "    # Perform crossValidation\n",
    "    # Calculate cv_valid and y_valid from cv_train and y_train\n",
    "    model.fit(x=X_train, \n",
    "              y=y_train,\n",
    "              epochs=5,\n",
    "              batch_size=64\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def cross_val_evaluate_model(model):\n",
    "    # Stratified K-fold produces k sets preserving the ratio of labels in each sample\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    scores = []\n",
    "    \n",
    "    for train_index, valid_index in skf.split(X_train, y_train):\n",
    "        X_cv_train, X_cv_valid = X_train[train_index], X_train[valid_index]\n",
    "        y_cv_train, y_cv_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "        \n",
    "        y_cv_train = pd.get_dummies(y_cv_train)\n",
    "        y_cv_valid = pd.get_dummies(y_cv_valid)\n",
    "        \n",
    "        # Do trainning\n",
    "        cve_model = model\n",
    "        \n",
    "        cve_model.fit(x=X_cv_train, \n",
    "                      y=y_cv_train,\n",
    "                      epochs=10,\n",
    "                      batch_size=64\n",
    "        )\n",
    "        \n",
    "        loss, accuracy = cve_model.evaluate(x=X_cv_valid,\n",
    "                                            y=y_cv_valid,\n",
    "                                            batch_size=64\n",
    "                         )\n",
    "        print('\\nTest Loss: {}'.format(loss))\n",
    "        print('Test Accuracy: {}'.format(accuracy))\n",
    "        \n",
    "        # Get all scores and make a mean\n",
    "        scores.append(accuracy)\n",
    "        \n",
    "    print(\"Accuracy scores: \", scores)\n",
    "    print(\"Average Accuracy score: \", sum(scores)/len(scores))\n",
    "\n",
    "def evaluate_model(model):\n",
    "    loss, accuracy = model.evaluate(x=X_test,\n",
    "                                    y=y_test\n",
    "                     )\n",
    "    print('Test Loss: {}'.format(loss))\n",
    "    print('Test Accuracy: {}'.format(accuracy))\n",
    "    return loss, accuracy\n",
    "    \n",
    "def predict_model(model):\n",
    "    pred = model.predict(cv_test)\n",
    "    accuracy_score(pred, y_test)\n",
    "    \n",
    "    cv_report = classification_report(y_test,pred,target_names = ['0','1'])\n",
    "    print(cv_report)\n",
    "    cm_cv = confusion_matrix(y_test,pred)\n",
    "    cm_cv\n",
    "    cm_cv = pd.DataFrame(cm_cv, index=[0,1], columns=[0,1])\n",
    "    cm_cv.index.name = 'Actual'\n",
    "    cm_cv.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.heatmap(cm_cv,cmap= \"Blues\",annot = True, fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Understanding LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An embedding layer stores one vector per word. When called, it converts the sequences of word indices to sequences of vectors. These vectors are trainable. After training (on enough data), words with similar meanings often have similar vectors.\n",
    "\n",
    "This index-lookup is much more efficient than the equivalent operation of passing a one-hot encoded vector through a tf.keras.layers.Dense layer.\n",
    "\n",
    "A recurrent neural network (RNN) processes sequence input by iterating through the elements. RNNs pass the outputs from one timestep to their inputâ€”and then to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Default output of RNN layer is a single vector per sample. Corresponds to the last timestep containing information about the entire input sequence. output_shape = (batch_size, units). Units are the argument passed to layer's constructor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Keras example\n",
    "model = Sequential()\n",
    "\n",
    "# input_dim = size of vocabulary\n",
    "# output_dim = embedding dimension\n",
    "model.add(Embedding(input_dim=700, output_dim=150))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "# If parameter \"return_sequences=True\" it outputs the entire\n",
    "# sequence of outputs for each sample.\n",
    "model.add(LSTM(128))\n",
    "\n",
    "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
    "model.add(layers.GRU(256, return_sequences=True))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Prepare data for training**. Create batches of encoded strings using \"padded_patch\" method. Then create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIAR-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/liar_dataset/train.tsv', sep='\\t', header=0)\n",
    "valid = pd.read_csv('data/liar_dataset/valid.tsv', sep='\\t', header=0)\n",
    "test = pd.read_csv('data/liar_dataset/test.tsv', sep='\\t', header=0)\n",
    "\n",
    "df = pd.concat([train, valid, test], ignore_index=True)\n",
    "#train.to_csv('data/liar_dataset/AllInOne.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text normalization\n",
    "extra_stop = [\"would\", \"arent\", \"cant\", \"couldnt\", \"didnt\", \"doesnt\", \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"hes\", \"isnt\", \"ive\", \"shes\", \"shouldnt\", \"wasnt\", \"werent\", \"wouldnt\", \"wont\", \"youd\", \"youll\", \"youre\", \"youve\"]\n",
    "stop = set(stopwords.words('english') + extra_stop)\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def normalize_liar_text(text):\n",
    "    \n",
    "    # Join semi-colon separated words\n",
    "    text = re.sub(\"(-)\", \"\", text)\n",
    "    \n",
    "    # Acronyms case sensitive\n",
    "    text = re.sub(\"US\", 'united states', text)\n",
    "    text = re.sub(\"U\\.S\\.\", 'united states', text)\n",
    "    text = re.sub(\"N\\.Y\\.\", 'new york', text)\n",
    "    text = re.sub(\"U\\.K\\.\", 'united kingdom', text)\n",
    "    text = re.sub(\"U\\.N\\.\", 'united nations', text)\n",
    "    \n",
    "    # New thingies\n",
    "    text = re.sub(\"Id \", '', text)\n",
    "    text = re.sub(\"$\", ' money ', text)\n",
    "    text = re.sub(\"%\", ' percent ', text)\n",
    "    \n",
    "    \n",
    "    text = text.lower()\n",
    "    '''\n",
    "    # Remove urls and other links\n",
    "    text = re.sub('(www\\.[^\\s]+)', '', text)\n",
    "    text = re.sub('(https?://[^\\s]+)', '', text)\n",
    "    text = re.sub('(bit\\.ly[^\\s]+)', '', text)\n",
    "    text = re.sub('(pic\\.twitter\\.com/[^\\s]+)', '', text)\n",
    "    text = re.sub('(tmsnrt\\.rs[^\\s]+)', '', text)\n",
    "    text = re.sub('(polling\\.reuters\\.com[^\\s]+)', '', text)              \n",
    "    \n",
    "    \n",
    "    # Remove non-text relevant content\n",
    "    text = text.replace(\"(video)\", '')\n",
    "    text = text.replace(\"(videos)\", '')    \n",
    "    text = text.replace(\"(tweet)\", '')\n",
    "    text = text.replace(\"(tweets)\", '')    \n",
    "    text = text.replace(\"(image)\", '')\n",
    "    text = text.replace(\"(images)\", '')\n",
    "    text = text.replace(\"(graphic images)\", '')\n",
    "    '''\n",
    "    \n",
    "    # Remove everything but lowercase, accounts and whitespaces\n",
    "    text = re.sub('([^a-z@ ]+)', ' ',text)\n",
    "    \n",
    "    # Remove extra white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "\n",
    "    temp = []\n",
    "    for word in text.split():\n",
    "        if word not in stop and len(word) > 1 and '@' not in word:\n",
    "            temp.append(wnl.lemmatize(word))\n",
    "\n",
    "    return \" \".join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_text'] = train.statement.apply(normalize_liar_text)\n",
    "valid['clean_text'] = valid.statement.apply(normalize_liar_text)\n",
    "test['clean_text'] = test.statement.apply(normalize_liar_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, valid, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false          1995\n",
       "mostly-true    1962\n",
       "true           1676\n",
       "barely-true    1654\n",
       "pants-fire      839\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = ['pants-fire', 'false', 'barely-true']\n",
    "\n",
    "train['category'] = [1 if x in fake else 0 for x in train.label]\n",
    "valid['category'] = [1 if x in fake else 0 for x in valid.label]\n",
    "test['category'] = [1 if x in fake else 0 for x in test.label]\n",
    "\n",
    "train.to_csv('data/liar_dataset/Processed_train2.csv')\n",
    "valid.to_csv('data/liar_dataset/Processed_valid2.csv')\n",
    "test.to_csv('data/liar_dataset/Processed_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    12792.000000\n",
      "mean        11.459350\n",
      "std          5.918259\n",
      "min          2.000000\n",
      "25%          8.000000\n",
      "50%         11.000000\n",
      "75%         14.000000\n",
      "max        296.000000\n",
      "Name: length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = [len(text.split()) for text in df.clean_text]\n",
    "\n",
    "df['length'] = lengths\n",
    "print(df.length.describe())\n",
    "\n",
    "plt.hist(df.length.values, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[296,\n",
       " 278,\n",
       " 195,\n",
       " 142,\n",
       " 127,\n",
       " 44,\n",
       " 40,\n",
       " 39,\n",
       " 35,\n",
       " 33,\n",
       " 33,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df.length, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['party'].value_counts()\n",
    "#Possible groupings (6 groups)\n",
    "#Hyper param -> num_party\n",
    "party_dict = {'republican':0,'democrat':1,'none':2,'organization':3,'newsmaker':4}\n",
    "#default index for rest party is 5\n",
    "def map_party(party):\n",
    "    if party in party_dict:\n",
    "        return party_dict[party]\n",
    "    else:\n",
    "        return 5\n",
    "data_set['party_id'] = data_set['party'].apply(map_party)\n",
    "val_set['party_id'] = val_set['party'].apply(map_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5753\n",
       "1    4488\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['jsonId', 'label', 'statement', 'subject', 'speaker', 'speakerJobTitle',\n",
       "       'stateInfo', 'partyAffiliation', 'barely-true', 'false', 'half-true',\n",
       "       'mostly-true', 'pants-on-fire', 'context', 'clean_text', 'category',\n",
       "       'length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.stateInfo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jsonId</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speakerJobTitle</th>\n",
       "      <th>stateInfo</th>\n",
       "      <th>partyAffiliation</th>\n",
       "      <th>barely-true</th>\n",
       "      <th>false</th>\n",
       "      <th>half-true</th>\n",
       "      <th>mostly-true</th>\n",
       "      <th>pants-on-fire</th>\n",
       "      <th>context</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>Denver</td>\n",
       "      <td>hillary clinton agrees john mccain voting give...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>153.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>I'm the only person on this stage who has work...</td>\n",
       "      <td>ethics</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>a Democratic debate in Philadelphia, Pa.</td>\n",
       "      <td>person stage worked actively last year passing...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>620.json</td>\n",
       "      <td>true</td>\n",
       "      <td>McCain opposed a requirement that the governme...</td>\n",
       "      <td>federal-budget</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>a radio ad</td>\n",
       "      <td>mccain opposed requirement government buy amer...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10039.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>The cost of health care is now the single-bigg...</td>\n",
       "      <td>deficit,federal-budget,health-care</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>a speech at Northwestern University</td>\n",
       "      <td>cost health care singlebiggest factor driving ...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>338.json</td>\n",
       "      <td>true</td>\n",
       "      <td>Sen. Obama has always had a 100 percent procho...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>an e-mail message sent to voters before Super ...</td>\n",
       "      <td>sen obama always percent prochoice rating money</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12707</th>\n",
       "      <td>10416.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Weve doubled the production of clean energy.</td>\n",
       "      <td>energy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>a speech in Knoxville, Tenn.</td>\n",
       "      <td>weve doubled production clean energy money</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12726</th>\n",
       "      <td>1909.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>I've issued a six-month moratorium on deepwate...</td>\n",
       "      <td>energy,oil-spill</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>an address from the Oval Office</td>\n",
       "      <td>issued sixmonth moratorium deepwater drilling ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12729</th>\n",
       "      <td>10466.json</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>The reason we even have colleges is that at so...</td>\n",
       "      <td>education,history</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>an interview with YouTube celebrity Bethany Mota</td>\n",
       "      <td>reason even college point politician said know...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12736</th>\n",
       "      <td>1652.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>On recess appointments.</td>\n",
       "      <td>foreign-policy,legal-issues,workers</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>a prepared statement</td>\n",
       "      <td>recess appointment money</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12783</th>\n",
       "      <td>609.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>On offshore drilling.</td>\n",
       "      <td>energy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>offshore drilling money</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>613 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           jsonId        label  \\\n",
       "2        324.json  mostly-true   \n",
       "7        153.json    half-true   \n",
       "16       620.json         true   \n",
       "74     10039.json  mostly-true   \n",
       "105      338.json         true   \n",
       "...           ...          ...   \n",
       "12707  10416.json  mostly-true   \n",
       "12726   1909.json    half-true   \n",
       "12729  10466.json  barely-true   \n",
       "12736   1652.json    half-true   \n",
       "12783    609.json    half-true   \n",
       "\n",
       "                                               statement  \\\n",
       "2      Hillary Clinton agrees with John McCain \"by vo...   \n",
       "7      I'm the only person on this stage who has work...   \n",
       "16     McCain opposed a requirement that the governme...   \n",
       "74     The cost of health care is now the single-bigg...   \n",
       "105    Sen. Obama has always had a 100 percent procho...   \n",
       "...                                                  ...   \n",
       "12707       Weve doubled the production of clean energy.   \n",
       "12726  I've issued a six-month moratorium on deepwate...   \n",
       "12729  The reason we even have colleges is that at so...   \n",
       "12736                            On recess appointments.   \n",
       "12783                              On offshore drilling.   \n",
       "\n",
       "                                   subject       speaker speakerJobTitle  \\\n",
       "2                           foreign-policy  barack-obama       President   \n",
       "7                                   ethics  barack-obama       President   \n",
       "16                          federal-budget  barack-obama       President   \n",
       "74      deficit,federal-budget,health-care  barack-obama       President   \n",
       "105                               abortion  barack-obama       President   \n",
       "...                                    ...           ...             ...   \n",
       "12707                               energy  barack-obama       President   \n",
       "12726                     energy,oil-spill  barack-obama       President   \n",
       "12729                    education,history  barack-obama       President   \n",
       "12736  foreign-policy,legal-issues,workers  barack-obama       President   \n",
       "12783                               energy  barack-obama       President   \n",
       "\n",
       "      stateInfo partyAffiliation  barely-true  false  half-true  mostly-true  \\\n",
       "2      Illinois         democrat           70     71        160          163   \n",
       "7      Illinois         democrat           70     71        160          163   \n",
       "16     Illinois         democrat           70     71        160          163   \n",
       "74     Illinois         democrat           70     71        160          163   \n",
       "105    Illinois         democrat           70     71        160          163   \n",
       "...         ...              ...          ...    ...        ...          ...   \n",
       "12707  Illinois         democrat           70     71        160          163   \n",
       "12726  Illinois         democrat           70     71        160          163   \n",
       "12729  Illinois         democrat           70     71        160          163   \n",
       "12736  Illinois         democrat           70     71        160          163   \n",
       "12783  Illinois         democrat           70     71        160          163   \n",
       "\n",
       "       pants-on-fire                                            context  \\\n",
       "2                  9                                             Denver   \n",
       "7                  9           a Democratic debate in Philadelphia, Pa.   \n",
       "16                 9                                         a radio ad   \n",
       "74                 9                a speech at Northwestern University   \n",
       "105                9  an e-mail message sent to voters before Super ...   \n",
       "...              ...                                                ...   \n",
       "12707              9                       a speech in Knoxville, Tenn.   \n",
       "12726              9                    an address from the Oval Office   \n",
       "12729              9   an interview with YouTube celebrity Bethany Mota   \n",
       "12736              9                               a prepared statement   \n",
       "12783              9                                                NaN   \n",
       "\n",
       "                                              clean_text  category  length  \n",
       "2      hillary clinton agrees john mccain voting give...         0      13  \n",
       "7      person stage worked actively last year passing...         0      16  \n",
       "16     mccain opposed requirement government buy amer...         0      13  \n",
       "74     cost health care singlebiggest factor driving ...         0      10  \n",
       "105      sen obama always percent prochoice rating money         0       7  \n",
       "...                                                  ...       ...     ...  \n",
       "12707         weve doubled production clean energy money         0       6  \n",
       "12726  issued sixmonth moratorium deepwater drilling ...         0       6  \n",
       "12729  reason even college point politician said know...         1      10  \n",
       "12736                           recess appointment money         0       3  \n",
       "12783                            offshore drilling money         0       3  \n",
       "\n",
       "[613 rows x 17 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.speaker == 'barack-obama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10240.000000\n",
      "mean        10.497852\n",
      "std          5.611663\n",
      "min          1.000000\n",
      "25%          7.000000\n",
      "50%         10.000000\n",
      "75%         13.000000\n",
      "max        295.000000\n",
      "Name: length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1284.000000\n",
      "mean       10.477414\n",
      "std         4.219831\n",
      "min         2.000000\n",
      "25%         7.000000\n",
      "50%        10.000000\n",
      "75%        13.000000\n",
      "max        27.000000\n",
      "Name: length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAN+klEQVR4nO3dbYwd1X3H8e+vENKGRMXEK8u1addtUKoWtQWtaCqiCMV9cEIUUwkhUJWalMqtBC1pKgWTviBvkJw2TZpKLZIb0zgSgSBCaqv0IRYF0UrFzZogHuxQLGKCLWNvlJCHRmpK+PfFDmi17GLvzr17d89+P5J1Z87M7PxHo/35+Nwz41QVkqS2/NioC5AkDZ7hLkkNMtwlqUGGuyQ1yHCXpAadPeoCANauXVvj4+OjLkOSVpSDBw9+s6rG5tq2LMJ9fHycycnJUZchSStKkufm2+awjCQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNWhZPKGqhRnfcf+ry0d3XjHCSiQtV/bcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkPPcV4GZ8+LBufHSamDPXZIaZLhLUoNOG+5J7khyKsmTM9r+IsnXkjye5EtJzpux7ZYkR5I8neS3hlW4lpfxHfe/+kfS6J1Jz/2zwJZZbfuBi6rql4D/Bm4BSPILwDXAL3bH/G2SswZWrSTpjJz2C9WqejjJ+Ky2L89YfQS4qlveCtxdVf8LfD3JEeBS4D8HUq2WjC8nk1a2QYy5/x7wz93yBuD5GduOdW2vkWR7kskkk1NTUwMoQ5L0il7hnuTPgJeAOxd6bFXtqqqJqpoYGxvrU4YkaZZFz3NPch3wPmBzVVXXfBy4YMZuG7s2SdISWlTPPckW4CPA+6vqBzM27QOuSfLGJJuAC4H/6l+mJGkhTttzT3IXcDmwNskx4FamZ8e8EdifBOCRqvrDqnoqyT3AIaaHa26oqh8Nq3hJ0tzOZLbMtXM0736d/W8DbutTlCSpH59QlaQGGe6S1CDfCrkM+MCQpEGz5y5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGuQrf7Ui+FpkaWHsuUtSgwx3SWqQ4S5JDTLcJalBhrskNei04Z7kjiSnkjw5o+38JPuTPNN9runak+SvkxxJ8niSS4ZZvCRpbmfSc/8ssGVW2w7ggaq6EHigWwd4D3Bh92c7cPtgypQkLcRp57lX1cNJxmc1bwUu75b3AA8BN3ftn6uqAh5Jcl6S9VV1YlAFqw3OW5eGa7Fj7utmBPYLwLpueQPw/Iz9jnVtr5Fke5LJJJNTU1OLLEOSNJfeX6h2vfRaxHG7qmqiqibGxsb6liFJmmGx4X4yyXqA7vNU134cuGDGfhu7NknSElpsuO8DtnXL24C9M9p/t5s18w7gO463S9LSO+0XqknuYvrL07VJjgG3AjuBe5JcDzwHXN3t/k/Ae4EjwA+ADw6hZknSaZzJbJlr59m0eY59C7ihb1GSpH58QlWSGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXo7FEXIA3D+I77X10+uvOKEVYijUavnnuSP0nyVJInk9yV5MeTbEpyIMmRJF9Ics6gipUknZlFh3uSDcAfAxNVdRFwFnAN8HHgU1X1NuDbwPWDKFSSdOb6jrmfDfxEkrOBNwEngHcD93bb9wBX9jyHJGmBFh3uVXUc+ATwDaZD/TvAQeDFqnqp2+0YsGGu45NsTzKZZHJqamqxZUiS5tBnWGYNsBXYBPwUcC6w5UyPr6pdVTVRVRNjY2OLLUOSNIc+wzK/Dny9qqaq6v+A+4DLgPO6YRqAjcDxnjVKkhaoT7h/A3hHkjclCbAZOAQ8CFzV7bMN2NuvREnSQvUZcz/A9BenjwJPdD9rF3Az8OEkR4C3ArsHUKckaQF6PcRUVbcCt85qfha4tM/PlST14+sHJKlBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJalCv97lLLRnfcf+ry0d3XjHCSqT+7LlLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgXuGe5Lwk9yb5WpLDSX4tyflJ9id5pvtcM6hiJUlnpm/P/dPAv1TVzwO/DBwGdgAPVNWFwAPduiRpCS063JP8JPAuYDdAVf2wql4EtgJ7ut32AFf2LVKStDB9eu6bgCng75N8NclnkpwLrKuqE90+LwDr5jo4yfYkk0kmp6amepQhSZqtT7ifDVwC3F5VFwP/w6whmKoqoOY6uKp2VdVEVU2MjY31KEOSNFufcD8GHKuqA936vUyH/ckk6wG6z1P9SpQkLdSiw72qXgCeT/L2rmkzcAjYB2zr2rYBe3tVKElasL6v/P0j4M4k5wDPAh9k+i+Me5JcDzwHXN3zHJKkBeoV7lX1GDAxx6bNfX6uJKkfn1CVpAYZ7pLUIMNdkhpkuEtSg/wPsofA/2hZ0qjZc5ekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNciqktEhOedVyZs9dkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CAfYpKWiA89aSnZc5ekBhnuktSg3uGe5KwkX03yj936piQHkhxJ8oUk5/QvU5K0EIPoud8EHJ6x/nHgU1X1NuDbwPUDOIckaQF6hXuSjcAVwGe69QDvBu7tdtkDXNnnHJKkhevbc/8r4CPAy936W4EXq+qlbv0YsKHnOSRJC7TocE/yPuBUVR1c5PHbk0wmmZyamlpsGZKkOfTpuV8GvD/JUeBupodjPg2cl+SV+fMbgeNzHVxVu6pqoqomxsbGepQhSZpt0eFeVbdU1caqGgeuAf6tqn4HeBC4qtttG7C3d5WSpAUZxjz3m4EPJznC9Bj87iGcQ5L0Ogby+oGqegh4qFt+Frh0ED93ufCxcUkrjU+oSlKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDRrIu2UkDZ7vNFIf9twlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNcjXD0iN8HUFmsmeuyQ1aNHhnuSCJA8mOZTkqSQ3de3nJ9mf5Jnuc83gypUknYk+wzIvAX9aVY8meQtwMMl+4DrggaramWQHsAO4uX+pkkbNoZ+VY9E996o6UVWPdsvfAw4DG4CtwJ5utz3AlX2LlCQtzEDG3JOMAxcDB4B1VXWi2/QCsG6eY7YnmUwyOTU1NYgyJEmd3uGe5M3AF4EPVdV3Z26rqgJqruOqaldVTVTVxNjYWN8yJEkz9Ar3JG9gOtjvrKr7uuaTSdZ329cDp/qVKElaqD6zZQLsBg5X1SdnbNoHbOuWtwF7F1+eJGkx+syWuQz4APBEkse6to8CO4F7klwPPAdc3a9ESdJCLTrcq+o/gMyzefNif64kqT+fUJWkBhnuktQgXxwmrVI+bdo2e+6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDVoVc5zd36vtDT8XRsde+6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDVoxc9zdx6t1I4Wfp+XyzXYc5ekBhnuktSgFT8sI2n1WugQyHIZMlkK9twlqUFDC/ckW5I8neRIkh3DOo8k6bWGMiyT5Czgb4DfAI4BX0myr6oODeN8krSSLMXw0LB67pcCR6rq2ar6IXA3sHVI55IkzZKqGvwPTa4CtlTV73frHwB+tapunLHPdmB7t/p24OmBFzI6a4FvjrqIJeY1rw6r7ZqX+/X+TFWNzbVhZLNlqmoXsGtU5x+mJJNVNTHqOpaS17w6rLZrXsnXO6xhmePABTPWN3ZtkqQlMKxw/wpwYZJNSc4BrgH2DelckqRZhjIsU1UvJbkR+FfgLOCOqnpqGOdappocbjoNr3l1WG3XvGKvdyhfqEqSRssnVCWpQYa7JDXIcB+wJEeTPJHksSSTo65nGJLckeRUkidntJ2fZH+SZ7rPNaOscZDmud6PJTne3efHkrx3lDUOWpILkjyY5FCSp5Lc1LW3fJ/nu+YVea8dcx+wJEeBiapazg8+9JLkXcD3gc9V1UVd258D36qqnd27hNZU1c2jrHNQ5rnejwHfr6pPjLK2YUmyHlhfVY8meQtwELgSuI527/N813w1K/Be23PXglXVw8C3ZjVvBfZ0y3uY/qVowjzX27SqOlFVj3bL3wMOAxto+z7Pd80rkuE+eAV8OcnB7hULq8W6qjrRLb8ArBtlMUvkxiSPd8M2zQxPzJZkHLgYOMAquc+zrhlW4L023AfvnVV1CfAe4Ibun/SrSk2P9bU+3nc78HPArwAngL8cbTnDkeTNwBeBD1XVd2dua/U+z3HNK/JeG+4DVlXHu89TwJeYfkPmanCyG7N8Zezy1IjrGaqqOllVP6qql4G/o8H7nOQNTIfcnVV1X9fc9H2e65pX6r023AcoybndFzEkORf4TeDJ1z+qGfuAbd3yNmDvCGsZulcCrvPbNHafkwTYDRyuqk/O2NTsfZ7vmlfqvXa2zAAl+Vmme+sw/WqHz1fVbSMsaSiS3AVczvTrUE8CtwL/ANwD/DTwHHB1VTXxJeQ813s50/9ML+Ao8AczxqJXvCTvBP4deAJ4uWv+KNNj0K3e5/mu+VpW4L023CWpQQ7LSFKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoP8Hi8LFZTz/W0sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1267.000000\n",
      "mean       10.758485\n",
      "std         9.201282\n",
      "min         1.000000\n",
      "25%         8.000000\n",
      "50%        10.000000\n",
      "75%        13.000000\n",
      "max       277.000000\n",
      "Name: length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aux = []\n",
    "\n",
    "lengths = [len(text.split()) for text in train.clean_text]\n",
    "train['length'] = lengths\n",
    "print(train.length.describe())\n",
    "\n",
    "aux.extend(lengths)\n",
    "\n",
    "plt.hist(lengths, 100)\n",
    "plt.show()\n",
    "\n",
    "lengths = [len(text.split()) for text in valid.clean_text]\n",
    "valid['length'] = lengths\n",
    "print(valid.length.describe())\n",
    "\n",
    "aux.extend(lengths)\n",
    "\n",
    "plt.hist(lengths, 100)\n",
    "plt.show()\n",
    "\n",
    "lengths = [len(text.split()) for text in test.clean_text]\n",
    "test['length'] = lengths\n",
    "print(test.length.describe())\n",
    "\n",
    "aux.extend(lengths)\n",
    "\n",
    "plt.hist(lengths, 100)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(aux, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_100 = pd.DataFrame(columns=[\"clean_text\", \"news_id\", \"category\"])\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    \n",
    "    subtexts = normalize_text_100(row.statement, 30)\n",
    "    \n",
    "    for st in subtexts: \n",
    "        new_row = pd.Series({\"clean_text\": st, \"news_id\": index, \"category\": row.category})\n",
    "        train_100 = train_100.append(new_row, ignore_index=True)\n",
    "        \n",
    "\n",
    "valid_100 = pd.DataFrame(columns=[\"clean_text\", \"news_id\", \"category\"])\n",
    "\n",
    "for index, row in valid.iterrows():\n",
    "    \n",
    "    subtexts = normalize_text_100(row.statement, 30)    \n",
    "    for st in subtexts:        \n",
    "        new_row = pd.Series({\"clean_text\": st, \"news_id\": index, \"category\": row.category})\n",
    "        valid_100 = valid_100.append(new_row, ignore_index=True)\n",
    "\n",
    "\n",
    "test_100 = pd.DataFrame(columns=[\"clean_text\", \"news_id\", \"category\"])\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    \n",
    "    subtexts = normalize_text_100(row.statement, 30)    \n",
    "    for st in subtexts:        \n",
    "        new_row = pd.Series({\"clean_text\": st, \"news_id\": index, \"category\": row.category})\n",
    "        test_100 = test_100.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_text_indices = []\n",
    "\n",
    "for index, text in enumerate(train_100.clean_text.values):\n",
    "    if text == '': \n",
    "        empty_text_indices.append(index)\n",
    "        \n",
    "for i in empty_text_indices:\n",
    "    print('Text:', train_100.iloc[i].clean_text, i)\n",
    "\n",
    "for i in empty_text_indices:\n",
    "    train_100 = train_100.drop(i, axis=0) # Un-useful entry -> empty text value\n",
    "    \n",
    "\n",
    "empty_text_indices = []\n",
    "\n",
    "for index, text in enumerate(valid_100.clean_text.values):\n",
    "    if text == '': \n",
    "        empty_text_indices.append(index)\n",
    "        \n",
    "for i in empty_text_indices:\n",
    "    print('Text:', valid_100.iloc[i].clean_text, i)\n",
    "\n",
    "for i in empty_text_indices:\n",
    "    valid_100 = valid_100.drop(i, axis=0) # Un-useful entry -> empty text value\n",
    "    \n",
    "    \n",
    "empty_text_indices = []\n",
    "\n",
    "for index, text in enumerate(test_100.clean_text.values):\n",
    "    if text == '': \n",
    "        empty_text_indices.append(index)\n",
    "        \n",
    "for i in empty_text_indices:\n",
    "    print('Text:', test_100.iloc[i].clean_text, i)\n",
    "\n",
    "for i in empty_text_indices:\n",
    "    test_100 = test_100.drop(i, axis=0) # Un-useful entry -> empty text value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_100.to_csv('data/liar_dataset/Processed_train_100.csv', index=False)\n",
    "valid_100.to_csv('data/liar_dataset/Processed_valid_100.csv', index=False)\n",
    "test_100.to_csv('data/liar_dataset/Processed_test_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_100 = pd.read_csv('data/liar_dataset/Processed_train_100.csv')\n",
    "valid_100 = pd.read_csv('data/liar_dataset/Processed_valid_100.csv')\n",
    "test_100 = pd.read_csv('data/liar_dataset/Processed_test_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clean_text', 'news_id', 'category'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_100.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_liar_news_100(in_kaggle=False):\n",
    "        \n",
    "    train_path = 'data/liar_dataset/Processed_train_100.csv'\n",
    "    valid_path = 'data/liar_dataset/Processed_valid_100.csv'\n",
    "    test_path = 'data/liar_dataset/Processed_test_100.csv'\n",
    "    \n",
    "    train_data = pd.read_csv(train_path)\n",
    "    valid_data = pd.read_csv(valid_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    \n",
    "    X_train, X_valid, X_test = train_data.clean_text.values, valid_data.clean_text.values, test_data.clean_text.values\n",
    "    y_train = np.array([[1, 0] if category==1 else [0, 1] for category in train_data.category.values])\n",
    "    y_valid = np.array([[1, 0] if category==1 else [0, 1] for category in valid_data.category.values])\n",
    "    y_test = np.array([[1, 0] if category==1 else [0, 1] for category in test_data.category.values])\n",
    "        \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = load_liar_news_100()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(y_test)):\n",
    "    predictions.append(random())\n",
    "\n",
    "test_data = pd.read_csv('data/liar_dataset/Processed_test_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "(1, 1)\n",
      "(2, 2)\n",
      "(3, 3)\n",
      "(4, 4)\n",
      "(5, 5)\n",
      "(6, 6)\n",
      "(7, 7)\n",
      "(8, 8)\n",
      "(9, 9)\n",
      "(10, 10)\n",
      "(11, 11)\n",
      "(12, 12)\n",
      "(13, 13)\n",
      "(14, 14)\n",
      "(15, 15)\n",
      "(16, 16)\n",
      "(17, 17)\n",
      "(18, 18)\n",
      "(19, 19)\n",
      "(20, 20)\n",
      "(21, 21)\n",
      "(22, 22)\n",
      "(23, 23)\n",
      "(24, 24)\n",
      "(25, 25)\n",
      "(26, 26)\n",
      "(27, 27)\n",
      "(28, 28)\n",
      "(29, 29)\n",
      "(30, 30)\n",
      "(31, 31)\n",
      "(32, 32)\n",
      "(33, 33)\n",
      "(34, 34)\n",
      "(35, 35)\n",
      "(36, 36)\n",
      "(37, 37)\n",
      "(38, 38)\n",
      "(39, 39)\n",
      "(40, 40)\n",
      "(41, 41)\n",
      "(42, 42)\n",
      "(43, 43)\n",
      "(44, 44)\n",
      "(45, 45)\n",
      "(46, 46)\n",
      "(47, 47)\n",
      "(48, 48)\n",
      "(49, 49)\n",
      "(50, 50)\n",
      "(51, 51)\n",
      "(52, 52)\n",
      "(53, 53)\n",
      "(54, 54)\n",
      "(55, 55)\n",
      "(56, 56)\n",
      "(57, 57)\n",
      "(58, 58)\n",
      "(59, 59)\n",
      "(60, 60)\n",
      "(61, 61)\n",
      "(62, 62)\n",
      "(63, 63)\n",
      "(64, 64)\n",
      "(65, 65)\n",
      "(66, 66)\n",
      "(67, 67)\n",
      "(68, 68)\n",
      "(69, 69)\n",
      "(70, 70)\n",
      "(71, 71)\n",
      "(72, 72)\n",
      "(73, 73)\n",
      "(74, 74)\n",
      "(75, 75)\n",
      "(76, 76)\n",
      "(77, 77)\n",
      "(78, 78)\n",
      "(79, 79)\n",
      "(80, 80)\n",
      "(81, 81)\n",
      "(82, 82)\n",
      "(83, 83)\n",
      "(84, 84)\n",
      "(85, 85)\n",
      "(86, 86)\n",
      "(87, 87)\n",
      "(88, 88)\n",
      "(89, 89)\n",
      "(90, 90)\n",
      "(91, 91)\n",
      "(92, 92)\n",
      "(93, 93)\n",
      "(94, 94)\n",
      "(95, 95)\n",
      "(96, 96)\n",
      "(97, 97)\n",
      "(98, 98)\n",
      "(99, 99)\n",
      "(100, 100)\n",
      "(101, 101)\n",
      "(102, 102)\n",
      "(103, 103)\n",
      "(104, 104)\n",
      "(105, 105)\n",
      "(106, 106)\n",
      "(107, 107)\n",
      "(108, 108)\n",
      "(109, 109)\n",
      "(110, 110)\n",
      "(111, 111)\n",
      "(112, 112)\n",
      "(113, 113)\n",
      "(114, 114)\n",
      "(115, 115)\n",
      "(116, 116)\n",
      "(117, 117)\n",
      "(118, 118)\n",
      "(119, 119)\n",
      "(120, 120)\n",
      "(121, 121)\n",
      "(122, 122)\n",
      "(123, 123)\n",
      "(124, 124)\n",
      "(125, 125)\n",
      "(126, 126)\n",
      "(127, 127)\n",
      "(128, 128)\n",
      "(129, 129)\n",
      "(130, 130)\n",
      "(131, 131)\n",
      "(132, 132)\n",
      "(133, 133)\n",
      "(134, 134)\n",
      "(135, 135)\n",
      "(136, 136)\n",
      "(137, 137)\n",
      "(138, 138)\n",
      "(139, 139)\n",
      "(140, 140)\n",
      "(141, 141)\n",
      "(142, 142)\n",
      "(143, 143)\n",
      "(144, 144)\n",
      "(145, 145)\n",
      "(146, 146)\n",
      "(147, 147)\n",
      "(148, 148)\n",
      "(149, 149)\n",
      "(150, 150)\n",
      "(151, 151)\n",
      "(152, 152)\n",
      "(153, 153)\n",
      "(154, 154)\n",
      "(155, 155)\n",
      "(156, 156)\n",
      "(157, 157)\n",
      "(158, 158)\n",
      "(159, 159)\n",
      "(160, 160)\n",
      "(161, 161)\n",
      "(162, 162)\n",
      "(163, 163)\n",
      "(164, 164)\n",
      "(165, 165)\n",
      "(166, 166)\n",
      "(167, 167)\n",
      "(168, 168)\n",
      "(169, 169)\n",
      "(170, 170)\n",
      "(171, 171)\n",
      "(172, 172)\n",
      "(173, 173)\n",
      "(174, 174)\n",
      "(175, 175)\n",
      "(176, 176)\n",
      "(177, 177)\n",
      "(178, 178)\n",
      "(179, 179)\n",
      "(180, 180)\n",
      "(181, 181)\n",
      "(182, 182)\n",
      "(183, 183)\n",
      "(184, 184)\n",
      "(185, 185)\n",
      "(186, 186)\n",
      "(187, 187)\n",
      "(188, 188)\n",
      "(189, 189)\n",
      "(190, 190)\n",
      "(191, 191)\n",
      "(192, 192)\n",
      "(193, 193)\n",
      "(194, 194)\n",
      "(195, 195)\n",
      "(196, 196)\n",
      "(197, 197)\n",
      "(198, 198)\n",
      "(199, 199)\n",
      "(200, 200)\n",
      "(201, 201)\n",
      "(202, 202)\n",
      "(203, 203)\n",
      "(204, 204)\n",
      "(205, 205)\n",
      "(206, 206)\n",
      "(207, 207)\n",
      "(208, 208)\n",
      "(209, 209)\n",
      "(210, 210)\n",
      "(211, 211)\n",
      "(212, 212)\n",
      "(213, 213)\n",
      "(214, 214)\n",
      "(215, 215)\n",
      "(216, 216)\n",
      "(217, 217)\n",
      "(218, 218)\n",
      "(219, 219)\n",
      "(220, 220)\n",
      "(221, 221)\n",
      "(222, 222)\n",
      "(223, 223)\n",
      "(224, 224)\n",
      "(225, 225)\n",
      "(226, 226)\n",
      "(227, 227)\n",
      "(228, 228)\n",
      "(229, 229)\n",
      "(230, 230)\n",
      "(231, 231)\n",
      "(232, 232)\n",
      "(233, 233)\n",
      "(234, 234)\n",
      "(235, 235)\n",
      "(236, 236)\n",
      "(237, 237)\n",
      "(238, 238)\n",
      "(239, 239)\n",
      "(240, 240)\n",
      "(241, 241)\n",
      "(242, 242)\n",
      "(243, 243)\n",
      "(244, 244)\n",
      "(245, 245)\n",
      "(246, 246)\n",
      "(247, 247)\n",
      "(248, 248)\n",
      "(249, 249)\n",
      "(250, 250)\n",
      "(251, 251)\n",
      "(252, 252)\n",
      "(253, 253)\n",
      "(254, 254)\n",
      "(255, 255)\n",
      "(256, 256)\n",
      "(257, 257)\n",
      "(258, 258)\n",
      "(259, 259)\n",
      "(260, 260)\n",
      "(261, 261)\n",
      "(262, 262)\n",
      "(263, 263)\n",
      "(264, 264)\n",
      "(265, 265)\n",
      "(266, 266)\n",
      "(267, 267)\n",
      "(268, 268)\n",
      "(269, 269)\n",
      "(270, 270)\n",
      "(271, 271)\n",
      "(272, 272)\n",
      "(273, 273)\n",
      "(274, 274)\n",
      "(275, 275)\n",
      "(276, 276)\n",
      "(277, 277)\n",
      "(278, 278)\n",
      "(279, 279)\n",
      "(280, 280)\n",
      "(281, 281)\n",
      "(282, 282)\n",
      "(283, 283)\n",
      "(284, 284)\n",
      "(285, 285)\n",
      "(286, 286)\n",
      "(287, 287)\n",
      "(288, 288)\n",
      "(289, 289)\n",
      "(290, 290)\n",
      "(291, 291)\n",
      "(292, 292)\n",
      "(293, 293)\n",
      "(294, 294)\n",
      "(295, 295)\n",
      "(296, 296)\n",
      "(297, 297)\n",
      "(298, 298)\n",
      "(299, 299)\n",
      "(300, 300)\n",
      "(301, 301)\n",
      "(302, 302)\n",
      "(303, 303)\n",
      "(304, 304)\n",
      "(305, 305)\n",
      "(306, 306)\n",
      "(307, 307)\n",
      "(308, 308)\n",
      "(309, 309)\n",
      "(310, 310)\n",
      "(311, 311)\n",
      "(312, 312)\n",
      "(313, 313)\n",
      "(314, 314)\n",
      "(315, 315)\n",
      "(316, 316)\n",
      "(317, 317)\n",
      "(318, 318)\n",
      "(319, 319)\n",
      "(320, 320)\n",
      "(321, 321)\n",
      "(322, 322)\n",
      "(323, 323)\n",
      "(324, 324)\n",
      "(325, 325)\n",
      "(326, 326)\n",
      "(327, 327)\n",
      "(328, 328)\n",
      "(329, 329)\n",
      "(330, 330)\n",
      "(331, 331)\n",
      "(332, 332)\n",
      "(333, 333)\n",
      "(334, 334)\n",
      "(335, 335)\n",
      "(336, 336)\n",
      "(337, 337)\n",
      "(338, 338)\n",
      "(339, 339)\n",
      "(340, 340)\n",
      "(341, 341)\n",
      "(342, 342)\n",
      "(343, 343)\n",
      "(344, 344)\n",
      "(345, 345)\n",
      "(346, 346)\n",
      "(347, 347)\n",
      "(348, 348)\n",
      "(349, 349)\n",
      "(350, 350)\n",
      "(351, 351)\n",
      "(352, 352)\n",
      "(353, 353)\n",
      "(354, 354)\n",
      "(355, 355)\n",
      "(356, 356)\n",
      "(357, 357)\n",
      "(358, 358)\n",
      "(359, 359)\n",
      "(360, 360)\n",
      "(361, 361)\n",
      "(362, 362)\n",
      "(363, 363)\n",
      "(364, 364)\n",
      "(365, 365)\n",
      "(366, 366)\n",
      "(367, 367)\n",
      "(368, 368)\n",
      "(369, 369)\n",
      "(370, 370)\n",
      "(371, 371)\n",
      "(372, 372)\n",
      "(373, 373)\n",
      "(374, 374)\n",
      "(375, 375)\n",
      "(376, 376)\n",
      "(377, 377)\n",
      "(378, 378)\n",
      "(379, 379)\n",
      "(380, 380)\n",
      "(381, 381)\n",
      "(382, 382)\n",
      "(383, 383)\n",
      "(384, 384)\n",
      "(385, 385)\n",
      "(386, 386)\n",
      "(387, 387)\n",
      "(388, 388)\n",
      "(389, 389)\n",
      "(390, 390)\n",
      "(391, 391)\n",
      "(392, 392)\n",
      "(393, 393)\n",
      "(394, 394)\n",
      "(395, 395)\n",
      "(396, 396)\n",
      "(397, 397)\n",
      "(398, 398)\n",
      "(399, 399)\n",
      "(400, 400)\n",
      "(401, 401)\n",
      "(402, 402)\n",
      "(403, 403)\n",
      "(404, 404)\n",
      "(405, 405)\n",
      "(406, 406)\n",
      "(407, 407)\n",
      "(408, 408)\n",
      "(409, 409)\n",
      "(410, 410)\n",
      "(411, 411)\n",
      "(412, 412)\n",
      "(413, 413)\n",
      "(414, 414)\n",
      "(415, 415)\n",
      "(416, 416)\n",
      "(417, 417)\n",
      "(418, 418)\n",
      "(419, 419)\n",
      "(420, 420)\n",
      "(421, 421)\n",
      "(422, 422)\n",
      "(423, 423)\n",
      "(424, 424)\n",
      "(425, 425)\n",
      "(426, 426)\n",
      "(427, 427)\n",
      "(428, 428)\n",
      "(429, 429)\n",
      "(430, 430)\n",
      "(431, 431)\n",
      "(432, 432)\n",
      "(433, 433)\n",
      "(434, 434)\n",
      "(435, 435)\n",
      "(436, 436)\n",
      "(437, 437)\n",
      "(438, 438)\n",
      "(439, 439)\n",
      "(440, 440)\n",
      "(441, 441)\n",
      "(442, 442)\n",
      "(443, 443)\n",
      "(444, 444)\n",
      "(445, 445)\n",
      "(446, 446)\n",
      "(447, 447)\n",
      "(448, 448)\n",
      "(449, 449)\n",
      "(450, 450)\n",
      "(451, 451)\n",
      "(452, 452)\n",
      "(453, 453)\n",
      "(454, 454)\n",
      "(455, 455)\n",
      "(456, 456)\n",
      "(457, 457)\n",
      "(458, 458)\n",
      "(459, 459)\n",
      "(460, 460)\n",
      "(461, 461)\n",
      "(462, 462)\n",
      "(463, 463)\n",
      "(464, 464)\n",
      "(465, 465)\n",
      "(466, 466)\n",
      "(467, 467)\n",
      "(468, 468)\n",
      "(469, 469)\n",
      "(470, 470)\n",
      "(471, 471)\n",
      "(472, 472)\n",
      "(473, 473)\n",
      "(474, 474)\n",
      "(475, 475)\n",
      "(476, 476)\n",
      "(477, 477)\n",
      "(478, 478)\n",
      "(479, 479)\n",
      "(480, 480)\n",
      "(481, 481)\n",
      "(482, 482)\n",
      "(483, 483)\n",
      "(484, 484)\n",
      "(485, 485)\n",
      "(486, 486)\n",
      "(487, 487)\n",
      "(488, 488)\n",
      "(489, 489)\n",
      "(490, 490)\n",
      "(491, 491)\n",
      "(492, 492)\n",
      "(493, 493)\n",
      "(494, 494)\n",
      "(495, 495)\n",
      "(496, 496)\n",
      "(497, 497)\n",
      "(498, 498)\n",
      "(499, 499)\n",
      "(500, 500)\n",
      "(501, 501)\n",
      "(502, 502)\n",
      "(503, 503)\n",
      "(504, 504)\n",
      "(505, 505)\n",
      "(506, 506)\n",
      "(507, 507)\n",
      "(508, 508)\n",
      "(509, 509)\n",
      "(510, 510)\n",
      "(511, 511)\n",
      "(512, 512)\n",
      "(513, 513)\n",
      "(514, 514)\n",
      "(515, 515)\n",
      "(516, 516)\n",
      "(517, 517)\n",
      "(518, 518)\n",
      "(519, 519)\n",
      "(520, 520)\n",
      "(521, 521)\n",
      "(522, 522)\n",
      "(523, 523)\n",
      "(524, 524)\n",
      "(525, 525)\n",
      "(526, 526)\n",
      "(527, 527)\n",
      "(528, 528)\n",
      "(529, 529)\n",
      "(530, 530)\n",
      "(531, 531)\n",
      "(532, 532)\n",
      "(533, 533)\n",
      "(534, 534)\n",
      "(535, 535)\n",
      "(536, 536)\n",
      "(537, 537)\n",
      "(538, 538)\n",
      "(539, 539)\n",
      "(540, 540)\n",
      "(541, 541)\n",
      "(542, 542)\n",
      "(543, 543)\n",
      "(544, 544)\n",
      "(545, 545)\n",
      "(546, 546)\n",
      "(547, 547)\n",
      "(548, 548)\n",
      "(549, 549)\n",
      "(550, 550)\n",
      "(551, 551)\n",
      "(552, 552)\n",
      "(553, 553)\n",
      "(554, 554)\n",
      "(555, 555)\n",
      "(556, 556)\n",
      "(557, 557)\n",
      "(558, 558)\n",
      "(559, 559)\n",
      "(560, 560)\n",
      "(561, 561)\n",
      "(562, 562)\n",
      "(563, 563)\n",
      "(564, 564)\n",
      "(565, 565)\n",
      "(566, 566)\n",
      "(567, 567)\n",
      "(568, 568)\n",
      "(569, 569)\n",
      "(570, 570)\n",
      "(571, 571)\n",
      "(572, 572)\n",
      "(573, 573)\n",
      "(574, 574)\n",
      "(575, 575)\n",
      "(576, 576)\n",
      "(577, 577)\n",
      "(578, 578)\n",
      "(579, 579)\n",
      "(580, 580)\n",
      "(581, 581)\n",
      "(582, 582)\n",
      "(583, 583)\n",
      "(584, 584)\n",
      "(585, 585)\n",
      "(586, 586)\n",
      "(587, 587)\n",
      "(588, 588)\n",
      "(589, 589)\n",
      "(590, 590)\n",
      "(591, 591)\n",
      "(592, 592)\n",
      "(593, 593)\n",
      "(594, 594)\n",
      "(595, 595)\n",
      "(596, 596)\n",
      "(597, 597)\n",
      "(598, 598)\n",
      "(599, 599)\n",
      "(600, 600)\n",
      "(601, 601)\n",
      "(602, 602)\n",
      "(603, 603)\n",
      "(604, 604)\n",
      "(605, 605)\n",
      "(606, 606)\n",
      "(607, 607)\n",
      "(608, 608)\n",
      "(609, 609)\n",
      "(610, 610)\n",
      "(611, 611)\n",
      "(612, 612)\n",
      "(613, 613)\n",
      "(614, 614)\n",
      "(615, 615)\n",
      "(616, 616)\n",
      "(617, 617)\n",
      "(618, 618)\n",
      "(619, 619)\n",
      "(620, 620)\n",
      "(621, 621)\n",
      "(622, 622)\n",
      "(623, 623)\n",
      "(624, 624)\n",
      "(625, 625)\n",
      "(626, 626)\n",
      "(627, 627)\n",
      "(628, 628)\n",
      "(629, 629)\n",
      "(630, 630)\n",
      "(631, 631)\n",
      "(632, 632)\n",
      "(633, 633)\n",
      "(634, 634)\n",
      "(635, 635)\n",
      "(636, 636)\n",
      "(637, 637)\n",
      "(638, 638)\n",
      "(639, 639)\n",
      "(640, 640)\n",
      "(641, 641)\n",
      "(642, 642)\n",
      "(643, 643)\n",
      "(644, 644)\n",
      "(645, 645)\n",
      "(646, 646)\n",
      "(647, 647)\n",
      "(648, 648)\n",
      "(649, 649)\n",
      "(650, 650)\n",
      "(651, 651)\n",
      "(652, 652)\n",
      "(653, 653)\n",
      "(654, 654)\n",
      "(655, 655)\n",
      "(656, 656)\n",
      "(657, 657)\n",
      "(658, 658)\n",
      "(659, 659)\n",
      "(660, 660)\n",
      "(661, 661)\n",
      "(662, 662)\n",
      "(663, 663)\n",
      "(664, 664)\n",
      "(665, 665)\n",
      "(666, 666)\n",
      "(667, 667)\n",
      "(668, 668)\n",
      "(669, 669)\n",
      "(670, 670)\n",
      "(671, 671)\n",
      "(672, 672)\n",
      "(673, 673)\n",
      "(674, 674)\n",
      "(675, 675)\n",
      "(676, 676)\n",
      "(677, 677)\n",
      "(678, 678)\n",
      "(679, 679)\n",
      "(680, 680)\n",
      "(681, 681)\n",
      "(682, 682)\n",
      "(683, 683)\n",
      "(684, 684)\n",
      "(685, 685)\n",
      "(686, 686)\n",
      "(687, 687)\n",
      "(688, 688)\n",
      "(689, 689)\n",
      "(690, 690)\n",
      "(691, 691)\n",
      "(692, 692)\n",
      "(693, 693)\n",
      "(694, 694)\n",
      "(695, 695)\n",
      "(696, 696)\n",
      "(697, 697)\n",
      "(698, 698)\n",
      "(699, 699)\n",
      "(700, 700)\n",
      "(701, 701)\n",
      "(702, 702)\n",
      "(703, 703)\n",
      "(704, 703)\n",
      "(705, 703)\n",
      "(706, 703)\n",
      "(707, 703)\n",
      "(708, 703)\n",
      "(709, 703)\n",
      "(710, 703)\n",
      "(711, 703)\n",
      "(712, 703)\n",
      "(713, 704)\n",
      "(714, 705)\n",
      "(715, 706)\n",
      "(716, 707)\n",
      "(717, 708)\n",
      "(718, 709)\n",
      "(719, 710)\n",
      "(720, 711)\n",
      "(721, 712)\n",
      "(722, 713)\n",
      "(723, 714)\n",
      "(724, 715)\n",
      "(725, 716)\n",
      "(726, 717)\n",
      "(727, 718)\n",
      "(728, 719)\n",
      "(729, 720)\n",
      "(730, 721)\n",
      "(731, 722)\n",
      "(732, 723)\n",
      "(733, 724)\n",
      "(734, 725)\n",
      "(735, 726)\n",
      "(736, 727)\n",
      "(737, 728)\n",
      "(738, 729)\n",
      "(739, 730)\n",
      "(740, 731)\n",
      "(741, 732)\n",
      "(742, 733)\n",
      "(743, 734)\n",
      "(744, 735)\n",
      "(745, 736)\n",
      "(746, 737)\n",
      "(747, 738)\n",
      "(748, 739)\n",
      "(749, 740)\n",
      "(750, 741)\n",
      "(751, 742)\n",
      "(752, 743)\n",
      "(753, 744)\n",
      "(754, 745)\n",
      "(755, 746)\n",
      "(756, 747)\n",
      "(757, 748)\n",
      "(758, 749)\n",
      "(759, 750)\n",
      "(760, 751)\n",
      "(761, 752)\n",
      "(762, 753)\n",
      "(763, 754)\n",
      "(764, 755)\n",
      "(765, 756)\n",
      "(766, 757)\n",
      "(767, 758)\n",
      "(768, 759)\n",
      "(769, 760)\n",
      "(770, 761)\n",
      "(771, 762)\n",
      "(772, 763)\n",
      "(773, 764)\n",
      "(774, 765)\n",
      "(775, 766)\n",
      "(776, 767)\n",
      "(777, 768)\n",
      "(778, 769)\n",
      "(779, 770)\n",
      "(780, 771)\n",
      "(781, 772)\n",
      "(782, 773)\n",
      "(783, 774)\n",
      "(784, 775)\n",
      "(785, 776)\n",
      "(786, 777)\n",
      "(787, 778)\n",
      "(788, 779)\n",
      "(789, 780)\n",
      "(790, 781)\n",
      "(791, 782)\n",
      "(792, 783)\n",
      "(793, 784)\n",
      "(794, 785)\n",
      "(795, 786)\n",
      "(796, 787)\n",
      "(797, 788)\n",
      "(798, 789)\n",
      "(799, 790)\n",
      "(800, 791)\n",
      "(801, 792)\n",
      "(802, 793)\n",
      "(803, 794)\n",
      "(804, 795)\n",
      "(805, 796)\n",
      "(806, 797)\n",
      "(807, 798)\n",
      "(808, 799)\n",
      "(809, 800)\n",
      "(810, 801)\n",
      "(811, 802)\n",
      "(812, 803)\n",
      "(813, 804)\n",
      "(814, 805)\n",
      "(815, 806)\n",
      "(816, 807)\n",
      "(817, 808)\n",
      "(818, 809)\n",
      "(819, 810)\n",
      "(820, 811)\n",
      "(821, 812)\n",
      "(822, 813)\n",
      "(823, 814)\n",
      "(824, 815)\n",
      "(825, 816)\n",
      "(826, 817)\n",
      "(827, 818)\n",
      "(828, 819)\n",
      "(829, 820)\n",
      "(830, 821)\n",
      "(831, 822)\n",
      "(832, 823)\n",
      "(833, 824)\n",
      "(834, 825)\n",
      "(835, 826)\n",
      "(836, 827)\n",
      "(837, 828)\n",
      "(838, 829)\n",
      "(839, 830)\n",
      "(840, 831)\n",
      "(841, 832)\n",
      "(842, 833)\n",
      "(843, 834)\n",
      "(844, 835)\n",
      "(845, 836)\n",
      "(846, 837)\n",
      "(847, 838)\n",
      "(848, 839)\n",
      "(849, 840)\n",
      "(850, 841)\n",
      "(851, 842)\n",
      "(852, 843)\n",
      "(853, 844)\n",
      "(854, 845)\n",
      "(855, 846)\n",
      "(856, 847)\n",
      "(857, 848)\n",
      "(858, 849)\n",
      "(859, 850)\n",
      "(860, 851)\n",
      "(861, 852)\n",
      "(862, 853)\n",
      "(863, 854)\n",
      "(864, 855)\n",
      "(865, 856)\n",
      "(866, 857)\n",
      "(867, 858)\n",
      "(868, 859)\n",
      "(869, 860)\n",
      "(870, 861)\n",
      "(871, 862)\n",
      "(872, 863)\n",
      "(873, 864)\n",
      "(874, 865)\n",
      "(875, 866)\n",
      "(876, 867)\n",
      "(877, 868)\n",
      "(878, 869)\n",
      "(879, 870)\n",
      "(880, 871)\n",
      "(881, 872)\n",
      "(882, 873)\n",
      "(883, 874)\n",
      "(884, 875)\n",
      "(885, 876)\n",
      "(886, 877)\n",
      "(887, 878)\n",
      "(888, 879)\n",
      "(889, 880)\n",
      "(890, 881)\n",
      "(891, 882)\n",
      "(892, 883)\n",
      "(893, 884)\n",
      "(894, 885)\n",
      "(895, 886)\n",
      "(896, 887)\n",
      "(897, 888)\n",
      "(898, 889)\n",
      "(899, 890)\n",
      "(900, 891)\n",
      "(901, 892)\n",
      "(902, 893)\n",
      "(903, 894)\n",
      "(904, 895)\n",
      "(905, 896)\n",
      "(906, 897)\n",
      "(907, 898)\n",
      "(908, 899)\n",
      "(909, 900)\n",
      "(910, 901)\n",
      "(911, 902)\n",
      "(912, 903)\n",
      "(913, 904)\n",
      "(914, 905)\n",
      "(915, 906)\n",
      "(916, 907)\n",
      "(917, 908)\n",
      "(918, 909)\n",
      "(919, 910)\n",
      "(920, 911)\n",
      "(921, 912)\n",
      "(922, 913)\n",
      "(923, 914)\n",
      "(924, 915)\n",
      "(925, 916)\n",
      "(926, 917)\n",
      "(927, 918)\n",
      "(928, 919)\n",
      "(929, 920)\n",
      "(930, 921)\n",
      "(931, 922)\n",
      "(932, 923)\n",
      "(933, 923)\n",
      "(934, 923)\n",
      "(935, 923)\n",
      "(936, 923)\n",
      "(937, 924)\n",
      "(938, 925)\n",
      "(939, 926)\n",
      "(940, 927)\n",
      "(941, 928)\n",
      "(942, 929)\n",
      "(943, 930)\n",
      "(944, 931)\n",
      "(945, 932)\n",
      "(946, 933)\n",
      "(947, 934)\n",
      "(948, 935)\n",
      "(949, 936)\n",
      "(950, 937)\n",
      "(951, 938)\n",
      "(952, 939)\n",
      "(953, 940)\n",
      "(954, 941)\n",
      "(955, 942)\n",
      "(956, 943)\n",
      "(957, 944)\n",
      "(958, 945)\n",
      "(959, 946)\n",
      "(960, 947)\n",
      "(961, 948)\n",
      "(962, 949)\n",
      "(963, 950)\n",
      "(964, 951)\n",
      "(965, 952)\n",
      "(966, 953)\n",
      "(967, 954)\n",
      "(968, 955)\n",
      "(969, 956)\n",
      "(970, 957)\n",
      "(971, 958)\n",
      "(972, 959)\n",
      "(973, 960)\n",
      "(974, 961)\n",
      "(975, 962)\n",
      "(976, 963)\n",
      "(977, 964)\n",
      "(978, 965)\n",
      "(979, 966)\n",
      "(980, 967)\n",
      "(981, 968)\n",
      "(982, 969)\n",
      "(983, 970)\n",
      "(984, 971)\n",
      "(985, 972)\n",
      "(986, 973)\n",
      "(987, 974)\n",
      "(988, 975)\n",
      "(989, 976)\n",
      "(990, 977)\n",
      "(991, 978)\n",
      "(992, 979)\n",
      "(993, 980)\n",
      "(994, 981)\n",
      "(995, 982)\n",
      "(996, 983)\n",
      "(997, 984)\n",
      "(998, 985)\n",
      "(999, 986)\n",
      "(1000, 987)\n",
      "(1001, 988)\n",
      "(1002, 989)\n",
      "(1003, 990)\n",
      "(1004, 991)\n",
      "(1005, 992)\n",
      "(1006, 993)\n",
      "(1007, 994)\n",
      "(1008, 995)\n",
      "(1009, 996)\n",
      "(1010, 997)\n",
      "(1011, 998)\n",
      "(1012, 999)\n",
      "(1013, 1000)\n",
      "(1014, 1001)\n",
      "(1015, 1002)\n",
      "(1016, 1003)\n",
      "(1017, 1004)\n",
      "(1018, 1005)\n",
      "(1019, 1006)\n",
      "(1020, 1007)\n",
      "(1021, 1008)\n",
      "(1022, 1009)\n",
      "(1023, 1010)\n",
      "(1024, 1011)\n",
      "(1025, 1012)\n",
      "(1026, 1013)\n",
      "(1027, 1014)\n",
      "(1028, 1015)\n",
      "(1029, 1016)\n",
      "(1030, 1017)\n",
      "(1031, 1018)\n",
      "(1032, 1019)\n",
      "(1033, 1020)\n",
      "(1034, 1021)\n",
      "(1035, 1022)\n",
      "(1036, 1023)\n",
      "(1037, 1024)\n",
      "(1038, 1025)\n",
      "(1039, 1026)\n",
      "(1040, 1027)\n",
      "(1041, 1028)\n",
      "(1042, 1029)\n",
      "(1043, 1030)\n",
      "(1044, 1031)\n",
      "(1045, 1032)\n",
      "(1046, 1033)\n",
      "(1047, 1034)\n",
      "(1048, 1035)\n",
      "(1049, 1036)\n",
      "(1050, 1037)\n",
      "(1051, 1038)\n",
      "(1052, 1039)\n",
      "(1053, 1040)\n",
      "(1054, 1041)\n",
      "(1055, 1042)\n",
      "(1056, 1043)\n",
      "(1057, 1044)\n",
      "(1058, 1045)\n",
      "(1059, 1046)\n",
      "(1060, 1047)\n",
      "(1061, 1048)\n",
      "(1062, 1049)\n",
      "(1063, 1050)\n",
      "(1064, 1051)\n",
      "(1065, 1052)\n",
      "(1066, 1053)\n",
      "(1067, 1054)\n",
      "(1068, 1055)\n",
      "(1069, 1056)\n",
      "(1070, 1057)\n",
      "(1071, 1058)\n",
      "(1072, 1058)\n",
      "(1073, 1059)\n",
      "(1074, 1060)\n",
      "(1075, 1061)\n",
      "(1076, 1062)\n",
      "(1077, 1063)\n",
      "(1078, 1064)\n",
      "(1079, 1065)\n",
      "(1080, 1066)\n",
      "(1081, 1067)\n",
      "(1082, 1068)\n",
      "(1083, 1069)\n",
      "(1084, 1070)\n",
      "(1085, 1071)\n",
      "(1086, 1072)\n",
      "(1087, 1073)\n",
      "(1088, 1074)\n",
      "(1089, 1075)\n",
      "(1090, 1076)\n",
      "(1091, 1077)\n",
      "(1092, 1078)\n",
      "(1093, 1079)\n",
      "(1094, 1080)\n",
      "(1095, 1081)\n",
      "(1096, 1082)\n",
      "(1097, 1083)\n",
      "(1098, 1084)\n",
      "(1099, 1085)\n",
      "(1100, 1086)\n",
      "(1101, 1087)\n",
      "(1102, 1088)\n",
      "(1103, 1089)\n",
      "(1104, 1090)\n",
      "(1105, 1091)\n",
      "(1106, 1092)\n",
      "(1107, 1093)\n",
      "(1108, 1094)\n",
      "(1109, 1095)\n",
      "(1110, 1096)\n",
      "(1111, 1097)\n",
      "(1112, 1098)\n",
      "(1113, 1099)\n",
      "(1114, 1100)\n",
      "(1115, 1101)\n",
      "(1116, 1102)\n",
      "(1117, 1103)\n",
      "(1118, 1104)\n",
      "(1119, 1105)\n",
      "(1120, 1106)\n",
      "(1121, 1107)\n",
      "(1122, 1108)\n",
      "(1123, 1109)\n",
      "(1124, 1110)\n",
      "(1125, 1111)\n",
      "(1126, 1112)\n",
      "(1127, 1113)\n",
      "(1128, 1114)\n",
      "(1129, 1115)\n",
      "(1130, 1116)\n",
      "(1131, 1117)\n",
      "(1132, 1118)\n",
      "(1133, 1119)\n",
      "(1134, 1120)\n",
      "(1135, 1121)\n",
      "(1136, 1122)\n",
      "(1137, 1123)\n",
      "(1138, 1124)\n",
      "(1139, 1125)\n",
      "(1140, 1126)\n",
      "(1141, 1127)\n",
      "(1142, 1128)\n",
      "(1143, 1129)\n",
      "(1144, 1130)\n",
      "(1145, 1131)\n",
      "(1146, 1132)\n",
      "(1147, 1133)\n",
      "(1148, 1134)\n",
      "(1149, 1135)\n",
      "(1150, 1136)\n",
      "(1151, 1137)\n",
      "(1152, 1138)\n",
      "(1153, 1139)\n",
      "(1154, 1140)\n",
      "(1155, 1141)\n",
      "(1156, 1142)\n",
      "(1157, 1143)\n",
      "(1158, 1144)\n",
      "(1159, 1145)\n",
      "(1160, 1146)\n",
      "(1161, 1147)\n",
      "(1162, 1148)\n",
      "(1163, 1149)\n",
      "(1164, 1150)\n",
      "(1165, 1151)\n",
      "(1166, 1152)\n",
      "(1167, 1153)\n",
      "(1168, 1154)\n",
      "(1169, 1155)\n",
      "(1170, 1156)\n",
      "(1171, 1157)\n",
      "(1172, 1158)\n",
      "(1173, 1159)\n",
      "(1174, 1160)\n",
      "(1175, 1161)\n",
      "(1176, 1162)\n",
      "(1177, 1163)\n",
      "(1178, 1164)\n",
      "(1179, 1165)\n",
      "(1180, 1166)\n",
      "(1181, 1167)\n",
      "(1182, 1168)\n",
      "(1183, 1169)\n",
      "(1184, 1170)\n",
      "(1185, 1171)\n",
      "(1186, 1172)\n",
      "(1187, 1173)\n",
      "(1188, 1174)\n",
      "(1189, 1175)\n",
      "(1190, 1176)\n",
      "(1191, 1177)\n",
      "(1192, 1178)\n",
      "(1193, 1179)\n",
      "(1194, 1180)\n",
      "(1195, 1181)\n",
      "(1196, 1182)\n",
      "(1197, 1183)\n",
      "(1198, 1184)\n",
      "(1199, 1185)\n",
      "(1200, 1186)\n",
      "(1201, 1187)\n",
      "(1202, 1188)\n",
      "(1203, 1189)\n",
      "(1204, 1190)\n",
      "(1205, 1191)\n",
      "(1206, 1192)\n",
      "(1207, 1193)\n",
      "(1208, 1194)\n",
      "(1209, 1195)\n",
      "(1210, 1196)\n",
      "(1211, 1197)\n",
      "(1212, 1198)\n",
      "(1213, 1199)\n",
      "(1214, 1200)\n",
      "(1215, 1201)\n",
      "(1216, 1202)\n",
      "(1217, 1203)\n",
      "(1218, 1204)\n",
      "(1219, 1205)\n",
      "(1220, 1206)\n",
      "(1221, 1207)\n",
      "(1222, 1208)\n",
      "(1223, 1209)\n",
      "(1224, 1210)\n",
      "(1225, 1211)\n",
      "(1226, 1212)\n",
      "(1227, 1213)\n",
      "(1228, 1214)\n",
      "(1229, 1215)\n",
      "(1230, 1216)\n",
      "(1231, 1217)\n",
      "(1232, 1218)\n",
      "(1233, 1219)\n",
      "(1234, 1220)\n",
      "(1235, 1221)\n",
      "(1236, 1222)\n",
      "(1237, 1223)\n",
      "(1238, 1224)\n",
      "(1239, 1225)\n",
      "(1240, 1226)\n",
      "(1241, 1227)\n",
      "(1242, 1228)\n",
      "(1243, 1229)\n",
      "(1244, 1230)\n",
      "(1245, 1231)\n",
      "(1246, 1232)\n",
      "(1247, 1233)\n",
      "(1248, 1234)\n",
      "(1249, 1235)\n",
      "(1250, 1236)\n",
      "(1251, 1237)\n",
      "(1252, 1238)\n",
      "(1253, 1239)\n",
      "(1254, 1240)\n",
      "(1255, 1241)\n",
      "(1256, 1242)\n",
      "(1257, 1243)\n",
      "(1258, 1244)\n",
      "(1259, 1245)\n",
      "(1260, 1246)\n",
      "(1261, 1247)\n",
      "(1262, 1248)\n",
      "(1263, 1249)\n",
      "(1264, 1250)\n",
      "(1265, 1251)\n",
      "(1266, 1252)\n",
      "(1267, 1253)\n",
      "(1268, 1254)\n",
      "(1269, 1255)\n",
      "(1270, 1256)\n",
      "(1271, 1257)\n",
      "(1272, 1258)\n",
      "(1273, 1259)\n",
      "(1274, 1260)\n",
      "(1275, 1261)\n",
      "(1276, 1262)\n",
      "(1277, 1263)\n",
      "(1278, 1264)\n",
      "(1279, 1265)\n",
      "(1280, 1266)\n"
     ]
    }
   ],
   "source": [
    "for i in test_data.news_id.iteritems():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = test_data[test_data.news_id != test_data.index].news_id.values\n",
    "b = len(set(a))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[703, 704, 705, 706, 707, 708, 709, 710, 711, 712]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_data[test_data.news_id == 703].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1267 [0.45636962618014976, 0.7422106157378502, 0.16797168983924493, 0.19219720184847677, 0.4929351307208808, 0.279457152215997, 0.7518928356312075, 0.04099856577875838, 0.5905967402470802, 0.032742162113741036, 0.6262296688091141, 0.7450954811735195, 0.008336825593579511, 0.753596454096571, 0.11056590837150515, 0.5797483654291853, 0.205447102120757, 0.10945650970902376, 0.47930016307148904, 0.8752802096571307, 0.4429035774773591, 0.38396410537094416, 0.1326726381024772, 0.025187672295923447, 0.53792816893901, 0.508075176237385, 0.4981992638577547, 0.5585150073445637, 0.7563934301895082, 0.22069196629582544, 0.1272441768817021, 0.5059459896854966, 0.7612580741665129, 0.6247395907557265, 0.537082668813529, 0.13854940702040475, 0.35389599613001044, 0.018964915909085556, 0.11736325326981822, 0.05183328631093109, 0.22750741664704088, 0.010823558922238297, 0.041706960149895056, 0.7579832262508239, 0.38073066315058934, 0.5329550559198557, 0.685099214123894, 0.7336962938689732, 0.9343229984967043, 0.3851208598865804, 0.2706931546368627, 0.9291194967012572, 0.9472870893775694, 0.8540732922655432, 0.09490781586937258, 0.08155485493933667, 0.11741998701420675, 0.9156569143812011, 0.3389573969679217, 0.19735680671193134, 0.537745605000054, 0.45861463527108337, 0.5386139589549443, 0.6652942876657882, 0.1575938919894131, 0.36812372314002906, 0.10636059092414285, 0.30801381010526363, 0.9006241016467722, 0.13329671507886443, 0.3465045922195722, 0.030393415470365115, 0.8402913049533258, 0.4075578983145062, 0.18166734377000437, 0.6357615068737635, 0.9018387242608952, 0.6537996977519105, 0.04855933449360661, 0.014963155478567969, 0.06502137309690992, 0.743724572186348, 0.771835422196231, 0.47626060822863936, 0.9788830565101287, 0.11378066908684914, 0.4382274064693342, 0.05914628206604222, 0.5428039079261111, 0.40757853884353057, 0.8123178349921146, 0.8492440912714319, 0.48375244825643715, 0.3950911960901561, 0.13261271949566045, 0.3857590056865229, 0.9586020289961572, 0.8546447383700816, 0.9295197722195241, 0.8382026926126391, 0.5515612019453301, 0.13478065715603382, 0.0004315942104072823, 0.9134168005319575, 0.7413296757107263, 0.1515621954528139, 0.9786657198918663, 0.6733699411901959, 0.5401168084174811, 0.12221289723249051, 0.924947535769796, 0.7497149596088881, 0.26221224152972356, 0.8886988397300047, 0.59381456726431, 0.7449940569767834, 0.5191111405244576, 0.7687406025782819, 0.19871951727871018, 0.3777862860536991, 0.9355184193038221, 0.09372655223686555, 0.12428161980764818, 0.1406631482580537, 0.4851424444161264, 0.8762673996736837, 0.4919788742973209, 0.6782631117941885, 0.6946320252289732, 0.9624581770909406, 0.49611600009639356, 0.9045596545271847, 0.8938188442027566, 0.32384573706821884, 0.29707863837510873, 0.9356571751408906, 0.5579635588789691, 0.413823820844747, 0.011381849559375046, 0.8575077554551467, 0.2883783378840741, 0.3663593218740401, 0.06814361151670478, 0.1903137442734718, 0.5272079851094349, 0.42180493944201924, 0.383374004673786, 0.5624229662105303, 0.5158679256657703, 0.592888623119457, 0.19196035631468011, 0.5571006903150654, 0.10891148927661953, 0.5033956630548017, 0.32603059412442503, 0.2502089652509276, 0.8214662980365316, 0.30437757149693, 0.2834165604964508, 0.309329212905459, 0.3274153583605751, 0.984341923827692, 0.37885305515940193, 0.885360322735574, 0.3067250365106994, 0.10478340378187478, 0.38924883859308035, 0.43333730101949275, 0.7727491749434447, 0.2656689519435742, 0.30204396054832905, 0.14714698446013796, 0.30767100527316105, 0.49843834490302785, 0.8023910592983068, 0.24080851038305506, 0.2248831505645008, 0.9877529181070975, 0.27259897675440803, 0.4627557428114193, 0.54672966996688, 0.5167155639351724, 0.6783126759713466, 0.8887478319044498, 0.3388618103466656, 0.540847918082083, 0.9101978705782163, 0.4974371788038394, 0.8874434803013973, 0.31164270182099396, 0.9346959162459448, 0.03870289975095931, 0.09003195593691449, 0.5841873036734171, 0.7058775876351331, 0.07519637130440315, 0.9642053657405885, 0.12332424117399132, 0.571044346731972, 0.3171372161509175, 0.07917280118743697, 0.19911234806484845, 0.8404124759241962, 0.8079084002936154, 0.14276042549193146, 0.7745089869341568, 0.8139743844674344, 0.5714893320570792, 0.5464525618587587, 0.21256215579607152, 0.04417776869059131, 0.10235056292175015, 0.35011298065526386, 0.7411012807726458, 0.6084169874857007, 0.1447068358777629, 0.2513340601422618, 0.3611701046354906, 0.4585033086925925, 0.16516789293893486, 0.6638662549631127, 0.21873079289224662, 0.5264025034533397, 0.36725874238264977, 0.6555870989444902, 0.42498097726813644, 0.11422373136386477, 0.08381689633098477, 0.24992386549030077, 0.49482896735768334, 0.4585313151946566, 0.8955149496691018, 0.7608465296391757, 0.3541760819598273, 0.11844962549286786, 0.9780590453650287, 0.9013569667984361, 0.5150518373457307, 0.1958826326519314, 0.38234184389017944, 0.6714697773456675, 0.4300312312397504, 0.9104512549213921, 0.2050686466831909, 0.4150905650422938, 0.2217095206576406, 0.6455877353946456, 0.6138050264588447, 0.2032329272708504, 0.024239449110653566, 0.8625535017463324, 0.20908584212165482, 0.7016482463330036, 0.8206850765383182, 0.24243413357767618, 0.8025848553521837, 0.03216661600826709, 0.9464646913014878, 0.714041258550208, 0.021453363267616377, 0.8456237786064942, 0.48605841959654195, 0.4617021467013994, 0.9172249982881941, 0.5684037842795956, 0.9508410546768196, 0.6564884815551391, 0.4122811262584235, 0.30398325751503064, 0.8990820137869596, 0.08333641329626229, 0.853889924918548, 0.828719835958952, 0.4358226997543384, 0.21859657918580033, 0.4090553092189603, 0.40814621583747845, 0.6821986665174434, 0.6935417813513912, 0.8919237926771085, 0.017671498458247004, 0.307897743801538, 0.7110499248385822, 0.030574179437463767, 0.8716583859733533, 0.5228967707877848, 0.6241410118558723, 0.2541490015766259, 0.29365727128760855, 0.05178997561873677, 0.5382251736039945, 0.08089321847526487, 0.13600737153628872, 0.6237941761031853, 0.9774123502694272, 0.8395420212984664, 0.6737644182172782, 0.09340123744069295, 0.5208486221613949, 0.26883249392925934, 0.9147851670478003, 0.6498838292498329, 0.15196101811383944, 0.8908566857770932, 0.6570405211136281, 0.619403663217068, 0.11660751182866647, 0.4428921718533081, 0.24982313474618312, 0.05384939121074095, 0.5547220929586673, 0.8987021329316508, 0.6049543882941422, 0.8302996640845531, 0.7417217675071476, 0.33194098137436345, 0.6507535367804279, 0.6105453946894652, 0.11123192798881343, 0.47983239519326637, 0.91924981106499, 0.8075898591380563, 0.5643997159797619, 0.35861856754731425, 0.8444323639993977, 0.7533648509720989, 0.18015297608291758, 0.24013785181903413, 0.7993923673338659, 0.802805704841712, 0.16175418473519598, 0.571915212959722, 0.061022214014221365, 0.48810742445108457, 0.046639550312629896, 0.3405970172216296, 0.7764118710488482, 0.011910380188970726, 0.22925443423668412, 0.9125892419507515, 0.3444185194520384, 0.12933987340990627, 0.14193518030724106, 0.714411513276093, 0.3408865670758008, 0.06926983137586129, 0.03378306849094026, 0.5788265563162102, 0.16082711425143326, 0.7466761845966969, 0.15201542235065668, 0.8118207825724726, 0.3825308656419303, 0.2029751034857371, 0.11368175154915494, 0.4749791832914023, 0.9088735852828402, 0.9466394689495516, 0.015986394163902462, 0.7955526603510036, 0.2911985249490161, 0.6210116413591419, 0.29615640155357736, 0.6063266070311821, 0.003555269796052918, 0.5753159536757076, 0.32700055594737365, 0.09224447777333333, 0.7950357874223437, 0.6064212939688913, 0.08119926159212765, 0.722876021527849, 0.09867808196060845, 0.06637812106925844, 0.777907792980653, 0.9532395259147977, 0.5255204087001056, 0.9197660129151191, 0.28072131112481213, 0.6901523196934432, 0.8843215677965256, 0.0788477217758331, 0.6079665813578384, 0.08839460602173566, 0.526516837380463, 0.09565394124837034, 0.06303881220909668, 0.8155847577599389, 0.43833795238107354, 0.9949401258796717, 0.43457507086986635, 0.37466554908077243, 0.5933231275442173, 0.16746561938335158, 0.4046736248168481, 0.10079175127480022, 0.47062677551222654, 0.1602662342191422, 0.3564665246248784, 0.5755049628437583, 0.019630906933903236, 0.472623149380068, 0.05469762532034328, 0.9422519810842567, 0.8343203603757995, 0.0635281927393414, 0.5853713166630363, 0.771298874131503, 0.04064247187037384, 0.7378270613170724, 0.4509742067820197, 0.7113110549056624, 0.5620728295180754, 0.11023086203951349, 0.1090868518852961, 0.9819015145230314, 0.4976212535862633, 0.8475420595637032, 0.16815335092970085, 0.5011557851864004, 0.1528783945535389, 0.3953628803863485, 0.7724271483869434, 0.9471700076285147, 0.1792856688585177, 0.31990607250260295, 0.19123557450245177, 0.02465755058065644, 0.16458088830747908, 0.7159783886413241, 0.1900658342055721, 0.3263064945136863, 0.45542945034333904, 0.8175886504553024, 0.31983225797919435, 0.40449429548227533, 0.8752870902011105, 0.6326050066035752, 0.056260776272361146, 0.3029868160093021, 0.21874498608530601, 0.26583267737480587, 0.043845994900208574, 0.4260008412931253, 0.7193652654446602, 0.8628950720253652, 0.9688473838316942, 0.2632957209285759, 0.3122303886231136, 0.8988422851037436, 0.24711652353797287, 0.2955084332854171, 0.4276441308782365, 0.7500342495953789, 0.2850272150356411, 0.010988647482475189, 0.5355351158030005, 0.645044190198758, 0.8603622028216468, 0.5859315279790491, 0.29933438608046314, 0.5619287574218128, 0.16816025674420532, 0.4088854709036891, 0.5159935416224368, 0.15864167536216922, 0.42820070024689993, 0.2593406881590449, 0.5343722076603737, 0.8292289168859938, 0.8079311884189502, 0.07945450563556922, 0.5150368401374325, 0.041634985259074275, 0.1638769228662319, 0.9064048575317561, 0.49797504885711497, 0.7351646886828158, 0.10271191593965534, 0.9185011656106552, 0.8115191731244633, 0.7038811007421709, 0.5660852685052176, 0.26342808782864824, 0.3635355379510038, 0.9912735796544331, 0.6064033742113193, 0.3998906085270675, 0.9007858789320471, 0.6519919511494898, 0.10712764692933052, 0.4214777398721037, 0.31036830525376513, 0.5963236875055281, 0.08390916590632314, 0.44789113078382004, 0.41431646926188936, 0.15880645581427455, 0.35378761910468515, 0.8654147792883563, 0.6769817532555946, 0.3771195875052812, 0.5660428488036595, 0.4165693147690873, 0.8950310942109297, 0.7967683234414327, 0.5159715035661817, 0.6420842785776705, 0.8842074755662723, 0.04717901725129969, 0.4074219658653252, 0.464188578044766, 0.10763518198471311, 0.5385675167355248, 0.13287000748236377, 0.6366918203545937, 0.13504443967631485, 0.20386253906526708, 0.6631025424043795, 0.4203409781963252, 0.5441084521712635, 0.10648931909307391, 0.6017396423723496, 0.1991198226718084, 0.01800134087241878, 0.10988761418296678, 0.1338797069664619, 0.4782680624047273, 0.8591732647034434, 0.924443213380095, 0.10593395848660137, 0.36125364769623025, 0.37420690065504436, 0.5405893284483593, 0.22042264298749803, 0.1311368623664667, 0.6843136678515634, 0.38066084230444597, 0.12086494710961271, 0.17377953726257034, 0.7634238005621391, 0.6013336713715179, 0.49022244014016647, 0.8853302180628602, 0.4331110690936144, 0.14501847726331907, 0.04408992190985417, 0.13117496571675036, 0.8501722736461109, 0.4895943579745228, 0.04012290609198177, 0.856934948486604, 0.6398121608414753, 0.4839245174724248, 0.6181921778192773, 0.52848397830951, 0.5614657341048453, 0.8541549727669527, 0.6602130917017717, 0.8136246478308525, 0.05543960619733057, 0.8209246655481771, 0.9756987349730264, 0.2269599849207996, 0.28130020591694105, 0.32355961605092654, 0.8751395135820054, 0.9148412718607585, 0.43835203088654173, 0.3769107064745233, 0.36381425673088275, 0.647553344393458, 0.10206545388308241, 0.37466404838646694, 0.257621210983356, 0.9708831839420332, 0.05593726991358272, 0.12050020112356852, 0.08138145849698919, 0.7381504474443558, 0.36987167129323895, 0.08696918445644786, 0.08951377068112243, 0.9579397078792768, 0.28408879918561947, 0.974348119734917, 0.7281403972027759, 0.967500282439639, 0.5120951668149045, 0.8646272702851919, 0.1550002753723263, 0.025121555240818272, 0.42107918739308436, 0.3239194342321148, 0.5240439390440221, 0.9496640643291876, 0.8865460813519767, 0.32638598299058397, 0.5812319267727417, 0.6419996081928894, 0.4371979993403776, 0.03804688687760771, 0.04989879547290743, 0.10066438613140105, 0.022569274335478284, 0.4896928619844365, 0.6303602693908048, 0.05479497127780075, 0.15614802174273512, 0.7925373013734542, 0.964550494543327, 0.850495044723256, 0.5276409060789499, 0.9827714886510645, 0.9530210854441412, 0.33706966081501444, 0.3998585209369593, 0.5532634064656026, 0.3965702019776187, 0.7968230246889249, 0.2436234412834174, 0.6644724794217685, 0.7217762128308849, 0.6124800967843407, 0.5505430201176192, 0.6756107165483786, 0.3150343474354018, 0.02238297795686084, 0.375148088896871, 0.13942165239326343, 0.7611741579049633, 0.8722993520819086, 0.8149598424069541, 0.09500877545484188, 0.053696694067138506, 0.8062732626612854, 0.5170448845316508, 0.17193404924275457, 0.5353499103666843, 0.984169175824806, 0.5320420537022743, 0.2506866509666399, 0.9200584966456098, 0.6164875287318776, 0.4685245350010204, 0.7033469384118413, 0.16044124789749048, 0.7183890202059012, 0.014138954802202841, 0.4330269146532446, 0.19117929366172237, 0.11920326115482027, 0.13665179012708994, 0.9772985006967888, 0.46789650682642514, 0.9160608600596069, 0.8194072473103482, 0.9974291615892336, 0.09487903203653314, 0.6846976348087733, 0.6931124940677715, 0.7987378241483328, 0.4135067478469959, 0.8582368605757742, 0.3777251978937701, 0.49089949654755427, 0.5830405183553066, 0.3481227945437658, 0.7702224983464894, 0.8333769010425913, 0.8103782635860797, 0.1368532324972317, 0.2392359376605656, 0.8373366145604672, 0.11293249044037079, 0.6828824990048227, 0.026742710409645154, 0.5936356498894344, 0.9868259522701908, 0.5880277281166576, 0.6386063475887769, 0.4759006901113477, 0.7426441497440887, 0.9144045486591293, 0.6547073047321426, 0.6474317147564381, 0.8174427776343791, 0.5046250713852515, 0.049590500303066, 0.19085701488891404, 0.9637206509371696, 0.3781395669305422, 0.47522423734776054, 0.886871608755793, 0.23223254069918753, 0.6812643909572417, 0.13945156603017628, 0.47137882803578757, 0.9232676888463243, 0.3645200540599757, 0.34471234304019605, 0.9507733933192711, 0.7915920337687193, 0.4507419103467464, 0.5933088972191478, 0.6242564715425498, 0.7431522708116517, 0.8698558203085939, 0.13380191121568474, 0.25933836761210216, 0.08240735768139873, 0.016440608691574488, 0.10037401414111269, 0.5414470998393369, 0.9376450946411014, 0.21353508022884093, 0.41501246436808537, 0.3689743252327471, 0.22780471519879908, 0.7275525563096217, 0.6119424901396224, 0.9793176633835856, 0.6505259030842768, 0.8883978121187173, 0.5021230620227408, 0.16000089304926102, 0.9543830784613367, 0.8501928510208363, 0.0018925333153020363, 0.7648519150058942, 0.8111662888601782, 0.628658431180757, 0.6513133795351466, 0.25802909346549996, 0.027935655250921898, 0.2702674953971085, 0.642009211865079, 0.9874952656419633, 0.6423093233883819, 0.972070000794045, 0.0379024355148202, 0.9799286558032377, 0.5468568469603132, 0.3400594630222462, 0.29067845639442536, 0.001165110826769844, 0.08084351470654827, 0.10857032167647462, 0.5097902500295446, 0.7757908428548863, 0.02176249852732659, 0.42474290426550654, 0.02133089790945275, 0.552393694819119, 0.14547824840359525, 0.6322121687837832, 0.14221007704088828, 0.3527464861194993, 0.4788176356657331, 0.4899238043311933, 0.2625289008426096, 0.929957704426602, 0.07222620854481254, 0.5800004754114918, 0.867127671074007, 0.00027320309730149983, 0.8648534533601094, 0.0585500092624085, 0.292496718217773, 0.5131712650338239, 0.26722949594634426, 0.7069507133279401, 0.7340762544515963, 0.12756477075634487, 0.9654411736983609, 0.9669507083483693, 0.864247321800612, 0.18461874963570146, 0.9793681186521137, 0.02059126032704728, 0.4182887402337955, 0.7748326353520126, 0.8947920935806901, 0.8265429638907754, 0.957639042587414, 0.8173114986621793, 0.4829354847438727, 0.7201840130661725, 0.777656554120619, 0.5037875594041088, 0.4710810289834708, 0.5584641688008688, 0.1301566824980529, 0.1338870900429282, 0.850053001746909, 0.7080526389667943, 0.20322606492282813, 0.5474286148607379, 0.6772494368640479, 0.9513009975007005, 0.475099924221435, 0.820005353095656, 0.057626628318418804, 0.6632014675857727, 0.12234576677366327, 0.5211223555025405, 0.7650097064383242, 0.20675035737254222, 0.7490293355006659, 0.8823880406555507, 0.5719370517850578, 0.9586646912812856, 0.7663168198094338, 0.19229406097709612, 0.23300473685271994, 0.7533710826294943, 0.0035576574737368194, 0.32648408776400983, 0.5729053763581217, 0.7460071941969941, 0.8579171730790841, 0.8939832841243656, 0.9949870642770797, 0.4165129454843345, 0.8702941995806962, 0.33180575975020987, 0.18657317992985845, 0.7879344271025557, 0.30604135547670885, 0.17291387105029465, 0.8717039602420389, 0.5787707631276909, 0.15495483070279048, 0.9529659446735014, 0.9429026303301975, 0.5850233329688995, 0.3046009100998195, 0.7440558616951546, 0.3713188114713809, 0.7964162239155386, 0.4692388391015939, 0.8884578464371699, 0.9470701380033374, 0.9826359093984686, 0.4036538055062967, 0.4758903569916251, 0.6368896662965008, 0.6326535375944107, 0.05624497624742497, 0.23864612844372612, 0.794035485378758, 0.9527557077264233, 0.8599922188051544, 0.6747355073331469, 0.20325827421209008, 0.3296874027259814, 0.9969441289658973, 0.11836507283899977, 0.7856621855129831, 0.7098668028770361, 0.7014067934291965, 0.6785430309780021, 0.13873198182783086, 0.5014945378926599, 0.6939515948767697, 0.9543629447427979, 0.06500287380605374, 0.3602157098993255, 0.3848907819099412, 0.8613813033942036, 0.2581038746166514, 0.12644101776817818, 0.8826286488643513, 0.1511524947725782, 0.20801799059962145, 0.3260109405876678, 0.4247391941725467, 0.8485390162719532, 0.39230860246893606, 0.8368342092740831, 0.7776506160165639, 0.4092417386818289, 0.867196266755543, 0.03748417867976539, 0.06902609994293407, 0.5132105960836307, 0.674780244973409, 0.6519390837436658, 0.931672144076144, 0.18135653203459468, 0.11329357383102934, 0.8674398726452301, 0.6830513443632406, 0.053449383776651094, 0.17047174356246486, 0.43972257628102585, 0.9115200260158507, 0.3650623694210249, 0.24191315642642008, 0.02499461013402915, 0.6465467586444044, 0.40144629838242707, 0.4465678667512648, 0.8512207824458602, 0.5909143122038294, 0.6815730447165786, 0.15566093150177274, 0.667515229644326, 0.1727446051424265, 0.04765481230312185, 0.17516523429775777, 0.7099737405618063, 0.8833947370809504, 0.48800904262707323, 0.45481578308834225, 0.9725345972099901, 0.6536823582705348, 0.9958433839829655, 0.8402384462186014, 0.5594363295987153, 0.9888897328315395, 0.1439110331423601, 0.9167542830398115, 0.3813658941862329, 0.5265377984332549, 0.9395909814715868, 0.0311945659714562, 0.0034193680486316325, 0.6606814855738464, 0.9555502215612812, 0.5219872735839096, 0.9033317273322757, 0.9367726567069443, 0.012046593467504252, 0.48698207078185685, 0.793828836478479, 0.8531939786216586, 0.5082340514072513, 0.5641158190106881, 0.1441530341755224, 0.256227994895172, 0.41448918844486526, 0.518450902767531, 0.3912662587952821, 0.5119389718144033, 0.291427266946661, 0.6203824015805313, 0.4640341932282972, 0.843146896095095, 0.16880568562797393, 0.6536948748099716, 0.899566629138228, 0.08384837422404234, 0.04963708826715063, 0.4881805704894333, 0.2882301178665728, 0.8394523049617305, 0.7594611770080594, 0.06229287107488812, 0.04137990224648547, 0.44890720845206167, 0.8499326100607437, 0.10514485257707773, 0.4746991207737269, 0.9939927715302109, 0.1110828235206941, 0.46769458490137905, 0.9513199520547873, 0.6731350680217113, 0.2812525469206393, 0.3222449980331369, 0.576807972429173, 0.9598582765587246, 0.4515145623224066, 0.6402688703231059, 0.9412749257066527, 0.7063543090581585, 0.5490605845413771, 0.0007519418462976768, 0.10003654270967244, 0.5686940752494414, 0.7689198739793771, 0.7142358395674934, 0.48734473580151483, 0.7370700822103077, 0.6194861916321397, 0.27479759084959865, 0.6449498629461939, 0.16326061999767716, 0.11173416253716584, 0.631186125935834, 0.08039900526185795, 0.8754587158951851, 0.38398178864770727, 0.9064229833631072, 0.8106669836119708, 0.7386204532040157, 0.9895658100584181, 0.3288933797074086, 0.47121298188175886, 0.26370173209553227, 0.3961788045551722, 0.8743600858926166, 0.881256905847435, 0.053500129306383815, 0.7876930863819013, 0.5128119772717691, 0.5582355887458503, 0.9801181602999063, 0.9077689685899102, 0.3765940019839916, 0.8923040715299023, 0.46184811979210494, 0.2025413906507294, 0.18649588191333533, 0.7006379594608094, 0.16399952348386015, 0.2519989441015198, 0.7475558371549678, 0.8156994003431439, 0.4586470693789192, 0.8315529609342334, 0.005086513938236559, 0.751824671336579, 0.5064125504084622, 0.2536616140566579, 0.15957107416240157, 0.2627896811993703, 0.6723712843613511, 0.6627314255259342, 0.2403042395734276, 0.7482993020880016, 0.1755442560900451, 0.37317147279577667, 0.9003139663903659, 0.4719568869118871, 0.6298852953590778, 0.04457998769873661, 0.9715206167972931, 0.7634739008680631, 0.17816109592041163, 0.9852263038722319, 0.35597805925696824, 0.5901744420081384, 0.08441290679715308, 0.14193700194923764, 0.5356225794560723, 0.8567775338037357, 0.4495539131354287, 0.497645591415535, 0.4431383461845253, 0.8543609067593703, 0.9864386677180004, 0.05989074724846122, 0.27095358860915664, 0.7647714783793487, 0.44211178536347473, 0.7051740857818959, 0.38517808926142316, 0.5634175928011659, 0.026691350515270273, 0.9494586281848088, 0.24660953316485335, 0.6846282745710437, 0.46622562195338624, 0.20735726366275298, 0.3393628263531724, 0.5807188292124388, 0.270742859196755, 0.7920967152577583, 0.6079423191873988, 0.11440023125812748, 0.44594779080422453, 0.706264839016185, 0.7840592166910791, 0.8905723126468816, 0.2973161546394, 0.3616527137647889, 0.6078755627903863, 0.9825857219735905, 0.36084424190517905, 0.6561663217899537, 0.07292025375567013, 0.35315152228183067, 0.7232023027823197, 0.6051630819248766, 0.04103228431235584, 0.8144026832282424, 0.8043947769640873, 0.4419084590079436, 0.2621440371967141, 0.6527228946358511, 0.5523098606915057, 0.18670751191497192, 0.8710054010827031, 0.1833141630218703, 0.059206960055707136, 0.49887616408846547, 0.6753412443550969, 0.19532871067299462, 0.1861937221016159, 0.3435198193925024, 0.06077339070521637, 0.9263606673939231, 0.05807914737553088, 0.2675699676734986, 0.5062899807034598, 0.8135142196969114, 0.36357817290139793, 0.4204213914373425, 0.5161687873763312, 0.11534697329216004, 0.6677730173727874, 0.9797171365497892, 0.043275159962880116, 0.48057518215774464, 0.26819517282009675, 0.4458869223708748, 0.10343426280227574, 0.13211230896086368, 0.4058691473164582, 0.7341660195954186, 0.7033636256647512, 0.5219332124788525, 0.5375007099978802, 0.17573759209256412, 0.8333004505979321, 0.9194771132856144, 0.9609385649510064, 0.591102299015357, 0.8762089720502054, 0.6863726704911753, 0.262577222327419, 0.401574415728955, 0.7574275895328939, 0.16056063431035583, 0.9137315914518571, 0.5974675693555229, 0.033135223472026354, 0.6254131241507288, 0.6472366797192719, 0.9729573151707352, 0.34381233975597814, 0.051200549510616256, 0.7727995772224758, 0.1320427601802544, 0.8294845555249736, 0.019105494339939244, 0.639374837828608, 0.531933380238744, 0.32483341609161875, 0.21804419215613224, 0.10100702966612096, 0.5237220218819775, 0.6393253579125417, 0.21612199254085662, 0.4017890985793152, 0.7027408776891577, 0.1953001392343745, 0.592770703655264, 0.7747290245420908, 0.9302660774329784, 0.569402838789524, 0.8594446812625749, 0.08906440877053501, 0.43481761994251833, 0.8547321407383849, 0.8235536251747902, 0.421942343269714, 0.7780557539681974, 0.4778571929485247, 0.536739743564104, 0.711821733294596, 0.12134857044863434, 0.5139665316985287, 0.396825353394192, 0.816616540169721, 0.1316604603891265, 0.905780441093181, 0.3926767116761475, 0.8667378042466876, 0.4471299501589865, 0.5914177648206993, 0.6460350945011707, 0.6109194460341577, 0.7173543498905, 0.1825756274758561, 0.5899732301654995, 0.5564682161041468, 0.5218534339784013, 0.8030877292854788, 0.6267633349830104, 0.5996032645263469, 0.8886865497216093, 0.3881274595590877, 0.5835930776089039, 0.09004191539552686, 0.15454037799608777, 0.47575979677914726, 0.9705166812157813, 0.8165386341875303, 0.44161581667639305, 0.9297278095857905, 0.7562910124265927, 0.49069328666235346, 0.7127711468815353, 0.35997540350039015, 0.4972417007419673, 0.9974781195742214, 0.07190023977002824, 0.26719262071745864, 0.026380520985266553, 0.8491605609269333, 0.4560359454961772, 0.04480422077021595, 0.35220457385863524, 0.04156875908014179, 0.5452227374169658, 0.2349328683926324, 0.5749685012050447, 0.6164402467749501, 0.23202719444498165, 0.04223564894552623, 0.12158274950334946, 0.7743220745946288, 0.004023805888660581, 0.07479224593600564, 0.5576428488992362, 0.710985249790041, 0.7869545043838508, 0.2596792920742874, 0.06755667472572535, 0.9950214106225276, 0.8009578341886959, 0.10085374537272651, 0.026239524453910867, 0.7972514165796074, 0.3768478516642376, 0.33072222319102285, 0.12215042354945616, 0.12046408809130482, 0.8905996708808399, 0.949248987906387, 0.33205415359048196, 0.004578788193541183, 0.6745290373709396, 0.8023248905386212, 0.1796523714702789, 0.7907268477255717, 0.1883585178655579, 0.045287276026371504, 0.30053398113811514, 0.7303741343686346, 0.9628147939837401, 0.02748158871901607, 0.005890343775777462, 0.9095253480030305, 0.06514006307446918, 0.23253338418664993, 0.17310706426642242, 0.36785554106802765, 0.8566001286349054, 0.5581806492628892, 0.9955482478684005, 0.8836173675621545, 0.7699578598500069, 0.06721574449225531]\n"
     ]
    }
   ],
   "source": [
    "new_pred = []\n",
    "\n",
    "for nid in list(set(test_data.news_id.values)):\n",
    "    indices = list(test_data[test_data.news_id == nid].index)\n",
    "    if len(indices) == 1:\n",
    "        new_pred.append(predictions[indices[0]])\n",
    "    else:\n",
    "        new_pred.append(sum([predictions[i] for i in indices])/len(indices))\n",
    "\n",
    "print(len(new_pred), new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49329123914759276\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for p in new_pred:\n",
    "    if p > 0.5:\n",
    "        c = c+1\n",
    "        \n",
    "print(c/len(new_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_news(in_kaggle=False):\n",
    "    kaggle_path = '/kaggle/input/fake-and-real-news-dataset/Processed_news.csv'\n",
    "    jupyter_path = 'data/fake-and-real-news-dataset/Processed_news.csv'\n",
    "\n",
    "    path = kaggle_path if in_kaggle else jupyter_path\n",
    "    \n",
    "    clean_data = pd.read_csv(path)\n",
    "    X = clean_data.clean_text.values\n",
    "    y = np.array([[1, 0] if category==1 else [0, 1] for category in clean_data.category.values])\n",
    "\n",
    "    # Train 70% Validation 10% Test 20%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=21)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=21)\n",
    "    \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test\n",
    "\n",
    "def load_liar_news(in_kaggle=False):\n",
    "    #kaggle_path = '/kaggle/input/fake-and-real-news-dataset/Processed_news.csv'\n",
    "    train_path = 'data/liar_dataset/Processed_train.csv'\n",
    "    valid_path = 'data/liar_dataset/Processed_valid.csv'\n",
    "    test_path = 'data/liar_dataset/Processed_test.csv'\n",
    "    \n",
    "    #path = kaggle_path if in_kaggle else jupyter_path\n",
    "    \n",
    "    train_data = pd.read_csv(train_path)\n",
    "    valid_data = pd.read_csv(valid_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    \n",
    "    X_train, X_valid, X_test = train_data.clean_text.values, valid_data.clean_text.values, test_data.clean_text.values\n",
    "    y_train = np.array([[1, 0] if category==1 else [0, 1] for category in train_data.category.values])\n",
    "    y_valid = np.array([[1, 0] if category==1 else [0, 1] for category in valid_data.category.values])\n",
    "    y_test = np.array([[1, 0] if category==1 else [0, 1] for category in test_data.category.values])\n",
    "        \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test\n",
    "\n",
    "\n",
    "# Load real-fake-news\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = load_news()\n",
    "\n",
    "# Load real-fake-news\n",
    "X_train_liar, X_valid, X_test, y_train, y_valid, y_test = load_liar_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='OOV')\n",
    "tokenizer.fit_on_texts(X_train_liar)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "embedding_matrix = np.zeros((max_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    if i == max_words-1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22556999,  0.49417999,  0.48609999, -0.4332    ,  0.13738   ,\n",
       "        0.50616997,  0.26058   ,  0.30103001, -0.091486  ,  0.10876   ,\n",
       "        0.30579999,  0.051028  ,  0.22303   ,  0.054236  ,  0.068838  ,\n",
       "       -0.24700999,  0.32688999, -0.082203  , -0.28865999,  0.3734    ,\n",
       "        0.73803997, -0.040969  ,  0.040201  ,  0.11384   ,  0.69986999,\n",
       "       -0.49744999, -0.06755   , -0.42598999, -0.10725   , -0.010697  ,\n",
       "       -0.01479   ,  0.55975997,  0.3064    ,  0.053053  ,  0.058034  ,\n",
       "        0.32756001, -0.37233001,  0.46513   ,  0.14285   , -0.085003  ,\n",
       "       -0.45475999,  0.19773   ,  0.6383    , -0.31147999,  0.10858   ,\n",
       "        0.31557   ,  0.36682001, -0.35135001, -0.48414001, -0.33234999,\n",
       "       -0.33816001, -0.39678001,  0.1908    ,  1.3513    , -0.39043999,\n",
       "       -2.87949991, -0.14275999, -0.087754  ,  1.77129996,  0.99331999,\n",
       "       -0.14128999,  0.94388998,  0.050897  ,  0.47373   ,  0.86387002,\n",
       "       -0.16162001,  0.67198998,  0.52344   ,  0.14438   , -0.055194  ,\n",
       "       -0.34669   , -0.20742001,  0.18907   , -0.19845   ,  0.34862   ,\n",
       "        0.10121   , -0.092119  , -0.66258001, -1.0582    , -0.11803   ,\n",
       "        0.70170999,  0.077776  , -0.50546002,  0.032243  , -1.61759996,\n",
       "       -0.29302001, -0.061748  , -0.32473001,  0.3439    , -0.44698   ,\n",
       "        0.085689  ,  0.13294999, -0.1807    , -0.11854   , -0.82985002,\n",
       "        0.13784   , -0.34358999, -0.45743999,  0.49645999,  0.34906   ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22556999,  0.49417999,  0.48609999, -0.4332    ,  0.13738   ,\n",
       "        0.50616997,  0.26058   ,  0.30103001, -0.091486  ,  0.10876   ,\n",
       "        0.30579999,  0.051028  ,  0.22303   ,  0.054236  ,  0.068838  ,\n",
       "       -0.24700999,  0.32688999, -0.082203  , -0.28865999,  0.3734    ,\n",
       "        0.73803997, -0.040969  ,  0.040201  ,  0.11384   ,  0.69986999,\n",
       "       -0.49744999, -0.06755   , -0.42598999, -0.10725   , -0.010697  ,\n",
       "       -0.01479   ,  0.55975997,  0.3064    ,  0.053053  ,  0.058034  ,\n",
       "        0.32756001, -0.37233001,  0.46513   ,  0.14285   , -0.085003  ,\n",
       "       -0.45475999,  0.19773   ,  0.6383    , -0.31147999,  0.10858   ,\n",
       "        0.31557   ,  0.36682001, -0.35135001, -0.48414001, -0.33234999,\n",
       "       -0.33816001, -0.39678001,  0.1908    ,  1.3513    , -0.39043999,\n",
       "       -2.87949991, -0.14275999, -0.087754  ,  1.77129996,  0.99331999,\n",
       "       -0.14128999,  0.94388998,  0.050897  ,  0.47373   ,  0.86387002,\n",
       "       -0.16162001,  0.67198998,  0.52344   ,  0.14438   , -0.055194  ,\n",
       "       -0.34669   , -0.20742001,  0.18907   , -0.19845   ,  0.34862   ,\n",
       "        0.10121   , -0.092119  , -0.66258001, -1.0582    , -0.11803   ,\n",
       "        0.70170999,  0.077776  , -0.50546002,  0.032243  , -1.61759996,\n",
       "       -0.29302001, -0.061748  , -0.32473001,  0.3439    , -0.44698   ,\n",
       "        0.085689  ,  0.13294999, -0.1807    , -0.11854   , -0.82985002,\n",
       "        0.13784   , -0.34358999, -0.45743999,  0.49645999,  0.34906   ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save('embedding_matrix_liar_news.npy', embedding_matrix) # save\n",
    "new_num_arr = np.load('embedding_matrix_liar_news.npy') # load\n",
    "new_num_arr[15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
