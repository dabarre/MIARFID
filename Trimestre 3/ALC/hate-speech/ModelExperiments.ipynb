{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Concatenate\n",
    "from keras.layers import Embedding, LSTM, Bidirectional, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from keras.callbacks import LearningRateScheduler as LRS\n",
    "from keras.models import load_model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from transformers import TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_callbacks(model_id, kpi_to_monitor='val_accuracy'):\n",
    "    # Without log/ or models/ subfolder as not possible to access unexisting folders\n",
    "    # If possible to train with jupyter revise\n",
    "    path = \"models\"\n",
    "    name = \"ap\"\n",
    "    \n",
    "    log_filename = '%s/%s-%s.log' % (path,name, model_id)\n",
    "    csv_logger = CSVLogger(log_filename)\n",
    "    \n",
    "    chk_1_model_filename = '%s/%s-%s-{epoch:04d}-{%s:.6f}.h5' % (path, name, model_id, kpi_to_monitor)\n",
    "    chk_2_model_filename = '%s/%s-%s.h5' % (path, name, model_id)\n",
    "    \n",
    "    # Save best model fully not only weights after each epoch (period=1) \n",
    "    # with best accuracy value (mode=max, save_best_only=True)\n",
    "    checkpoint1 = ModelCheckpoint(\n",
    "        chk_1_model_filename,\n",
    "        monitor=kpi_to_monitor,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False, \n",
    "        verbose=1, mode='max', period=1\n",
    "    )\n",
    "\n",
    "    checkpoint2 = ModelCheckpoint(\n",
    "        chk_2_model_filename, \n",
    "        monitor=kpi_to_monitor,\n",
    "        save_best_only=False,\n",
    "        save_weights_only=False, \n",
    "        verbose=1, mode='auto', period=1\n",
    "    )\n",
    "\n",
    "    callbacks = [csv_logger, checkpoint1, checkpoint2]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### AUTHOR PROFILING FUNCTION FOR JOINING PREDICTIONS #########\n",
    "\n",
    "# de 20 0s y 20 1s\n",
    "\n",
    "def author_profiling_report(author_predictions, number_authors=40):\n",
    "    n = int(number_authors/2)\n",
    "    a = np.zeros(n)\n",
    "    b = np.ones(n)        \n",
    "    author_profile = np.concatenate([a,b])\n",
    "    \n",
    "    # Check author profiling -> 8,000 predictions\n",
    "    # Split into 40 authors -> 200 tweets per author\n",
    "    author_predictions = np.average(np.array_split(author_predictions, number_authors), axis=1)\n",
    "    author_predictions = np.array([1 if ap >= 0.5 else 0 for ap in author_predictions])\n",
    "\n",
    "    print(classification_report(author_profile, author_predictions, labels=[0, 1], target_names=['not hate','hate']))\n",
    "    return author_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open('es_indv.pickle', 'rb')\n",
    "es_indv = pickle.load(pickle_file)\n",
    "\n",
    "embedding_matrix_es_indv = es_indv[0]\n",
    "train_padded_es_indv, y_train_es_indv = es_indv[1], es_indv[2]\n",
    "valid_padded_es_indv, y_valid_es_indv = es_indv[3], es_indv[4]\n",
    "test_padded_es_indv = es_indv[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open('en_indv.pickle', 'rb')\n",
    "en_indv = pickle.load(pickle_file)\n",
    "\n",
    "embedding_matrix_en_indv = en_indv[0]\n",
    "train_padded_en_indv, y_train_en_indv = en_indv[1], en_indv[2]\n",
    "valid_padded_en_indv, y_valid_en_indv = en_indv[3], en_indv[4]\n",
    "test_padded_en_indv = en_indv[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open('es_20.pickle', 'rb')\n",
    "es_20 = pickle.load(pickle_file)\n",
    "\n",
    "train_padded_es_20, y_train_es_20 = es_20[0], es_20[1]\n",
    "valid_padded_es_20, y_valid_es_20 = es_20[2], es_20[3]\n",
    "test_padded_es_20 = es_20[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open('en_20.pickle', 'rb')\n",
    "en_20 = pickle.load(pickle_file)\n",
    "\n",
    "train_padded_en_20, y_train_en_20 = en_20[0], en_20[1]\n",
    "valid_padded_en_20, y_valid_en_20 = en_20[2], en_20[3]\n",
    "test_padded_en_20 = en_20[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open('es_cml.pickle', 'rb')\n",
    "es_cml = pickle.load(pickle_file)\n",
    "\n",
    "x_train_es, y_train_es = es_cml[0], es_cml[1]\n",
    "x_valid_es, y_valid_es = es_cml[2], es_cml[3]\n",
    "x_test_es = es_cml[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open('en_cml.pickle', 'rb')\n",
    "en_cml = pickle.load(pickle_file)\n",
    "\n",
    "x_train_en, y_train_en = en_cml[0], en_cml[1]\n",
    "x_valid_en, y_valid_en = en_cml[2], en_cml[3]\n",
    "x_test_en = en_cml[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open('es_indv_bert.pickle', 'rb')\n",
    "es_indv_bert = pickle.load(pickle_file)\n",
    "\n",
    "train_padded_es_indv_bert, train_mask_es_indv, y_train_es = es_indv_bert[0], es_indv_bert[1], es_indv_bert[2]\n",
    "valid_padded_es_indv_bert, valid_mask_es_indv, y_valid_es = es_indv_bert[3], es_indv_bert[4], es_indv_bert[5]\n",
    "test_padded_es_indv_bert, test_mask_es_indv = es_indv_bert[6], es_indv_bert[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open('es_20_bert.pickle', 'rb')\n",
    "es_20_bert = pickle.load(pickle_file)\n",
    "\n",
    "train_padded_es_20_bert, train_mask_es_20, y_train_es = es_20_bert[0], es_20_bert[1], es_20_bert[2]\n",
    "valid_padded_es_20_bert, valid_mask_es_20, y_valid_es = es_20_bert[3], es_20_bert[4], es_20_bert[5]\n",
    "test_padded_es_20_bert, test_mask_es_20 = es_20_bert[6], es_20_bert[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### RNN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Individual tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 15, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,219,777\n",
      "Trainable params: 219,777\n",
      "Non-trainable params: 3,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES INDVIDUAL TWEETS - PRETRAINED EMB\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 15\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    weights=[embedding_matrix_es_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=False,\n",
    "                    mask_zero=True))\n",
    "model1.add(LSTM(units=128))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.6459 - accuracy: 0.6225 - val_loss: 0.6677 - val_accuracy: 0.5984\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.6414 - accuracy: 0.6263 - val_loss: 0.6634 - val_accuracy: 0.6168\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 0.6352 - accuracy: 0.6346 - val_loss: 0.6615 - val_accuracy: 0.6090\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.6310 - accuracy: 0.6389 - val_loss: 0.6691 - val_accuracy: 0.6070\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.6270 - accuracy: 0.6474 - val_loss: 0.6619 - val_accuracy: 0.6047\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.6252 - accuracy: 0.6448 - val_loss: 0.6606 - val_accuracy: 0.6169\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.6207 - accuracy: 0.6518 - val_loss: 0.6687 - val_accuracy: 0.6056\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.6160 - accuracy: 0.6568 - val_loss: 0.6760 - val_accuracy: 0.6003\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.6131 - accuracy: 0.6571 - val_loss: 0.6864 - val_accuracy: 0.5840\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.6065 - accuracy: 0.6643 - val_loss: 0.6691 - val_accuracy: 0.6110\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.6026 - accuracy: 0.6674 - val_loss: 0.6614 - val_accuracy: 0.6212\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.5950 - accuracy: 0.6747 - val_loss: 0.6735 - val_accuracy: 0.6029\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.5869 - accuracy: 0.6809 - val_loss: 0.6930 - val_accuracy: 0.5980\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.5783 - accuracy: 0.6901 - val_loss: 0.7142 - val_accuracy: 0.6018\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.5688 - accuracy: 0.6973 - val_loss: 0.6964 - val_accuracy: 0.6096\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.5559 - accuracy: 0.7072 - val_loss: 0.7371 - val_accuracy: 0.5907\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.5424 - accuracy: 0.7171 - val_loss: 0.7242 - val_accuracy: 0.5909\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.5280 - accuracy: 0.7273 - val_loss: 0.7431 - val_accuracy: 0.5867\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.5119 - accuracy: 0.7423 - val_loss: 0.7781 - val_accuracy: 0.5864\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.4945 - accuracy: 0.7522 - val_loss: 0.7880 - val_accuracy: 0.5716\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.4784 - accuracy: 0.7648 - val_loss: 0.8036 - val_accuracy: 0.5891\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.4588 - accuracy: 0.7756 - val_loss: 0.8173 - val_accuracy: 0.5773\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.4394 - accuracy: 0.7904 - val_loss: 0.8519 - val_accuracy: 0.5815\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.4195 - accuracy: 0.8022 - val_loss: 0.8673 - val_accuracy: 0.5830\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.4003 - accuracy: 0.8128 - val_loss: 0.9155 - val_accuracy: 0.5810\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.86      0.60      0.71        20\n",
      "        hate       0.69      0.90      0.78        20\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.77      0.75      0.74        40\n",
      "weighted avg       0.77      0.75      0.74        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1.fit(x=train_padded_es_indv,\n",
    "          y=y_train_es_indv,\n",
    "          validation_data=(valid_padded_es_indv, y_valid_es_indv),\n",
    "          shuffle=True,\n",
    "          epochs=25,\n",
    "          batch_size=64)\n",
    "\n",
    "predictions = model1.predict(valid_padded_es_indv)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 15, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,219,777\n",
      "Trainable params: 3,219,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES INDVIDUAL TWEETS - PRETRAINED EMB TRAINABLE\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 15\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    weights=[embedding_matrix_es_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=True,\n",
    "                    mask_zero=True))\n",
    "model2.add(LSTM(units=128))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6300 - accuracy: 0.6343 - val_loss: 0.6731 - val_accuracy: 0.6060\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.4900 - accuracy: 0.7618 - val_loss: 0.6989 - val_accuracy: 0.6112\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.3905 - accuracy: 0.8190 - val_loss: 0.8267 - val_accuracy: 0.5989\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.3098 - accuracy: 0.8591 - val_loss: 1.0365 - val_accuracy: 0.5885\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.2417 - accuracy: 0.8932 - val_loss: 1.2318 - val_accuracy: 0.5864\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.1867 - accuracy: 0.9196 - val_loss: 1.5532 - val_accuracy: 0.5781\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.1462 - accuracy: 0.9357 - val_loss: 1.7653 - val_accuracy: 0.5778\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.1126 - accuracy: 0.9504 - val_loss: 2.1769 - val_accuracy: 0.5776\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0906 - accuracy: 0.9610 - val_loss: 2.3617 - val_accuracy: 0.5745\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0754 - accuracy: 0.9677 - val_loss: 2.7711 - val_accuracy: 0.5745\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0635 - accuracy: 0.9720 - val_loss: 2.9531 - val_accuracy: 0.5738\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0562 - accuracy: 0.9757 - val_loss: 3.1004 - val_accuracy: 0.5731\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0465 - accuracy: 0.9801 - val_loss: 3.4800 - val_accuracy: 0.5739\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0418 - accuracy: 0.9822 - val_loss: 3.5524 - val_accuracy: 0.5663\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0365 - accuracy: 0.9854 - val_loss: 3.6399 - val_accuracy: 0.5751\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0346 - accuracy: 0.9862 - val_loss: 3.4865 - val_accuracy: 0.5689\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.0294 - accuracy: 0.9876 - val_loss: 3.6942 - val_accuracy: 0.5669\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0266 - accuracy: 0.9888 - val_loss: 3.6837 - val_accuracy: 0.5689\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0266 - accuracy: 0.9887 - val_loss: 3.8309 - val_accuracy: 0.5710\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0231 - accuracy: 0.9905 - val_loss: 3.9777 - val_accuracy: 0.5700\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0210 - accuracy: 0.9911 - val_loss: 3.7756 - val_accuracy: 0.5749\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.0196 - accuracy: 0.9916 - val_loss: 3.9894 - val_accuracy: 0.5679\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0163 - accuracy: 0.9927 - val_loss: 4.3140 - val_accuracy: 0.5680\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0159 - accuracy: 0.9930 - val_loss: 4.0809 - val_accuracy: 0.5695\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.0149 - accuracy: 0.9932 - val_loss: 4.0264 - val_accuracy: 0.5706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.83      0.75      0.79        20\n",
      "        hate       0.77      0.85      0.81        20\n",
      "\n",
      "    accuracy                           0.80        40\n",
      "   macro avg       0.80      0.80      0.80        40\n",
      "weighted avg       0.80      0.80      0.80        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2.fit(x=train_padded_es_indv,\n",
    "          y=y_train_es_indv,\n",
    "          validation_data=(valid_padded_es_indv, y_valid_es_indv),\n",
    "          shuffle=True,\n",
    "          epochs=25,\n",
    "          batch_size=64)\n",
    "\n",
    "predictions = model2.predict(valid_padded_es_indv)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 15, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,219,777\n",
      "Trainable params: 3,219,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES INDVIDUAL TWEETS - TRAINABLE EMB\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 15\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    #weights=[embedding_matrix_es_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=True, # Changed to True\n",
    "                    mask_zero=True))\n",
    "model3.add(LSTM(units=128))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.6093 - accuracy: 0.6670 - val_loss: 0.6463 - val_accuracy: 0.6360\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.4912 - accuracy: 0.7613 - val_loss: 0.6960 - val_accuracy: 0.6210\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.3928 - accuracy: 0.8133 - val_loss: 0.8568 - val_accuracy: 0.6104\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.3115 - accuracy: 0.8546 - val_loss: 1.1021 - val_accuracy: 0.5999\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.2449 - accuracy: 0.8865 - val_loss: 1.3074 - val_accuracy: 0.5994\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.1932 - accuracy: 0.9117 - val_loss: 1.5461 - val_accuracy: 0.5924\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.1539 - accuracy: 0.9308 - val_loss: 1.8436 - val_accuracy: 0.5882\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.1201 - accuracy: 0.9465 - val_loss: 2.2400 - val_accuracy: 0.5961\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.0980 - accuracy: 0.9567 - val_loss: 2.1692 - val_accuracy: 0.5845\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0791 - accuracy: 0.9657 - val_loss: 2.5500 - val_accuracy: 0.5840\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0679 - accuracy: 0.9716 - val_loss: 2.9113 - val_accuracy: 0.5929\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0577 - accuracy: 0.9754 - val_loss: 2.7507 - val_accuracy: 0.5930\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0497 - accuracy: 0.9796 - val_loss: 2.8735 - val_accuracy: 0.5885\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0407 - accuracy: 0.9837 - val_loss: 3.4228 - val_accuracy: 0.5899\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 15s 31ms/step - loss: 0.0412 - accuracy: 0.9834 - val_loss: 3.2942 - val_accuracy: 0.5809\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0359 - accuracy: 0.9856 - val_loss: 3.2571 - val_accuracy: 0.5771\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0337 - accuracy: 0.9861 - val_loss: 3.3273 - val_accuracy: 0.5821\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0247 - accuracy: 0.9901 - val_loss: 3.6562 - val_accuracy: 0.5763\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0234 - accuracy: 0.9904 - val_loss: 3.5619 - val_accuracy: 0.5846\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0219 - accuracy: 0.9910 - val_loss: 3.5995 - val_accuracy: 0.5842\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0200 - accuracy: 0.9912 - val_loss: 3.9494 - val_accuracy: 0.5798\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0248 - accuracy: 0.9896 - val_loss: 3.3505 - val_accuracy: 0.5886\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0200 - accuracy: 0.9918 - val_loss: 3.8210 - val_accuracy: 0.5829\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0178 - accuracy: 0.9920 - val_loss: 3.7324 - val_accuracy: 0.5790\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.0191 - accuracy: 0.9919 - val_loss: 3.6997 - val_accuracy: 0.5813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.79      0.75      0.77        20\n",
      "        hate       0.76      0.80      0.78        20\n",
      "\n",
      "    accuracy                           0.78        40\n",
      "   macro avg       0.78      0.78      0.77        40\n",
      "weighted avg       0.78      0.78      0.77        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3.fit(x=train_padded_es_indv,\n",
    "          y=y_train_es_indv,\n",
    "          validation_data=(valid_padded_es_indv, y_valid_es_indv),\n",
    "          shuffle=True,\n",
    "          epochs=25,\n",
    "          batch_size=64)\n",
    "\n",
    "predictions = model3.predict(valid_padded_es_indv)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 15, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               439296    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,439,553\n",
      "Trainable params: 3,439,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES INDVIDUAL TWEETS - TRAINABLE EMB BI\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 15\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    #weights=[embedding_matrix_en_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=True, # Changed to True\n",
    "                    mask_zero=True))\n",
    "model4.add(Bidirectional(LSTM(units=128, dropout=0.05, recurrent_dropout=0.2)))\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.6056 - accuracy: 0.6709 - val_loss: 0.6424 - val_accuracy: 0.6382\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.4906 - accuracy: 0.7616 - val_loss: 0.6902 - val_accuracy: 0.6208\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.3831 - accuracy: 0.8242 - val_loss: 0.7782 - val_accuracy: 0.6033\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.2830 - accuracy: 0.8733 - val_loss: 1.0891 - val_accuracy: 0.5899\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.2025 - accuracy: 0.9088 - val_loss: 1.3936 - val_accuracy: 0.5896\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.1465 - accuracy: 0.9371 - val_loss: 1.7412 - val_accuracy: 0.5859\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.1105 - accuracy: 0.9537 - val_loss: 2.1149 - val_accuracy: 0.5822\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0862 - accuracy: 0.9642 - val_loss: 2.4908 - val_accuracy: 0.5824\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0691 - accuracy: 0.9714 - val_loss: 2.5101 - val_accuracy: 0.5792\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0575 - accuracy: 0.9770 - val_loss: 2.8510 - val_accuracy: 0.5785\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0496 - accuracy: 0.9801 - val_loss: 3.0187 - val_accuracy: 0.5784\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0434 - accuracy: 0.9829 - val_loss: 3.0964 - val_accuracy: 0.5830\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0384 - accuracy: 0.9844 - val_loss: 3.2908 - val_accuracy: 0.5801\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0320 - accuracy: 0.9870 - val_loss: 3.5400 - val_accuracy: 0.5796\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0314 - accuracy: 0.9880 - val_loss: 3.4806 - val_accuracy: 0.5796\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0269 - accuracy: 0.9895 - val_loss: 3.6802 - val_accuracy: 0.5794\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0224 - accuracy: 0.9912 - val_loss: 4.0669 - val_accuracy: 0.5704\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 3.8736 - val_accuracy: 0.5804\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0274 - accuracy: 0.9898 - val_loss: 3.7906 - val_accuracy: 0.5770\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 4.0818 - val_accuracy: 0.5730\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0193 - accuracy: 0.9923 - val_loss: 3.8445 - val_accuracy: 0.5784\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0173 - accuracy: 0.9931 - val_loss: 3.9706 - val_accuracy: 0.5750\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0146 - accuracy: 0.9944 - val_loss: 4.2318 - val_accuracy: 0.5806\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0133 - accuracy: 0.9944 - val_loss: 4.4437 - val_accuracy: 0.5806\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.0149 - accuracy: 0.9937 - val_loss: 4.3374 - val_accuracy: 0.5735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.79      0.75      0.77        20\n",
      "        hate       0.76      0.80      0.78        20\n",
      "\n",
      "    accuracy                           0.78        40\n",
      "   macro avg       0.78      0.78      0.77        40\n",
      "weighted avg       0.78      0.78      0.77        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model4.fit(x=train_padded_es_indv,\n",
    "          y=y_train_es_indv,\n",
    "          validation_data=(valid_padded_es_indv, y_valid_es_indv),\n",
    "          shuffle=True,\n",
    "          epochs=25,\n",
    "          batch_size=64)\n",
    "\n",
    "predictions = model4.predict(valid_padded_es_indv)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 15, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 15, 128)           219648    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 15, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 15, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,614,529\n",
      "Trainable params: 3,614,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES INDVIDUAL TWEETS - TRAINABLE EMB COMPLEXER NET\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 15\n",
    "\n",
    "model7 = Sequential()\n",
    "model7.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    #weights=[embedding_matrix_en_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=True, # Changed to True\n",
    "                    mask_zero=True))\n",
    "model7.add(LSTM(units=128, return_sequences=True))\n",
    "model7.add(LSTM(units=128, return_sequences=True))\n",
    "model7.add(LSTM(units=128, return_sequences=True))\n",
    "model7.add(LSTM(units=128))\n",
    "model7.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model7.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.6173 - accuracy: 0.6593 - val_loss: 0.6624 - val_accuracy: 0.6321\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 22s 44ms/step - loss: 0.5071 - accuracy: 0.7532 - val_loss: 0.6862 - val_accuracy: 0.6198\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 22s 44ms/step - loss: 0.4177 - accuracy: 0.8063 - val_loss: 0.7704 - val_accuracy: 0.6125\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 23s 46ms/step - loss: 0.3297 - accuracy: 0.8486 - val_loss: 0.9657 - val_accuracy: 0.6031\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 23s 45ms/step - loss: 0.2583 - accuracy: 0.8825 - val_loss: 1.1541 - val_accuracy: 0.5919\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 23s 45ms/step - loss: 0.2025 - accuracy: 0.9087 - val_loss: 1.3288 - val_accuracy: 0.5885\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 23s 46ms/step - loss: 0.1537 - accuracy: 0.9313 - val_loss: 1.8212 - val_accuracy: 0.5864\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 23s 46ms/step - loss: 0.1247 - accuracy: 0.9436 - val_loss: 1.9131 - val_accuracy: 0.5835\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 23s 46ms/step - loss: 0.1011 - accuracy: 0.9556 - val_loss: 1.9381 - val_accuracy: 0.5841\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 22s 45ms/step - loss: 0.0813 - accuracy: 0.9635 - val_loss: 2.6576 - val_accuracy: 0.5850\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 22s 43ms/step - loss: 0.0701 - accuracy: 0.9691 - val_loss: 2.2978 - val_accuracy: 0.5785\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.0600 - accuracy: 0.9734 - val_loss: 2.7173 - val_accuracy: 0.5859\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0496 - accuracy: 0.9781 - val_loss: 2.3442 - val_accuracy: 0.5780\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0448 - accuracy: 0.9802 - val_loss: 2.7397 - val_accuracy: 0.5846\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.0412 - accuracy: 0.9825 - val_loss: 2.4818 - val_accuracy: 0.5844\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0359 - accuracy: 0.9850 - val_loss: 3.1131 - val_accuracy: 0.5893\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.0328 - accuracy: 0.9858 - val_loss: 2.8580 - val_accuracy: 0.5916\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 22s 45ms/step - loss: 0.0284 - accuracy: 0.9881 - val_loss: 2.7098 - val_accuracy: 0.5855\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 22s 44ms/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 2.8450 - val_accuracy: 0.5854\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 23s 45ms/step - loss: 0.0259 - accuracy: 0.9892 - val_loss: 2.8365 - val_accuracy: 0.5816\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0253 - accuracy: 0.9892 - val_loss: 2.6505 - val_accuracy: 0.5847\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.0207 - accuracy: 0.9910 - val_loss: 3.1418 - val_accuracy: 0.5798\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0188 - accuracy: 0.9921 - val_loss: 2.9484 - val_accuracy: 0.5860\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0176 - accuracy: 0.9924 - val_loss: 3.2251 - val_accuracy: 0.5831\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0180 - accuracy: 0.9925 - val_loss: 2.7296 - val_accuracy: 0.5847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.75      0.75      0.75        20\n",
      "        hate       0.75      0.75      0.75        20\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.75      0.75      0.75        40\n",
      "weighted avg       0.75      0.75      0.75        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model7.fit(x=train_padded_es_indv,\n",
    "          y=y_train_es_indv,\n",
    "          validation_data=(valid_padded_es_indv, y_valid_es_indv),\n",
    "          shuffle=True,\n",
    "          epochs=25,\n",
    "          batch_size=64)\n",
    "\n",
    "predictions = model7.predict(valid_padded_es_indv)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 15, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 15, 512)           1665024   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 15, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 15, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 15, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,062,337\n",
      "Trainable params: 13,062,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES INDVIDUAL TWEETS - TRAINABLE EMB COMPLEXER NET\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 15\n",
    "\n",
    "model8 = Sequential()\n",
    "model8.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    #weights=[embedding_matrix_en_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=True, # Changed to True\n",
    "                    mask_zero=True))\n",
    "model8.add(LSTM(units=512, return_sequences=True))\n",
    "model8.add(LSTM(units=512, return_sequences=True))\n",
    "model8.add(LSTM(units=512, return_sequences=True))\n",
    "model8.add(LSTM(units=512, return_sequences=True))\n",
    "model8.add(LSTM(units=512))\n",
    "model8.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model8.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "500/500 [==============================] - 92s 183ms/step - loss: 0.6270 - accuracy: 0.6522 - val_loss: 0.6574 - val_accuracy: 0.6274\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.5165 - accuracy: 0.7510 - val_loss: 0.6930 - val_accuracy: 0.6159\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.4273 - accuracy: 0.8031 - val_loss: 0.7910 - val_accuracy: 0.6131\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.3407 - accuracy: 0.8481 - val_loss: 0.9331 - val_accuracy: 0.6043\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.2695 - accuracy: 0.8816 - val_loss: 0.9980 - val_accuracy: 0.5949\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.2109 - accuracy: 0.9087 - val_loss: 1.2438 - val_accuracy: 0.6014\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.1625 - accuracy: 0.9307 - val_loss: 1.7539 - val_accuracy: 0.5960\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.1335 - accuracy: 0.9441 - val_loss: 1.6710 - val_accuracy: 0.5907\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.1039 - accuracy: 0.9573 - val_loss: 1.7437 - val_accuracy: 0.5926\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0903 - accuracy: 0.9620 - val_loss: 1.7786 - val_accuracy: 0.5841\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0732 - accuracy: 0.9693 - val_loss: 2.1286 - val_accuracy: 0.5903\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0625 - accuracy: 0.9742 - val_loss: 2.1688 - val_accuracy: 0.5905\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0516 - accuracy: 0.9782 - val_loss: 2.5238 - val_accuracy: 0.5813\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0481 - accuracy: 0.9800 - val_loss: 2.3782 - val_accuracy: 0.5913\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0408 - accuracy: 0.9832 - val_loss: 2.3276 - val_accuracy: 0.5796\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0428 - accuracy: 0.9822 - val_loss: 2.3327 - val_accuracy: 0.5792\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0351 - accuracy: 0.9858 - val_loss: 2.4549 - val_accuracy: 0.5806\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0312 - accuracy: 0.9872 - val_loss: 2.8675 - val_accuracy: 0.5853\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0265 - accuracy: 0.9893 - val_loss: 2.6554 - val_accuracy: 0.5889\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0253 - accuracy: 0.9900 - val_loss: 2.6941 - val_accuracy: 0.5880\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0239 - accuracy: 0.9906 - val_loss: 2.7203 - val_accuracy: 0.5851\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0199 - accuracy: 0.9915 - val_loss: 2.5704 - val_accuracy: 0.5865\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0202 - accuracy: 0.9916 - val_loss: 2.9426 - val_accuracy: 0.5865\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 86s 172ms/step - loss: 0.0172 - accuracy: 0.9928 - val_loss: 2.7912 - val_accuracy: 0.5847\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 86s 173ms/step - loss: 0.0175 - accuracy: 0.9930 - val_loss: 2.6466 - val_accuracy: 0.5867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.88      0.75      0.81        20\n",
      "        hate       0.78      0.90      0.84        20\n",
      "\n",
      "    accuracy                           0.82        40\n",
      "   macro avg       0.83      0.82      0.82        40\n",
      "weighted avg       0.83      0.82      0.82        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model8.fit(x=train_padded_es_indv,\n",
    "          y=y_train_es_indv,\n",
    "          validation_data=(valid_padded_es_indv, y_valid_es_indv),\n",
    "          shuffle=True,\n",
    "          epochs=25,\n",
    "          batch_size=64)\n",
    "\n",
    "predictions = model8.predict(valid_padded_es_indv)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 20 joined tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 250, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,219,777\n",
      "Trainable params: 219,777\n",
      "Non-trainable params: 3,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES 20 JOINED TWEETS - TRAINABLE EMB\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 250\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    #weights=[embedding_matrix_es_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=False,\n",
    "                    mask_zero=True))\n",
    "model5.add(LSTM(units=128))\n",
    "model5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model5.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "619/619 [==============================] - 20s 32ms/step - loss: 0.6615 - accuracy: 0.6042 - val_loss: 0.5851 - val_accuracy: 0.6950\n",
      "Epoch 2/25\n",
      "619/619 [==============================] - 19s 30ms/step - loss: 0.6424 - accuracy: 0.6290 - val_loss: 0.6069 - val_accuracy: 0.6425\n",
      "Epoch 3/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.6345 - accuracy: 0.6349 - val_loss: 0.5698 - val_accuracy: 0.7125\n",
      "Epoch 4/25\n",
      "619/619 [==============================] - 19s 30ms/step - loss: 0.6293 - accuracy: 0.6421 - val_loss: 0.5821 - val_accuracy: 0.7175\n",
      "Epoch 5/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.6235 - accuracy: 0.6478 - val_loss: 0.5911 - val_accuracy: 0.6775\n",
      "Epoch 6/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.6182 - accuracy: 0.6535 - val_loss: 0.5549 - val_accuracy: 0.7125\n",
      "Epoch 7/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.6116 - accuracy: 0.6577 - val_loss: 0.5936 - val_accuracy: 0.6650\n",
      "Epoch 8/25\n",
      "619/619 [==============================] - 19s 30ms/step - loss: 0.6061 - accuracy: 0.6625 - val_loss: 0.5716 - val_accuracy: 0.6950\n",
      "Epoch 9/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.5982 - accuracy: 0.6687 - val_loss: 0.5661 - val_accuracy: 0.7025\n",
      "Epoch 10/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.5905 - accuracy: 0.6744 - val_loss: 0.5616 - val_accuracy: 0.7150\n",
      "Epoch 11/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.5832 - accuracy: 0.6803 - val_loss: 0.5871 - val_accuracy: 0.6775\n",
      "Epoch 12/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.5752 - accuracy: 0.6877 - val_loss: 0.5723 - val_accuracy: 0.7050\n",
      "Epoch 13/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.5642 - accuracy: 0.6964 - val_loss: 0.5873 - val_accuracy: 0.6925\n",
      "Epoch 14/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.5559 - accuracy: 0.7035 - val_loss: 0.5929 - val_accuracy: 0.6800\n",
      "Epoch 15/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.5443 - accuracy: 0.7139 - val_loss: 0.5694 - val_accuracy: 0.7050\n",
      "Epoch 16/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.5303 - accuracy: 0.7213 - val_loss: 0.6577 - val_accuracy: 0.6750\n",
      "Epoch 17/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.5157 - accuracy: 0.7322 - val_loss: 0.6208 - val_accuracy: 0.6825\n",
      "Epoch 18/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.5053 - accuracy: 0.7406 - val_loss: 0.6457 - val_accuracy: 0.6625\n",
      "Epoch 19/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.4897 - accuracy: 0.7531 - val_loss: 0.6204 - val_accuracy: 0.6925\n",
      "Epoch 20/25\n",
      "619/619 [==============================] - 18s 29ms/step - loss: 0.4707 - accuracy: 0.7621 - val_loss: 0.6772 - val_accuracy: 0.6500\n",
      "Epoch 21/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.4527 - accuracy: 0.7739 - val_loss: 0.7491 - val_accuracy: 0.7025\n",
      "Epoch 22/25\n",
      "619/619 [==============================] - 18s 29ms/step - loss: 0.4371 - accuracy: 0.7843 - val_loss: 0.7294 - val_accuracy: 0.6225\n",
      "Epoch 23/25\n",
      "619/619 [==============================] - 18s 29ms/step - loss: 0.4233 - accuracy: 0.7946 - val_loss: 0.7710 - val_accuracy: 0.6475\n",
      "Epoch 24/25\n",
      "619/619 [==============================] - 18s 29ms/step - loss: 0.4002 - accuracy: 0.8066 - val_loss: 0.8172 - val_accuracy: 0.6800\n",
      "Epoch 25/25\n",
      "619/619 [==============================] - 18s 30ms/step - loss: 0.3822 - accuracy: 0.8166 - val_loss: 0.8180 - val_accuracy: 0.6650\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.74      1.00      0.85        20\n",
      "        hate       1.00      0.65      0.79        20\n",
      "\n",
      "    accuracy                           0.82        40\n",
      "   macro avg       0.87      0.82      0.82        40\n",
      "weighted avg       0.87      0.82      0.82        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model5.fit(x=train_padded_es_20,\n",
    "          y=y_train_es_20,\n",
    "          validation_data=(valid_padded_es_20, y_valid_es_20),\n",
    "          shuffle=True,\n",
    "          epochs=25,\n",
    "          batch_size=64)\n",
    "\n",
    "predictions = model5.predict(valid_padded_es_20)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 250, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               439296    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,439,553\n",
      "Trainable params: 3,439,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES INDVIDUAL TWEETS - TRAINABLE EMB BI\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 250\n",
    "\n",
    "model6 = Sequential()\n",
    "model6.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    #weights=[embedding_matrix_en_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=True, # Changed to True\n",
    "                    mask_zero=True))\n",
    "model6.add(Bidirectional(LSTM(units=128, dropout=0.05, recurrent_dropout=0.2)))\n",
    "model6.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model6.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "619/619 [==============================] - 1095s 2s/step - loss: 0.5989 - accuracy: 0.6727 - val_loss: 0.5373 - val_accuracy: 0.7125\n",
      "Epoch 2/25\n",
      "619/619 [==============================] - 1095s 2s/step - loss: 0.4900 - accuracy: 0.7589 - val_loss: 0.5455 - val_accuracy: 0.7000\n",
      "Epoch 3/25\n",
      "619/619 [==============================] - 1093s 2s/step - loss: 0.3853 - accuracy: 0.8205 - val_loss: 0.7944 - val_accuracy: 0.6400\n",
      "Epoch 4/25\n",
      "619/619 [==============================] - 1093s 2s/step - loss: 0.2846 - accuracy: 0.8719 - val_loss: 0.8372 - val_accuracy: 0.6650\n",
      "Epoch 5/25\n",
      "619/619 [==============================] - 1091s 2s/step - loss: 0.2074 - accuracy: 0.9066 - val_loss: 1.2405 - val_accuracy: 0.6450\n",
      "Epoch 6/25\n",
      "619/619 [==============================] - 1095s 2s/step - loss: 0.1513 - accuracy: 0.9343 - val_loss: 1.5577 - val_accuracy: 0.6275\n",
      "Epoch 7/25\n",
      "619/619 [==============================] - 1121s 2s/step - loss: 0.1139 - accuracy: 0.9515 - val_loss: 1.8449 - val_accuracy: 0.6225\n",
      "Epoch 8/25\n",
      "619/619 [==============================] - 1174s 2s/step - loss: 0.0882 - accuracy: 0.9637 - val_loss: 2.1944 - val_accuracy: 0.6325\n",
      "Epoch 9/25\n",
      "619/619 [==============================] - 1178s 2s/step - loss: 0.0701 - accuracy: 0.9714 - val_loss: 2.4410 - val_accuracy: 0.6250\n",
      "Epoch 10/25\n",
      "619/619 [==============================] - 1096s 2s/step - loss: 0.0616 - accuracy: 0.9749 - val_loss: 2.6846 - val_accuracy: 0.6175\n",
      "Epoch 11/25\n",
      "619/619 [==============================] - 1092s 2s/step - loss: 0.0541 - accuracy: 0.9781 - val_loss: 2.5602 - val_accuracy: 0.6300\n",
      "Epoch 12/25\n",
      "619/619 [==============================] - 1092s 2s/step - loss: 0.0446 - accuracy: 0.9822 - val_loss: 2.8042 - val_accuracy: 0.6025\n",
      "Epoch 13/25\n",
      "619/619 [==============================] - 1091s 2s/step - loss: 0.0413 - accuracy: 0.9828 - val_loss: 3.1711 - val_accuracy: 0.6050\n",
      "Epoch 14/25\n",
      "619/619 [==============================] - 1098s 2s/step - loss: 0.0364 - accuracy: 0.9851 - val_loss: 3.1457 - val_accuracy: 0.6350\n",
      "Epoch 15/25\n",
      "619/619 [==============================] - 1094s 2s/step - loss: 0.0339 - accuracy: 0.9858 - val_loss: 3.1339 - val_accuracy: 0.6075\n",
      "Epoch 16/25\n",
      "619/619 [==============================] - 1096s 2s/step - loss: 0.0287 - accuracy: 0.9885 - val_loss: 3.4146 - val_accuracy: 0.6025\n",
      "Epoch 17/25\n",
      "619/619 [==============================] - 1097s 2s/step - loss: 0.0284 - accuracy: 0.9879 - val_loss: 3.3498 - val_accuracy: 0.6200\n",
      "Epoch 18/25\n",
      "619/619 [==============================] - 1095s 2s/step - loss: 0.0282 - accuracy: 0.9881 - val_loss: 3.3354 - val_accuracy: 0.6375\n",
      "Epoch 19/25\n",
      "619/619 [==============================] - 1091s 2s/step - loss: 0.0241 - accuracy: 0.9898 - val_loss: 3.5112 - val_accuracy: 0.6300\n",
      "Epoch 20/25\n",
      "619/619 [==============================] - 1096s 2s/step - loss: 0.0215 - accuracy: 0.9904 - val_loss: 3.5526 - val_accuracy: 0.6375\n",
      "Epoch 21/25\n",
      "619/619 [==============================] - 1095s 2s/step - loss: 0.0205 - accuracy: 0.9908 - val_loss: 3.6052 - val_accuracy: 0.6375\n",
      "Epoch 22/25\n",
      "619/619 [==============================] - 1102s 2s/step - loss: 0.0195 - accuracy: 0.9911 - val_loss: 3.7957 - val_accuracy: 0.6275\n",
      "Epoch 23/25\n",
      "619/619 [==============================] - 1094s 2s/step - loss: 0.0203 - accuracy: 0.9906 - val_loss: 3.5883 - val_accuracy: 0.6375\n",
      "Epoch 24/25\n",
      "619/619 [==============================] - 1092s 2s/step - loss: 0.0204 - accuracy: 0.9910 - val_loss: 3.8644 - val_accuracy: 0.6175\n",
      "Epoch 25/25\n",
      "619/619 [==============================] - 1097s 2s/step - loss: 0.0161 - accuracy: 0.9923 - val_loss: 3.8868 - val_accuracy: 0.6375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.68      0.95      0.79        20\n",
      "        hate       0.92      0.55      0.69        20\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.80      0.75      0.74        40\n",
      "weighted avg       0.80      0.75      0.74        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model6.fit(x=train_padded_es_20,\n",
    "          y=y_train_es_20,\n",
    "          validation_data=(valid_padded_es_20, y_valid_es_20),\n",
    "          shuffle=True,\n",
    "          epochs=25,\n",
    "          batch_size=64)\n",
    "\n",
    "predictions = model6.predict(valid_padded_es_20)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 250, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 250, 128)          219648    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 250, 128)          131584    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 250, 128)          131584    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,614,529\n",
      "Trainable params: 3,614,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES INDVIDUAL TWEETS - TRAINABLE EMB COMPLEXER NET\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 250\n",
    "\n",
    "model9 = Sequential()\n",
    "model9.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    #weights=[embedding_matrix_en_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=True, # Changed to True\n",
    "                    mask_zero=True))\n",
    "model9.add(LSTM(units=128, return_sequences=True))\n",
    "model9.add(LSTM(units=128, return_sequences=True))\n",
    "model9.add(LSTM(units=128, return_sequences=True))\n",
    "model9.add(LSTM(units=128))\n",
    "model9.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model9.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "619/619 [==============================] - 76s 123ms/step - loss: 0.6102 - accuracy: 0.6646 - val_loss: 0.5521 - val_accuracy: 0.7050\n",
      "Epoch 2/25\n",
      "619/619 [==============================] - 65s 105ms/step - loss: 0.5138 - accuracy: 0.7488 - val_loss: 0.5711 - val_accuracy: 0.7275\n",
      "Epoch 3/25\n",
      "619/619 [==============================] - 65s 106ms/step - loss: 0.4301 - accuracy: 0.7968 - val_loss: 0.7570 - val_accuracy: 0.6700\n",
      "Epoch 4/25\n",
      "619/619 [==============================] - 69s 112ms/step - loss: 0.3456 - accuracy: 0.8407 - val_loss: 0.9783 - val_accuracy: 0.6500\n",
      "Epoch 5/25\n",
      "619/619 [==============================] - 69s 111ms/step - loss: 0.2757 - accuracy: 0.8747 - val_loss: 1.0265 - val_accuracy: 0.6475\n",
      "Epoch 6/25\n",
      "619/619 [==============================] - 66s 106ms/step - loss: 0.2167 - accuracy: 0.9018 - val_loss: 1.1673 - val_accuracy: 0.6575\n",
      "Epoch 7/25\n",
      "619/619 [==============================] - 68s 109ms/step - loss: 0.1726 - accuracy: 0.9218 - val_loss: 1.4153 - val_accuracy: 0.6525\n",
      "Epoch 8/25\n",
      "619/619 [==============================] - 69s 111ms/step - loss: 0.1369 - accuracy: 0.9385 - val_loss: 1.7366 - val_accuracy: 0.6550\n",
      "Epoch 9/25\n",
      "619/619 [==============================] - 69s 112ms/step - loss: 0.1089 - accuracy: 0.9507 - val_loss: 1.9640 - val_accuracy: 0.6425\n",
      "Epoch 10/25\n",
      "619/619 [==============================] - 67s 108ms/step - loss: 0.0892 - accuracy: 0.9599 - val_loss: 1.7283 - val_accuracy: 0.6625\n",
      "Epoch 11/25\n",
      "619/619 [==============================] - 69s 112ms/step - loss: 0.0772 - accuracy: 0.9664 - val_loss: 1.9649 - val_accuracy: 0.6575\n",
      "Epoch 12/25\n",
      "619/619 [==============================] - 70s 113ms/step - loss: 0.0658 - accuracy: 0.9714 - val_loss: 2.0290 - val_accuracy: 0.6575\n",
      "Epoch 13/25\n",
      "619/619 [==============================] - 70s 112ms/step - loss: 0.0565 - accuracy: 0.9746 - val_loss: 2.3891 - val_accuracy: 0.6450\n",
      "Epoch 14/25\n",
      "619/619 [==============================] - 67s 109ms/step - loss: 0.0549 - accuracy: 0.9763 - val_loss: 2.2835 - val_accuracy: 0.6425\n",
      "Epoch 15/25\n",
      "619/619 [==============================] - 69s 112ms/step - loss: 0.0446 - accuracy: 0.9809 - val_loss: 2.2104 - val_accuracy: 0.6250\n",
      "Epoch 16/25\n",
      "619/619 [==============================] - 71s 114ms/step - loss: 0.0397 - accuracy: 0.9826 - val_loss: 2.4574 - val_accuracy: 0.6350\n",
      "Epoch 17/25\n",
      "619/619 [==============================] - 70s 113ms/step - loss: 0.0361 - accuracy: 0.9840 - val_loss: 2.0943 - val_accuracy: 0.6550\n",
      "Epoch 18/25\n",
      "619/619 [==============================] - 66s 107ms/step - loss: 0.0342 - accuracy: 0.9851 - val_loss: 2.4505 - val_accuracy: 0.6650\n",
      "Epoch 19/25\n",
      "619/619 [==============================] - 68s 109ms/step - loss: 0.0306 - accuracy: 0.9865 - val_loss: 2.5160 - val_accuracy: 0.6500\n",
      "Epoch 20/25\n",
      "619/619 [==============================] - 68s 110ms/step - loss: 0.0318 - accuracy: 0.9863 - val_loss: 2.3987 - val_accuracy: 0.6400\n",
      "Epoch 21/25\n",
      "619/619 [==============================] - 67s 109ms/step - loss: 0.0249 - accuracy: 0.9891 - val_loss: 2.4447 - val_accuracy: 0.6675\n",
      "Epoch 22/25\n",
      "619/619 [==============================] - 70s 113ms/step - loss: 0.0240 - accuracy: 0.9891 - val_loss: 2.7598 - val_accuracy: 0.6350\n",
      "Epoch 23/25\n",
      "619/619 [==============================] - 67s 108ms/step - loss: 0.0211 - accuracy: 0.9903 - val_loss: 3.0445 - val_accuracy: 0.6550\n",
      "Epoch 24/25\n",
      "619/619 [==============================] - 68s 109ms/step - loss: 0.0245 - accuracy: 0.9900 - val_loss: 2.7054 - val_accuracy: 0.6525\n",
      "Epoch 25/25\n",
      "619/619 [==============================] - 67s 109ms/step - loss: 0.0211 - accuracy: 0.9900 - val_loss: 2.8851 - val_accuracy: 0.6375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.61      1.00      0.75        20\n",
      "        hate       1.00      0.35      0.52        20\n",
      "\n",
      "    accuracy                           0.68        40\n",
      "   macro avg       0.80      0.68      0.64        40\n",
      "weighted avg       0.80      0.68      0.64        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model9.fit(x=train_padded_es_20,\n",
    "          y=y_train_es_20,\n",
    "          validation_data=(valid_padded_es_20, y_valid_es_20),\n",
    "          shuffle=True,\n",
    "          epochs=25,\n",
    "          batch_size=64)\n",
    "\n",
    "predictions = model9.predict(valid_padded_es_20)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 250, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 250, 512)          1665024   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 250, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 250, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 250, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,062,337\n",
      "Trainable params: 13,062,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES INDVIDUAL TWEETS - TRAINABLE EMB COMPLEXER NET\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 250\n",
    "\n",
    "model10 = Sequential()\n",
    "model10.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    #weights=[embedding_matrix_en_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=True, # Changed to True\n",
    "                    mask_zero=True))\n",
    "model10.add(LSTM(units=512, return_sequences=True))\n",
    "model10.add(LSTM(units=512, return_sequences=True))\n",
    "model10.add(LSTM(units=512, return_sequences=True))\n",
    "model10.add(LSTM(units=512, return_sequences=True))\n",
    "model10.add(LSTM(units=512))\n",
    "model10.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model10.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1238/1238 [==============================] - 273s 221ms/step - loss: 0.6313 - accuracy: 0.6437 - val_loss: 0.6028 - val_accuracy: 0.6600\n",
      "Epoch 2/25\n",
      "1238/1238 [==============================] - 244s 197ms/step - loss: 0.5304 - accuracy: 0.7420 - val_loss: 0.6695 - val_accuracy: 0.6175\n",
      "Epoch 3/25\n",
      "1238/1238 [==============================] - 239s 193ms/step - loss: 0.4499 - accuracy: 0.7917 - val_loss: 0.6855 - val_accuracy: 0.6625\n",
      "Epoch 4/25\n",
      "1238/1238 [==============================] - 239s 193ms/step - loss: 0.3632 - accuracy: 0.8393 - val_loss: 0.8361 - val_accuracy: 0.6575\n",
      "Epoch 5/25\n",
      "1238/1238 [==============================] - 239s 193ms/step - loss: 0.2825 - accuracy: 0.8793 - val_loss: 0.9371 - val_accuracy: 0.6450\n",
      "Epoch 6/25\n",
      "1238/1238 [==============================] - 239s 193ms/step - loss: 0.2167 - accuracy: 0.9091 - val_loss: 1.0598 - val_accuracy: 0.6450\n",
      "Epoch 7/25\n",
      "1238/1238 [==============================] - 239s 193ms/step - loss: 0.1702 - accuracy: 0.9297 - val_loss: 1.1037 - val_accuracy: 0.6700\n",
      "Epoch 8/25\n",
      "1238/1238 [==============================] - 239s 193ms/step - loss: 0.1305 - accuracy: 0.9453 - val_loss: 1.3465 - val_accuracy: 0.6725\n",
      "Epoch 9/25\n",
      "1238/1238 [==============================] - 239s 193ms/step - loss: 0.1061 - accuracy: 0.9568 - val_loss: 1.3742 - val_accuracy: 0.6450\n",
      "Epoch 10/25\n",
      "1238/1238 [==============================] - 240s 194ms/step - loss: 0.0913 - accuracy: 0.9627 - val_loss: 1.4852 - val_accuracy: 0.6725\n",
      "Epoch 11/25\n",
      "1238/1238 [==============================] - 243s 196ms/step - loss: 0.0737 - accuracy: 0.9711 - val_loss: 1.5693 - val_accuracy: 0.6550\n",
      "Epoch 12/25\n",
      "1238/1238 [==============================] - 242s 196ms/step - loss: 0.0578 - accuracy: 0.9764 - val_loss: 1.6078 - val_accuracy: 0.6525\n",
      "Epoch 13/25\n",
      "1238/1238 [==============================] - 242s 196ms/step - loss: 0.0539 - accuracy: 0.9784 - val_loss: 1.6586 - val_accuracy: 0.6325\n",
      "Epoch 14/25\n",
      "1238/1238 [==============================] - 242s 195ms/step - loss: 0.0469 - accuracy: 0.9805 - val_loss: 1.7016 - val_accuracy: 0.6550\n",
      "Epoch 15/25\n",
      "1238/1238 [==============================] - 240s 194ms/step - loss: 0.0392 - accuracy: 0.9845 - val_loss: 1.7147 - val_accuracy: 0.6625\n",
      "Epoch 16/25\n",
      "1238/1238 [==============================] - 241s 195ms/step - loss: 0.0353 - accuracy: 0.9855 - val_loss: 2.3233 - val_accuracy: 0.6400\n",
      "Epoch 17/25\n",
      "1238/1238 [==============================] - 240s 194ms/step - loss: 0.0328 - accuracy: 0.9872 - val_loss: 2.2771 - val_accuracy: 0.6325\n",
      "Epoch 18/25\n",
      "1238/1238 [==============================] - 239s 193ms/step - loss: 0.0284 - accuracy: 0.9879 - val_loss: 2.2079 - val_accuracy: 0.6325\n",
      "Epoch 19/25\n",
      "1238/1238 [==============================] - 240s 194ms/step - loss: 0.0261 - accuracy: 0.9892 - val_loss: 2.5441 - val_accuracy: 0.6525\n",
      "Epoch 20/25\n",
      "1238/1238 [==============================] - 239s 193ms/step - loss: 0.0231 - accuracy: 0.9903 - val_loss: 2.3423 - val_accuracy: 0.6350\n",
      "Epoch 21/25\n",
      "1238/1238 [==============================] - 240s 194ms/step - loss: 0.0218 - accuracy: 0.9912 - val_loss: 2.2976 - val_accuracy: 0.6350\n",
      "Epoch 22/25\n",
      "1238/1238 [==============================] - 239s 193ms/step - loss: 0.0207 - accuracy: 0.9916 - val_loss: 2.3532 - val_accuracy: 0.6300\n",
      "Epoch 23/25\n",
      "1238/1238 [==============================] - 239s 193ms/step - loss: 0.0199 - accuracy: 0.9919 - val_loss: 2.1277 - val_accuracy: 0.6300\n",
      "Epoch 24/25\n",
      "1238/1238 [==============================] - 240s 193ms/step - loss: 0.0175 - accuracy: 0.9927 - val_loss: 2.5591 - val_accuracy: 0.6525\n",
      "Epoch 25/25\n",
      "1238/1238 [==============================] - 239s 193ms/step - loss: 0.0188 - accuracy: 0.9922 - val_loss: 2.3406 - val_accuracy: 0.6275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.64      0.90      0.75        20\n",
      "        hate       0.83      0.50      0.62        20\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.74      0.70      0.69        40\n",
      "weighted avg       0.74      0.70      0.69        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model10.fit(x=train_padded_es_20,\n",
    "          y=y_train_es_20,\n",
    "          validation_data=(valid_padded_es_20, y_valid_es_20),\n",
    "          shuffle=True,\n",
    "          epochs=25,\n",
    "          batch_size=32)\n",
    "\n",
    "predictions = model10.predict(valid_padded_es_20)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  ES individual tweets\n",
    "\n",
    "bert_model1 = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "\n",
    "bert_model1.compile(loss='binary_crossentropy',\n",
    "                   optimizer=Adam(learning_rate=2e-5,epsilon=1e-08),\n",
    "                   metrics=['accuracy'])\n",
    "bert_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bert_model1.fit(x=[train_padded_es_indv_bert, train_mask_es_20],\n",
    "               y=y_train_es,\n",
    "               batch_size=32,\n",
    "               epochs=4,\n",
    "               validation_data=([valid_padded_es_20_bert, valid_mask_es_20], y_valid_es))\n",
    "\n",
    "predictions = bert_model1.predict([test_padded_es_20_bert, test_mask_es_20], batch_size=32)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ES joined 20 tweets\n",
    "\n",
    "bert_model2 = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "\n",
    "bert_model2.compile(loss='binary_crossentropy',\n",
    "                   optimizer=Adam(learning_rate=2e-5,epsilon=1e-08),\n",
    "                   metrics=['accuracy'])\n",
    "bert_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bert_model2.fit(x=[train_inp, train_mask],\n",
    "               y=train_label,\n",
    "               batch_size=32,\n",
    "               epochs=4,\n",
    "               validation_data=([val_inp,val_mask],val_label))\n",
    "\n",
    "\n",
    "predictions = bert_model2.predict([val_inp,val_mask],batch_size=32)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Classical ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 980 candidates, totalling 4900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 33.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed: 46.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 61.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3265 tasks      | elapsed: 78.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 98.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4885 tasks      | elapsed: 119.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4900 out of 4900 | elapsed: 120.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6550097877356043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1,\n",
       " 'tfidf__analyzer': 'char_wb',\n",
       " 'tfidf__max_df': 0.9,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (3, 6)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "\n",
    "pipe = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer()),\n",
    "        (\"clf\", LogisticRegression())\n",
    "])\n",
    "    \n",
    "param_grid = {\"tfidf__ngram_range\" : [(1,2),(1,3),(2,3),(3,4),(3,5),(3,6),(4,5)],\n",
    "              \"tfidf__max_df\":[0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "              \"tfidf__min_df\":[1,2,3,5], # or percentages\n",
    "              \"tfidf__analyzer\":[\"char_wb\"], # n-grams\n",
    "              \"clf__C\":[1,10,100,1000,10000]\n",
    "             }\n",
    "\n",
    "clf_lr = GridSearchCV(pipe,\n",
    "                      param_grid,\n",
    "                      cv=5,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=2,\n",
    "                      scoring=\"f1_macro\")\n",
    "\n",
    "clf_lr.fit(x_train_es, y_train_es)\n",
    "print(clf_lr.best_score_)\n",
    "clf_lr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Evaluation over validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.76      0.80      0.78        20\n",
      "        hate       0.79      0.75      0.77        20\n",
      "\n",
      "    accuracy                           0.78        40\n",
      "   macro avg       0.78      0.78      0.77        40\n",
      "weighted avg       0.78      0.78      0.77        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression ES\n",
    "''' BEST PARAMETERS\n",
    "\n",
    "{'clf__C': 1,\n",
    " 'tfidf__analyzer': 'char_wb',\n",
    " 'tfidf__max_df': 0.9,\n",
    " 'tfidf__min_df': 1,\n",
    " 'tfidf__ngram_range': (3, 6)}\n",
    "'''\n",
    "\n",
    "pipe = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(ngram_range=(3,6),\n",
    "                                 max_df=0.9,\n",
    "                                 min_df=1,\n",
    "                                 analyzer=\"char_wb\")),\n",
    "        (\"clf\", LogisticRegression(C=1))\n",
    "])\n",
    "\n",
    "pipe.fit(x_train_es, y_train_es)\n",
    "predictions = pipe.predict(x_valid_es)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.76      0.80      0.78        20\n",
      "        hate       0.79      0.75      0.77        20\n",
      "\n",
      "    accuracy                           0.78        40\n",
      "   macro avg       0.78      0.78      0.77        40\n",
      "weighted avg       0.78      0.78      0.77        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression EN\n",
    "\n",
    "pipe.fit(x_train_en, y_train_en)\n",
    "predictions = pipe.predict(x_valid_en)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Auxiliar Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define a learning rate scheduler\n",
    "def scheduler(epoch):\n",
    "    if epoch < 25:\n",
    "        return 0.001\n",
    "    elif epoch < 50:\n",
    "        return 0.0005\n",
    "    elif epoch < 75:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00005\n",
    "\n",
    "scheduler_lr = LRS(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "adam = Adam(learning_rate=0.001)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 250, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,219,777\n",
      "Trainable params: 219,777\n",
      "Non-trainable params: 3,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES 20 JOINED TWEETS - TRAINABLE EMB\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 250\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    #weights=[embedding_matrix_es_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=False,\n",
    "                    mask_zero=True))\n",
    "model5.add(LSTM(units=128))\n",
    "model5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model5.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 15, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 15, 512)           1665024   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 15, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 15, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 15, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,062,337\n",
      "Trainable params: 13,062,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES INDVIDUAL TWEETS - TRAINABLE EMB COMPLEXER NET\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 15\n",
    "\n",
    "model8 = Sequential()\n",
    "model8.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    #weights=[embedding_matrix_en_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=True, # Changed to True\n",
    "                    mask_zero=True))\n",
    "model8.add(LSTM(units=512, return_sequences=True))\n",
    "model8.add(LSTM(units=512, return_sequences=True))\n",
    "model8.add(LSTM(units=512, return_sequences=True))\n",
    "model8.add(LSTM(units=512, return_sequences=True))\n",
    "model8.add(LSTM(units=512))\n",
    "model8.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model8.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 250, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 250, 512)          1665024   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 250, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 250, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 250, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,062,337\n",
      "Trainable params: 13,062,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ES 20 JOINED TWEETS - TRAINABLE EMB COMPLEXER NET\n",
    "max_words = 10000\n",
    "word_embedding_size = 300\n",
    "max_length = 250\n",
    "\n",
    "model10 = Sequential()\n",
    "model10.add(Embedding(max_words,\n",
    "                    output_dim=word_embedding_size,\n",
    "                    #weights=[embedding_matrix_en_indv], # embeddings\n",
    "                    input_length=max_length,\n",
    "                    trainable=True, # Changed to True\n",
    "                    mask_zero=True))\n",
    "model10.add(LSTM(units=512, return_sequences=True))\n",
    "model10.add(LSTM(units=512, return_sequences=True))\n",
    "model10.add(LSTM(units=512, return_sequences=True))\n",
    "model10.add(LSTM(units=512, return_sequences=True))\n",
    "model10.add(LSTM(units=512))\n",
    "model10.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model10.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model10.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### ES 20 JOINED TWEETS - TRAINABLE EMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.6624 - accuracy: 0.5996\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71250, saving model to models/ap-model_5_es-0001-0.712500.h5\n",
      "\n",
      "Epoch 00001: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 61ms/step - loss: 0.6623 - accuracy: 0.5997 - val_loss: 0.6124 - val_accuracy: 0.7125\n",
      "Epoch 2/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.6444 - accuracy: 0.6243\n",
      "Epoch 00002: val_accuracy improved from 0.71250 to 0.72750, saving model to models/ap-model_5_es-0002-0.727500.h5\n",
      "\n",
      "Epoch 00002: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.6443 - accuracy: 0.6243 - val_loss: 0.5708 - val_accuracy: 0.7275\n",
      "Epoch 3/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.6375 - accuracy: 0.6328\n",
      "Epoch 00003: val_accuracy did not improve from 0.72750\n",
      "\n",
      "Epoch 00003: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.6375 - accuracy: 0.6327 - val_loss: 0.5669 - val_accuracy: 0.7100\n",
      "Epoch 4/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.6349 - accuracy: 0.6355\n",
      "Epoch 00004: val_accuracy did not improve from 0.72750\n",
      "\n",
      "Epoch 00004: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.6349 - accuracy: 0.6354 - val_loss: 0.5988 - val_accuracy: 0.6875\n",
      "Epoch 5/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.6297 - accuracy: 0.6411\n",
      "Epoch 00005: val_accuracy did not improve from 0.72750\n",
      "\n",
      "Epoch 00005: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.6298 - accuracy: 0.6409 - val_loss: 0.5739 - val_accuracy: 0.6925\n",
      "Epoch 6/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.6254 - accuracy: 0.6446\n",
      "Epoch 00006: val_accuracy did not improve from 0.72750\n",
      "\n",
      "Epoch 00006: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.6253 - accuracy: 0.6446 - val_loss: 0.5847 - val_accuracy: 0.6975\n",
      "Epoch 7/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.6213 - accuracy: 0.6488\n",
      "Epoch 00007: val_accuracy did not improve from 0.72750\n",
      "\n",
      "Epoch 00007: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.6213 - accuracy: 0.6486 - val_loss: 0.5696 - val_accuracy: 0.7100\n",
      "Epoch 8/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.6186 - accuracy: 0.6507\n",
      "Epoch 00008: val_accuracy improved from 0.72750 to 0.73250, saving model to models/ap-model_5_es-0008-0.732500.h5\n",
      "\n",
      "Epoch 00008: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.6186 - accuracy: 0.6507 - val_loss: 0.5460 - val_accuracy: 0.7325\n",
      "Epoch 9/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.6127 - accuracy: 0.6545\n",
      "Epoch 00009: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00009: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.6128 - accuracy: 0.6544 - val_loss: 0.5786 - val_accuracy: 0.7175\n",
      "Epoch 10/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.6099 - accuracy: 0.6584\n",
      "Epoch 00010: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00010: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.6098 - accuracy: 0.6585 - val_loss: 0.5610 - val_accuracy: 0.7275\n",
      "Epoch 11/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.6066 - accuracy: 0.6603\n",
      "Epoch 00011: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00011: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.6065 - accuracy: 0.6603 - val_loss: 0.5658 - val_accuracy: 0.7075\n",
      "Epoch 12/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.5998 - accuracy: 0.6675\n",
      "Epoch 00012: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00012: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.5999 - accuracy: 0.6675 - val_loss: 0.5740 - val_accuracy: 0.7200\n",
      "Epoch 13/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.5942 - accuracy: 0.6711\n",
      "Epoch 00013: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00013: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.5941 - accuracy: 0.6713 - val_loss: 0.5808 - val_accuracy: 0.7200\n",
      "Epoch 14/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.5884 - accuracy: 0.6768\n",
      "Epoch 00014: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00014: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 60ms/step - loss: 0.5885 - accuracy: 0.6767 - val_loss: 0.6051 - val_accuracy: 0.7100\n",
      "Epoch 15/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.5826 - accuracy: 0.6816\n",
      "Epoch 00015: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00015: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.5826 - accuracy: 0.6816 - val_loss: 0.6395 - val_accuracy: 0.6500\n",
      "Epoch 16/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.5757 - accuracy: 0.6885\n",
      "Epoch 00016: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00016: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 60ms/step - loss: 0.5758 - accuracy: 0.6885 - val_loss: 0.5856 - val_accuracy: 0.7100\n",
      "Epoch 17/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.5673 - accuracy: 0.6932\n",
      "Epoch 00017: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00017: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 59ms/step - loss: 0.5674 - accuracy: 0.6931 - val_loss: 0.5801 - val_accuracy: 0.7125\n",
      "Epoch 18/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.5609 - accuracy: 0.7011\n",
      "Epoch 00018: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00018: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 61ms/step - loss: 0.5609 - accuracy: 0.7011 - val_loss: 0.5934 - val_accuracy: 0.7025\n",
      "Epoch 19/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.5504 - accuracy: 0.7069\n",
      "Epoch 00019: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00019: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 59ms/step - loss: 0.5505 - accuracy: 0.7068 - val_loss: 0.6274 - val_accuracy: 0.7000\n",
      "Epoch 20/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.7150\n",
      "Epoch 00020: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00020: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.5393 - accuracy: 0.7149 - val_loss: 0.6141 - val_accuracy: 0.6925\n",
      "Epoch 21/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.5287 - accuracy: 0.7218\n",
      "Epoch 00021: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00021: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 60ms/step - loss: 0.5287 - accuracy: 0.7218 - val_loss: 0.6157 - val_accuracy: 0.6925\n",
      "Epoch 22/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.5216 - accuracy: 0.7268\n",
      "Epoch 00022: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00022: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.5216 - accuracy: 0.7267 - val_loss: 0.6269 - val_accuracy: 0.6925\n",
      "Epoch 23/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.5075 - accuracy: 0.7360\n",
      "Epoch 00023: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00023: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.5075 - accuracy: 0.7360 - val_loss: 0.6769 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.4954 - accuracy: 0.7459\n",
      "Epoch 00024: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00024: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.4954 - accuracy: 0.7459 - val_loss: 0.6839 - val_accuracy: 0.6850\n",
      "Epoch 25/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.4815 - accuracy: 0.7527\n",
      "Epoch 00025: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00025: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.4815 - accuracy: 0.7526 - val_loss: 0.6964 - val_accuracy: 0.6950\n",
      "Epoch 26/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.4481 - accuracy: 0.7727\n",
      "Epoch 00026: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00026: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.4481 - accuracy: 0.7727 - val_loss: 0.7156 - val_accuracy: 0.7075\n",
      "Epoch 27/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.4355 - accuracy: 0.7807\n",
      "Epoch 00027: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00027: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.4355 - accuracy: 0.7808 - val_loss: 0.7394 - val_accuracy: 0.6750\n",
      "Epoch 28/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.4254 - accuracy: 0.7860\n",
      "Epoch 00028: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00028: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.4254 - accuracy: 0.7860 - val_loss: 0.7369 - val_accuracy: 0.7000\n",
      "Epoch 29/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.4148 - accuracy: 0.7932\n",
      "Epoch 00029: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00029: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.4149 - accuracy: 0.7932 - val_loss: 0.7869 - val_accuracy: 0.6850\n",
      "Epoch 30/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.4046 - accuracy: 0.7984\n",
      "Epoch 00030: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00030: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.4045 - accuracy: 0.7984 - val_loss: 0.7951 - val_accuracy: 0.6900\n",
      "Epoch 31/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3946 - accuracy: 0.8061\n",
      "Epoch 00031: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00031: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.3946 - accuracy: 0.8061 - val_loss: 0.7985 - val_accuracy: 0.6875\n",
      "Epoch 32/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8097\n",
      "Epoch 00032: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00032: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.3883 - accuracy: 0.8098 - val_loss: 0.8373 - val_accuracy: 0.6825\n",
      "Epoch 33/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3765 - accuracy: 0.8170\n",
      "Epoch 00033: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00033: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 59ms/step - loss: 0.3764 - accuracy: 0.8170 - val_loss: 0.8221 - val_accuracy: 0.6975\n",
      "Epoch 34/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3645 - accuracy: 0.8222\n",
      "Epoch 00034: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00034: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 60ms/step - loss: 0.3646 - accuracy: 0.8221 - val_loss: 0.8416 - val_accuracy: 0.6725\n",
      "Epoch 35/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3567 - accuracy: 0.8266\n",
      "Epoch 00035: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00035: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 59ms/step - loss: 0.3567 - accuracy: 0.8266 - val_loss: 0.9083 - val_accuracy: 0.6775\n",
      "Epoch 36/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3515 - accuracy: 0.8297\n",
      "Epoch 00036: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00036: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.3514 - accuracy: 0.8297 - val_loss: 0.8726 - val_accuracy: 0.6800\n",
      "Epoch 37/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3417 - accuracy: 0.8362\n",
      "Epoch 00037: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00037: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.3417 - accuracy: 0.8363 - val_loss: 0.8779 - val_accuracy: 0.7125\n",
      "Epoch 38/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3305 - accuracy: 0.8422\n",
      "Epoch 00038: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00038: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 63ms/step - loss: 0.3306 - accuracy: 0.8422 - val_loss: 0.9045 - val_accuracy: 0.7150\n",
      "Epoch 39/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3270 - accuracy: 0.8446\n",
      "Epoch 00039: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00039: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.3269 - accuracy: 0.8446 - val_loss: 0.9265 - val_accuracy: 0.6750\n",
      "Epoch 40/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3225 - accuracy: 0.8476\n",
      "Epoch 00040: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00040: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.3226 - accuracy: 0.8475 - val_loss: 0.9438 - val_accuracy: 0.6875\n",
      "Epoch 41/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3109 - accuracy: 0.8554\n",
      "Epoch 00041: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00041: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.3109 - accuracy: 0.8554 - val_loss: 0.9958 - val_accuracy: 0.6775\n",
      "Epoch 42/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.3033 - accuracy: 0.8585\n",
      "Epoch 00042: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00042: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.3034 - accuracy: 0.8585 - val_loss: 1.0538 - val_accuracy: 0.6675\n",
      "Epoch 43/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2992 - accuracy: 0.8603\n",
      "Epoch 00043: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00043: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.2993 - accuracy: 0.8603 - val_loss: 0.9877 - val_accuracy: 0.6950\n",
      "Epoch 44/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2966 - accuracy: 0.8628\n",
      "Epoch 00044: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00044: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2967 - accuracy: 0.8628 - val_loss: 0.9676 - val_accuracy: 0.6925\n",
      "Epoch 45/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2859 - accuracy: 0.8679\n",
      "Epoch 00045: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00045: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2858 - accuracy: 0.8680 - val_loss: 0.9893 - val_accuracy: 0.6900\n",
      "Epoch 46/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2734 - accuracy: 0.8730\n",
      "Epoch 00046: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00046: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2734 - accuracy: 0.8730 - val_loss: 1.0105 - val_accuracy: 0.6575\n",
      "Epoch 47/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.8754\n",
      "Epoch 00047: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00047: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2722 - accuracy: 0.8753 - val_loss: 1.0903 - val_accuracy: 0.6850\n",
      "Epoch 48/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.8791\n",
      "Epoch 00048: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00048: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2624 - accuracy: 0.8792 - val_loss: 1.1339 - val_accuracy: 0.6475\n",
      "Epoch 49/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2619 - accuracy: 0.8808\n",
      "Epoch 00049: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00049: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2620 - accuracy: 0.8808 - val_loss: 1.0596 - val_accuracy: 0.6675\n",
      "Epoch 50/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2540 - accuracy: 0.8835\n",
      "Epoch 00050: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00050: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2541 - accuracy: 0.8835 - val_loss: 1.1851 - val_accuracy: 0.6650\n",
      "Epoch 51/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2300 - accuracy: 0.8985\n",
      "Epoch 00051: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00051: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2299 - accuracy: 0.8985 - val_loss: 1.2132 - val_accuracy: 0.6650\n",
      "Epoch 52/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2210 - accuracy: 0.9016\n",
      "Epoch 00052: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00052: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2211 - accuracy: 0.9016 - val_loss: 1.2569 - val_accuracy: 0.6725\n",
      "Epoch 53/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2178 - accuracy: 0.9023\n",
      "Epoch 00053: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00053: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2178 - accuracy: 0.9023 - val_loss: 1.2660 - val_accuracy: 0.6675\n",
      "Epoch 54/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2149 - accuracy: 0.9043\n",
      "Epoch 00054: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00054: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2149 - accuracy: 0.9043 - val_loss: 1.2759 - val_accuracy: 0.6650\n",
      "Epoch 55/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2126 - accuracy: 0.9051\n",
      "Epoch 00055: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00055: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2126 - accuracy: 0.9051 - val_loss: 1.2964 - val_accuracy: 0.6600\n",
      "Epoch 56/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9061\n",
      "Epoch 00056: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00056: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.2105 - accuracy: 0.9062 - val_loss: 1.3228 - val_accuracy: 0.6575\n",
      "Epoch 57/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.9072\n",
      "Epoch 00057: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00057: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 61ms/step - loss: 0.2094 - accuracy: 0.9071 - val_loss: 1.3361 - val_accuracy: 0.6675\n",
      "Epoch 58/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2062 - accuracy: 0.9087\n",
      "Epoch 00058: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00058: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 61ms/step - loss: 0.2062 - accuracy: 0.9087 - val_loss: 1.3197 - val_accuracy: 0.6725\n",
      "Epoch 59/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2049 - accuracy: 0.9093\n",
      "Epoch 00059: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00059: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 60ms/step - loss: 0.2049 - accuracy: 0.9093 - val_loss: 1.3262 - val_accuracy: 0.6650\n",
      "Epoch 60/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2026 - accuracy: 0.9099\n",
      "Epoch 00060: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00060: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.2026 - accuracy: 0.9098 - val_loss: 1.3301 - val_accuracy: 0.6725\n",
      "Epoch 61/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2006 - accuracy: 0.9118\n",
      "Epoch 00061: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00061: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 60ms/step - loss: 0.2006 - accuracy: 0.9118 - val_loss: 1.3746 - val_accuracy: 0.6700\n",
      "Epoch 62/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1983 - accuracy: 0.9131\n",
      "Epoch 00062: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00062: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1983 - accuracy: 0.9131 - val_loss: 1.3529 - val_accuracy: 0.6625\n",
      "Epoch 63/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1971 - accuracy: 0.9133\n",
      "Epoch 00063: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00063: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1971 - accuracy: 0.9134 - val_loss: 1.3453 - val_accuracy: 0.6700\n",
      "Epoch 64/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1955 - accuracy: 0.9143\n",
      "Epoch 00064: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00064: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1955 - accuracy: 0.9142 - val_loss: 1.3733 - val_accuracy: 0.6600\n",
      "Epoch 65/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.9151\n",
      "Epoch 00065: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00065: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.1943 - accuracy: 0.9151 - val_loss: 1.3914 - val_accuracy: 0.6575\n",
      "Epoch 66/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1918 - accuracy: 0.9169\n",
      "Epoch 00066: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00066: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1918 - accuracy: 0.9169 - val_loss: 1.3923 - val_accuracy: 0.6575\n",
      "Epoch 67/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1907 - accuracy: 0.9167\n",
      "Epoch 00067: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00067: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 61ms/step - loss: 0.1907 - accuracy: 0.9166 - val_loss: 1.4098 - val_accuracy: 0.6700\n",
      "Epoch 68/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1887 - accuracy: 0.9178\n",
      "Epoch 00068: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00068: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 61ms/step - loss: 0.1886 - accuracy: 0.9179 - val_loss: 1.3624 - val_accuracy: 0.6650\n",
      "Epoch 69/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1873 - accuracy: 0.9192\n",
      "Epoch 00069: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00069: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.1872 - accuracy: 0.9192 - val_loss: 1.4641 - val_accuracy: 0.6575\n",
      "Epoch 70/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1852 - accuracy: 0.9194\n",
      "Epoch 00070: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00070: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.1852 - accuracy: 0.9193 - val_loss: 1.4330 - val_accuracy: 0.6675\n",
      "Epoch 71/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1837 - accuracy: 0.9198\n",
      "Epoch 00071: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00071: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1836 - accuracy: 0.9198 - val_loss: 1.4283 - val_accuracy: 0.6675\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/310 [============================>.] - ETA: 0s - loss: 0.1816 - accuracy: 0.9215\n",
      "Epoch 00072: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00072: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1818 - accuracy: 0.9215 - val_loss: 1.4457 - val_accuracy: 0.6675\n",
      "Epoch 73/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1820 - accuracy: 0.9227\n",
      "Epoch 00073: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00073: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.1820 - accuracy: 0.9227 - val_loss: 1.4714 - val_accuracy: 0.6650\n",
      "Epoch 74/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1790 - accuracy: 0.9228\n",
      "Epoch 00074: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00074: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1789 - accuracy: 0.9229 - val_loss: 1.4549 - val_accuracy: 0.6700\n",
      "Epoch 75/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1774 - accuracy: 0.9241\n",
      "Epoch 00075: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00075: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1774 - accuracy: 0.9241 - val_loss: 1.4547 - val_accuracy: 0.6600\n",
      "Epoch 76/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1728 - accuracy: 0.9261\n",
      "Epoch 00076: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00076: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1728 - accuracy: 0.9262 - val_loss: 1.5010 - val_accuracy: 0.6650\n",
      "Epoch 77/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9259\n",
      "Epoch 00077: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00077: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1716 - accuracy: 0.9260 - val_loss: 1.5067 - val_accuracy: 0.6575\n",
      "Epoch 78/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1708 - accuracy: 0.9270\n",
      "Epoch 00078: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00078: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1710 - accuracy: 0.9269 - val_loss: 1.5108 - val_accuracy: 0.6625\n",
      "Epoch 79/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1701 - accuracy: 0.9267\n",
      "Epoch 00079: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00079: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1701 - accuracy: 0.9267 - val_loss: 1.5190 - val_accuracy: 0.6650\n",
      "Epoch 80/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.9275\n",
      "Epoch 00080: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00080: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.1691 - accuracy: 0.9275 - val_loss: 1.5307 - val_accuracy: 0.6675\n",
      "Epoch 81/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.9279\n",
      "Epoch 00081: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00081: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1683 - accuracy: 0.9279 - val_loss: 1.5281 - val_accuracy: 0.6650\n",
      "Epoch 82/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1677 - accuracy: 0.9284\n",
      "Epoch 00082: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00082: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1677 - accuracy: 0.9284 - val_loss: 1.5445 - val_accuracy: 0.6675\n",
      "Epoch 83/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1668 - accuracy: 0.9286\n",
      "Epoch 00083: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00083: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.1667 - accuracy: 0.9286 - val_loss: 1.5408 - val_accuracy: 0.6700\n",
      "Epoch 84/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1658 - accuracy: 0.9285\n",
      "Epoch 00084: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00084: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1659 - accuracy: 0.9285 - val_loss: 1.5359 - val_accuracy: 0.6700\n",
      "Epoch 85/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1651 - accuracy: 0.9288\n",
      "Epoch 00085: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00085: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 59ms/step - loss: 0.1651 - accuracy: 0.9288 - val_loss: 1.5579 - val_accuracy: 0.6700\n",
      "Epoch 86/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1642 - accuracy: 0.9294\n",
      "Epoch 00086: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00086: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1642 - accuracy: 0.9293 - val_loss: 1.5655 - val_accuracy: 0.6650\n",
      "Epoch 87/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1634 - accuracy: 0.9298\n",
      "Epoch 00087: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00087: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.1634 - accuracy: 0.9297 - val_loss: 1.5710 - val_accuracy: 0.6750\n",
      "Epoch 88/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1627 - accuracy: 0.9300\n",
      "Epoch 00088: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00088: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.1628 - accuracy: 0.9300 - val_loss: 1.5808 - val_accuracy: 0.6725\n",
      "Epoch 89/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9309\n",
      "Epoch 00089: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00089: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1618 - accuracy: 0.9309 - val_loss: 1.5786 - val_accuracy: 0.6650\n",
      "Epoch 90/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1612 - accuracy: 0.9308\n",
      "Epoch 00090: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00090: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.1613 - accuracy: 0.9307 - val_loss: 1.5981 - val_accuracy: 0.6675\n",
      "Epoch 91/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1602 - accuracy: 0.9318\n",
      "Epoch 00091: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00091: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 61ms/step - loss: 0.1602 - accuracy: 0.9317 - val_loss: 1.6488 - val_accuracy: 0.6600\n",
      "Epoch 92/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1599 - accuracy: 0.9315\n",
      "Epoch 00092: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00092: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 62ms/step - loss: 0.1599 - accuracy: 0.9315 - val_loss: 1.6210 - val_accuracy: 0.6700\n",
      "Epoch 93/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1589 - accuracy: 0.9329\n",
      "Epoch 00093: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00093: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 63ms/step - loss: 0.1589 - accuracy: 0.9330 - val_loss: 1.6212 - val_accuracy: 0.6675\n",
      "Epoch 94/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1581 - accuracy: 0.9330\n",
      "Epoch 00094: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00094: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 20s 63ms/step - loss: 0.1581 - accuracy: 0.9330 - val_loss: 1.6295 - val_accuracy: 0.6650\n",
      "Epoch 95/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1576 - accuracy: 0.9329\n",
      "Epoch 00095: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00095: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 62ms/step - loss: 0.1576 - accuracy: 0.9330 - val_loss: 1.6370 - val_accuracy: 0.6650\n",
      "Epoch 96/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9334\n",
      "Epoch 00096: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00096: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 62ms/step - loss: 0.1568 - accuracy: 0.9334 - val_loss: 1.6256 - val_accuracy: 0.6700\n",
      "Epoch 97/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1562 - accuracy: 0.9337\n",
      "Epoch 00097: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00097: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 62ms/step - loss: 0.1562 - accuracy: 0.9337 - val_loss: 1.6340 - val_accuracy: 0.6700\n",
      "Epoch 98/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9343\n",
      "Epoch 00098: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00098: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 62ms/step - loss: 0.1550 - accuracy: 0.9343 - val_loss: 1.6492 - val_accuracy: 0.6575\n",
      "Epoch 99/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9343\n",
      "Epoch 00099: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00099: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 19s 60ms/step - loss: 0.1547 - accuracy: 0.9343 - val_loss: 1.6528 - val_accuracy: 0.6750\n",
      "Epoch 100/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1536 - accuracy: 0.9348\n",
      "Epoch 00100: val_accuracy did not improve from 0.73250\n",
      "\n",
      "Epoch 00100: saving model to models/ap-model_5_es.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1536 - accuracy: 0.9348 - val_loss: 1.6435 - val_accuracy: 0.6650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4a546c0d68>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_es = model5\n",
    "model_id = 'model_5_es'\n",
    "\n",
    "model_5_es.fit(x=train_padded_es_20,\n",
    "               y=y_train_es_20,\n",
    "               batch_size=128,\n",
    "               validation_data=(valid_padded_es_20, y_valid_es_20),\n",
    "               shuffle=True,\n",
    "               verbose=1,                \n",
    "               epochs=epochs,\n",
    "               callbacks=[configure_callbacks(model_id), scheduler_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.83      1.00      0.91        20\n",
      "        hate       1.00      0.80      0.89        20\n",
      "\n",
      "    accuracy                           0.90        40\n",
      "   macro avg       0.92      0.90      0.90        40\n",
      "weighted avg       0.92      0.90      0.90        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_5_es = load_model('models/ap-model_5_es-0008-0.732500.h5')\n",
    "predictions = model_5_es.predict(valid_padded_es_20)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### EN 20 JOINED TWEETS - TRAINABLE EMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.4000 - accuracy: 0.8213\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66750, saving model to models/ap-model_5_en-0001-0.667500.h5\n",
      "\n",
      "Epoch 00001: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.3999 - accuracy: 0.8214 - val_loss: 0.9405 - val_accuracy: 0.6675\n",
      "Epoch 2/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2911 - accuracy: 0.8713\n",
      "Epoch 00002: val_accuracy improved from 0.66750 to 0.68750, saving model to models/ap-model_5_en-0002-0.687500.h5\n",
      "\n",
      "Epoch 00002: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 18s 58ms/step - loss: 0.2912 - accuracy: 0.8713 - val_loss: 1.0512 - val_accuracy: 0.6875\n",
      "Epoch 3/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2675 - accuracy: 0.8813\n",
      "Epoch 00003: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00003: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.2676 - accuracy: 0.8813 - val_loss: 1.1407 - val_accuracy: 0.6450\n",
      "Epoch 4/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2424 - accuracy: 0.8944\n",
      "Epoch 00004: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00004: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.2424 - accuracy: 0.8943 - val_loss: 1.2823 - val_accuracy: 0.6525\n",
      "Epoch 5/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2438 - accuracy: 0.8927\n",
      "Epoch 00005: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00005: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.2438 - accuracy: 0.8927 - val_loss: 1.0879 - val_accuracy: 0.6750\n",
      "Epoch 6/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2271 - accuracy: 0.9014\n",
      "Epoch 00006: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00006: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.2272 - accuracy: 0.9014 - val_loss: 1.1444 - val_accuracy: 0.6800\n",
      "Epoch 7/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2302 - accuracy: 0.9015\n",
      "Epoch 00007: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00007: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.2301 - accuracy: 0.9015 - val_loss: 1.2640 - val_accuracy: 0.6475\n",
      "Epoch 8/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.2082 - accuracy: 0.9123\n",
      "Epoch 00008: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00008: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.2082 - accuracy: 0.9123 - val_loss: 1.3161 - val_accuracy: 0.6575\n",
      "Epoch 9/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1971 - accuracy: 0.9154\n",
      "Epoch 00009: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00009: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1972 - accuracy: 0.9153 - val_loss: 1.2549 - val_accuracy: 0.6400\n",
      "Epoch 10/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2046 - accuracy: 0.9146\n",
      "Epoch 00010: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00010: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.2049 - accuracy: 0.9145 - val_loss: 1.3017 - val_accuracy: 0.6650\n",
      "Epoch 11/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.9093\n",
      "Epoch 00011: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00011: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.2166 - accuracy: 0.9093 - val_loss: 1.2454 - val_accuracy: 0.6700\n",
      "Epoch 12/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1904 - accuracy: 0.9208\n",
      "Epoch 00012: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00012: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1904 - accuracy: 0.9208 - val_loss: 1.4564 - val_accuracy: 0.6575\n",
      "Epoch 13/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9270\n",
      "Epoch 00013: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00013: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1759 - accuracy: 0.9270 - val_loss: 1.3469 - val_accuracy: 0.6450\n",
      "Epoch 14/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1778 - accuracy: 0.9273\n",
      "Epoch 00014: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00014: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1778 - accuracy: 0.9272 - val_loss: 1.4050 - val_accuracy: 0.6550\n",
      "Epoch 15/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1651 - accuracy: 0.9313\n",
      "Epoch 00015: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00015: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1652 - accuracy: 0.9313 - val_loss: 1.4259 - val_accuracy: 0.6500\n",
      "Epoch 16/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1602 - accuracy: 0.9346\n",
      "Epoch 00016: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00016: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1601 - accuracy: 0.9347 - val_loss: 1.3243 - val_accuracy: 0.6525\n",
      "Epoch 17/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1522 - accuracy: 0.9384\n",
      "Epoch 00017: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00017: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1524 - accuracy: 0.9383 - val_loss: 1.5062 - val_accuracy: 0.6725\n",
      "Epoch 18/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1710 - accuracy: 0.9313\n",
      "Epoch 00018: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00018: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1714 - accuracy: 0.9312 - val_loss: 1.3109 - val_accuracy: 0.6375\n",
      "Epoch 19/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9296\n",
      "Epoch 00019: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00019: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 18s 57ms/step - loss: 0.1766 - accuracy: 0.9296 - val_loss: 1.4351 - val_accuracy: 0.6400\n",
      "Epoch 20/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1470 - accuracy: 0.9412\n",
      "Epoch 00020: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00020: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 17s 54ms/step - loss: 0.1470 - accuracy: 0.9412 - val_loss: 1.5398 - val_accuracy: 0.6225\n",
      "Epoch 21/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1326 - accuracy: 0.9481\n",
      "Epoch 00021: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00021: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.1326 - accuracy: 0.9481 - val_loss: 1.5851 - val_accuracy: 0.6525\n",
      "Epoch 22/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9498\n",
      "Epoch 00022: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00022: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.1282 - accuracy: 0.9498 - val_loss: 1.6047 - val_accuracy: 0.6475\n",
      "Epoch 23/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1328 - accuracy: 0.9480\n",
      "Epoch 00023: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00023: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.1329 - accuracy: 0.9480 - val_loss: 1.5243 - val_accuracy: 0.6725\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/310 [============================>.] - ETA: 0s - loss: 0.1348 - accuracy: 0.9470\n",
      "Epoch 00024: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00024: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.1347 - accuracy: 0.9470 - val_loss: 1.6101 - val_accuracy: 0.6575\n",
      "Epoch 25/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.1241 - accuracy: 0.9510\n",
      "Epoch 00025: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00025: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.1240 - accuracy: 0.9511 - val_loss: 1.7802 - val_accuracy: 0.6425\n",
      "Epoch 26/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9666\n",
      "Epoch 00026: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00026: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0930 - accuracy: 0.9666 - val_loss: 1.8407 - val_accuracy: 0.6425\n",
      "Epoch 27/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0844 - accuracy: 0.9684\n",
      "Epoch 00027: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00027: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0844 - accuracy: 0.9684 - val_loss: 1.8614 - val_accuracy: 0.6425\n",
      "Epoch 28/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0815 - accuracy: 0.9703\n",
      "Epoch 00028: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00028: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0814 - accuracy: 0.9703 - val_loss: 1.9513 - val_accuracy: 0.6200\n",
      "Epoch 29/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0802 - accuracy: 0.9702\n",
      "Epoch 00029: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00029: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0802 - accuracy: 0.9701 - val_loss: 1.7829 - val_accuracy: 0.6550\n",
      "Epoch 30/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9706\n",
      "Epoch 00030: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00030: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0795 - accuracy: 0.9706 - val_loss: 1.9847 - val_accuracy: 0.6175\n",
      "Epoch 31/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9717\n",
      "Epoch 00031: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00031: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0783 - accuracy: 0.9717 - val_loss: 1.8263 - val_accuracy: 0.6450\n",
      "Epoch 32/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9720\n",
      "Epoch 00032: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00032: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0782 - accuracy: 0.9720 - val_loss: 2.0254 - val_accuracy: 0.6475\n",
      "Epoch 33/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.9737\n",
      "Epoch 00033: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00033: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0749 - accuracy: 0.9737 - val_loss: 2.1372 - val_accuracy: 0.6250\n",
      "Epoch 34/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0744 - accuracy: 0.9738\n",
      "Epoch 00034: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00034: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0743 - accuracy: 0.9739 - val_loss: 2.0046 - val_accuracy: 0.6200\n",
      "Epoch 35/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0708 - accuracy: 0.9747\n",
      "Epoch 00035: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00035: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0708 - accuracy: 0.9748 - val_loss: 2.1554 - val_accuracy: 0.6200\n",
      "Epoch 36/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 0.9758\n",
      "Epoch 00036: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00036: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0711 - accuracy: 0.9758 - val_loss: 2.1347 - val_accuracy: 0.6275\n",
      "Epoch 37/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 0.9772\n",
      "Epoch 00037: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00037: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0654 - accuracy: 0.9772 - val_loss: 2.2267 - val_accuracy: 0.6175\n",
      "Epoch 38/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9773\n",
      "Epoch 00038: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00038: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0653 - accuracy: 0.9773 - val_loss: 2.2457 - val_accuracy: 0.6200\n",
      "Epoch 39/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0660 - accuracy: 0.9773\n",
      "Epoch 00039: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00039: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0660 - accuracy: 0.9773 - val_loss: 2.1145 - val_accuracy: 0.6325\n",
      "Epoch 40/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9789\n",
      "Epoch 00040: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00040: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0626 - accuracy: 0.9789 - val_loss: 2.2291 - val_accuracy: 0.6325\n",
      "Epoch 41/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0581 - accuracy: 0.9803\n",
      "Epoch 00041: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00041: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0582 - accuracy: 0.9802 - val_loss: 2.2689 - val_accuracy: 0.6150\n",
      "Epoch 42/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9804\n",
      "Epoch 00042: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00042: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0562 - accuracy: 0.9804 - val_loss: 2.4256 - val_accuracy: 0.6200\n",
      "Epoch 43/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9805\n",
      "Epoch 00043: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00043: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0596 - accuracy: 0.9805 - val_loss: 2.4218 - val_accuracy: 0.6300\n",
      "Epoch 44/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9802\n",
      "Epoch 00044: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00044: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0581 - accuracy: 0.9802 - val_loss: 2.2714 - val_accuracy: 0.6350\n",
      "Epoch 45/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 0.9808\n",
      "Epoch 00045: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00045: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0577 - accuracy: 0.9808 - val_loss: 2.2684 - val_accuracy: 0.6175\n",
      "Epoch 46/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 0.9836\n",
      "Epoch 00046: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00046: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0514 - accuracy: 0.9836 - val_loss: 2.4112 - val_accuracy: 0.6275\n",
      "Epoch 47/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9837\n",
      "Epoch 00047: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00047: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0510 - accuracy: 0.9837 - val_loss: 2.1498 - val_accuracy: 0.6450\n",
      "Epoch 48/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9807\n",
      "Epoch 00048: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00048: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0587 - accuracy: 0.9807 - val_loss: 2.3614 - val_accuracy: 0.6225\n",
      "Epoch 49/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9855\n",
      "Epoch 00049: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00049: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 2.3802 - val_accuracy: 0.6400\n",
      "Epoch 50/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9820\n",
      "Epoch 00050: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00050: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0534 - accuracy: 0.9821 - val_loss: 2.4806 - val_accuracy: 0.6300\n",
      "Epoch 51/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0384 - accuracy: 0.9888\n",
      "Epoch 00051: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00051: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0383 - accuracy: 0.9888 - val_loss: 2.3882 - val_accuracy: 0.6150\n",
      "Epoch 52/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0339 - accuracy: 0.9894\n",
      "Epoch 00052: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00052: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 2.4334 - val_accuracy: 0.6225\n",
      "Epoch 53/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9891\n",
      "Epoch 00053: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00053: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0330 - accuracy: 0.9891 - val_loss: 2.5438 - val_accuracy: 0.6275\n",
      "Epoch 54/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9891\n",
      "Epoch 00054: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00054: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 2.6310 - val_accuracy: 0.6225\n",
      "Epoch 55/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9891\n",
      "Epoch 00055: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00055: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0320 - accuracy: 0.9891 - val_loss: 2.6055 - val_accuracy: 0.6200\n",
      "Epoch 56/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9887\n",
      "Epoch 00056: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00056: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 2.6262 - val_accuracy: 0.6375\n",
      "Epoch 57/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9891\n",
      "Epoch 00057: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00057: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0319 - accuracy: 0.9891 - val_loss: 2.6981 - val_accuracy: 0.6275\n",
      "Epoch 58/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9896\n",
      "Epoch 00058: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00058: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 2.5614 - val_accuracy: 0.6325\n",
      "Epoch 59/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9895\n",
      "Epoch 00059: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00059: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 2.5959 - val_accuracy: 0.6375\n",
      "Epoch 60/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9893\n",
      "Epoch 00060: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00060: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0301 - accuracy: 0.9893 - val_loss: 2.7481 - val_accuracy: 0.6175\n",
      "Epoch 61/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9903\n",
      "Epoch 00061: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00061: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 2.7806 - val_accuracy: 0.6175\n",
      "Epoch 62/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9902\n",
      "Epoch 00062: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00062: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 2.7546 - val_accuracy: 0.6225\n",
      "Epoch 63/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9902\n",
      "Epoch 00063: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00063: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 2.6442 - val_accuracy: 0.6350\n",
      "Epoch 64/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9904\n",
      "Epoch 00064: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00064: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0287 - accuracy: 0.9904 - val_loss: 2.7915 - val_accuracy: 0.6300\n",
      "Epoch 65/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9905\n",
      "Epoch 00065: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00065: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0284 - accuracy: 0.9904 - val_loss: 2.7479 - val_accuracy: 0.6250\n",
      "Epoch 66/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9910\n",
      "Epoch 00066: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00066: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 2.6862 - val_accuracy: 0.6350\n",
      "Epoch 67/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9904\n",
      "Epoch 00067: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00067: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0278 - accuracy: 0.9904 - val_loss: 2.7941 - val_accuracy: 0.6350\n",
      "Epoch 68/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9906\n",
      "Epoch 00068: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00068: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0277 - accuracy: 0.9906 - val_loss: 2.7419 - val_accuracy: 0.6350\n",
      "Epoch 69/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9912\n",
      "Epoch 00069: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00069: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 2.7777 - val_accuracy: 0.6350\n",
      "Epoch 70/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9907\n",
      "Epoch 00070: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00070: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 2.8309 - val_accuracy: 0.6250\n",
      "Epoch 71/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9908\n",
      "Epoch 00071: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00071: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 2.9207 - val_accuracy: 0.6350\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9915\n",
      "Epoch 00072: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00072: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 2.8529 - val_accuracy: 0.6275\n",
      "Epoch 73/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9912\n",
      "Epoch 00073: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00073: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 2.9092 - val_accuracy: 0.6150\n",
      "Epoch 74/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9913\n",
      "Epoch 00074: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00074: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 2.8260 - val_accuracy: 0.6200\n",
      "Epoch 75/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9911\n",
      "Epoch 00075: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00075: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0257 - accuracy: 0.9911 - val_loss: 2.8683 - val_accuracy: 0.6300\n",
      "Epoch 76/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9926\n",
      "Epoch 00076: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00076: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 2.8678 - val_accuracy: 0.6275\n",
      "Epoch 77/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9921\n",
      "Epoch 00077: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00077: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 2.9017 - val_accuracy: 0.6275\n",
      "Epoch 78/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9923\n",
      "Epoch 00078: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00078: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 2.8844 - val_accuracy: 0.6325\n",
      "Epoch 79/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9920\n",
      "Epoch 00079: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00079: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 2.9296 - val_accuracy: 0.6400\n",
      "Epoch 80/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9923\n",
      "Epoch 00080: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00080: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 2.9429 - val_accuracy: 0.6300\n",
      "Epoch 81/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9922\n",
      "Epoch 00081: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00081: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 2.9439 - val_accuracy: 0.6325\n",
      "Epoch 82/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9925\n",
      "Epoch 00082: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00082: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0223 - accuracy: 0.9924 - val_loss: 2.9745 - val_accuracy: 0.6350\n",
      "Epoch 83/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9923\n",
      "Epoch 00083: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00083: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 2.9079 - val_accuracy: 0.6400\n",
      "Epoch 84/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9921\n",
      "Epoch 00084: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00084: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0221 - accuracy: 0.9921 - val_loss: 2.9721 - val_accuracy: 0.6350\n",
      "Epoch 85/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9923\n",
      "Epoch 00085: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00085: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0219 - accuracy: 0.9923 - val_loss: 2.9391 - val_accuracy: 0.6350\n",
      "Epoch 86/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9922\n",
      "Epoch 00086: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00086: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 2.9576 - val_accuracy: 0.6325\n",
      "Epoch 87/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9925\n",
      "Epoch 00087: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00087: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 2.9523 - val_accuracy: 0.6350\n",
      "Epoch 88/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9924\n",
      "Epoch 00088: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00088: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0216 - accuracy: 0.9924 - val_loss: 3.0017 - val_accuracy: 0.6275\n",
      "Epoch 89/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9923\n",
      "Epoch 00089: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00089: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0214 - accuracy: 0.9923 - val_loss: 2.9805 - val_accuracy: 0.6325\n",
      "Epoch 90/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9922\n",
      "Epoch 00090: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00090: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 3.0089 - val_accuracy: 0.6325\n",
      "Epoch 91/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9925\n",
      "Epoch 00091: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00091: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0212 - accuracy: 0.9925 - val_loss: 3.0450 - val_accuracy: 0.6300\n",
      "Epoch 92/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9927\n",
      "Epoch 00092: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00092: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 2.9943 - val_accuracy: 0.6375\n",
      "Epoch 93/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9926\n",
      "Epoch 00093: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00093: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0211 - accuracy: 0.9926 - val_loss: 3.0069 - val_accuracy: 0.6375\n",
      "Epoch 94/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9925\n",
      "Epoch 00094: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00094: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0210 - accuracy: 0.9924 - val_loss: 3.0277 - val_accuracy: 0.6325\n",
      "Epoch 95/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9929\n",
      "Epoch 00095: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00095: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 51ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 3.0609 - val_accuracy: 0.6350\n",
      "Epoch 96/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9926\n",
      "Epoch 00096: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00096: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 3.0269 - val_accuracy: 0.6400\n",
      "Epoch 97/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9926\n",
      "Epoch 00097: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00097: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0205 - accuracy: 0.9925 - val_loss: 3.0896 - val_accuracy: 0.6325\n",
      "Epoch 98/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9929\n",
      "Epoch 00098: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00098: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0203 - accuracy: 0.9929 - val_loss: 3.0107 - val_accuracy: 0.6350\n",
      "Epoch 99/100\n",
      "309/310 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9927\n",
      "Epoch 00099: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00099: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 3.0358 - val_accuracy: 0.6350\n",
      "Epoch 100/100\n",
      "310/310 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9930\n",
      "Epoch 00100: val_accuracy did not improve from 0.68750\n",
      "\n",
      "Epoch 00100: saving model to models/ap-model_5_en.h5\n",
      "310/310 [==============================] - 16s 52ms/step - loss: 0.0202 - accuracy: 0.9930 - val_loss: 3.0862 - val_accuracy: 0.6325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4a1c2e6d30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_en = model5\n",
    "model_id = 'model_5_en'\n",
    "\n",
    "model_5_en.fit(x=train_padded_en_20,\n",
    "               y=y_train_es_20,\n",
    "               batch_size=128,\n",
    "               validation_data=(valid_padded_en_20, y_valid_en_20),\n",
    "               shuffle=True,\n",
    "               verbose=1,                \n",
    "               epochs=epochs,\n",
    "               callbacks=[configure_callbacks(model_id), scheduler_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.65      1.00      0.78        20\n",
      "        hate       1.00      0.45      0.62        20\n",
      "\n",
      "    accuracy                           0.73        40\n",
      "   macro avg       0.82      0.72      0.70        40\n",
      "weighted avg       0.82      0.72      0.70        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_5_en = load_model('models/ap-model_5_en-0002-0.687500.h5')\n",
    "predictions = model_5_en.predict(valid_padded_en_20)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### ES INDIVIDUAL TWEETS - TRAINABLE EMB COMPLEXER NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 0.5375\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.47462, saving model to models/ap-model_8_es-0001-0.474625.h5\n",
      "\n",
      "Epoch 00001: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 72s 288ms/step - loss: 0.6891 - accuracy: 0.5375 - val_loss: 0.6922 - val_accuracy: 0.4746\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6712 - accuracy: 0.5803\n",
      "Epoch 00002: val_accuracy improved from 0.47462 to 0.53962, saving model to models/ap-model_8_es-0002-0.539625.h5\n",
      "\n",
      "Epoch 00002: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.6712 - accuracy: 0.5803 - val_loss: 0.7000 - val_accuracy: 0.5396\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.5899\n",
      "Epoch 00003: val_accuracy did not improve from 0.53962\n",
      "\n",
      "Epoch 00003: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.6636 - accuracy: 0.5899 - val_loss: 0.6967 - val_accuracy: 0.4924\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6628 - accuracy: 0.5898\n",
      "Epoch 00004: val_accuracy did not improve from 0.53962\n",
      "\n",
      "Epoch 00004: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.6628 - accuracy: 0.5898 - val_loss: 0.6828 - val_accuracy: 0.5005\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6537 - accuracy: 0.5997\n",
      "Epoch 00005: val_accuracy improved from 0.53962 to 0.56775, saving model to models/ap-model_8_es-0005-0.567750.h5\n",
      "\n",
      "Epoch 00005: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.6537 - accuracy: 0.5997 - val_loss: 0.6796 - val_accuracy: 0.5677\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6265 - accuracy: 0.6520\n",
      "Epoch 00006: val_accuracy improved from 0.56775 to 0.58050, saving model to models/ap-model_8_es-0006-0.580500.h5\n",
      "\n",
      "Epoch 00006: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.6265 - accuracy: 0.6520 - val_loss: 0.6827 - val_accuracy: 0.5805\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5873 - accuracy: 0.6892\n",
      "Epoch 00007: val_accuracy improved from 0.58050 to 0.59925, saving model to models/ap-model_8_es-0007-0.599250.h5\n",
      "\n",
      "Epoch 00007: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 262ms/step - loss: 0.5873 - accuracy: 0.6892 - val_loss: 0.7014 - val_accuracy: 0.5993\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.7363\n",
      "Epoch 00008: val_accuracy did not improve from 0.59925\n",
      "\n",
      "Epoch 00008: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.5328 - accuracy: 0.7363 - val_loss: 0.7289 - val_accuracy: 0.5926\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4817 - accuracy: 0.7716\n",
      "Epoch 00009: val_accuracy did not improve from 0.59925\n",
      "\n",
      "Epoch 00009: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.4817 - accuracy: 0.7716 - val_loss: 0.7527 - val_accuracy: 0.5928\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.8018\n",
      "Epoch 00010: val_accuracy improved from 0.59925 to 0.61387, saving model to models/ap-model_8_es-0010-0.613875.h5\n",
      "\n",
      "Epoch 00010: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 266ms/step - loss: 0.4348 - accuracy: 0.8018 - val_loss: 0.7713 - val_accuracy: 0.6139\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3955 - accuracy: 0.8245\n",
      "Epoch 00011: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00011: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.3955 - accuracy: 0.8245 - val_loss: 0.8319 - val_accuracy: 0.5995\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3642 - accuracy: 0.8418\n",
      "Epoch 00012: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00012: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.3642 - accuracy: 0.8418 - val_loss: 0.9248 - val_accuracy: 0.5955\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.8596\n",
      "Epoch 00013: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00013: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 258ms/step - loss: 0.3311 - accuracy: 0.8596 - val_loss: 0.9517 - val_accuracy: 0.5935\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.8726\n",
      "Epoch 00014: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00014: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.3068 - accuracy: 0.8726 - val_loss: 1.0441 - val_accuracy: 0.5863\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.8851\n",
      "Epoch 00015: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00015: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.2811 - accuracy: 0.8851 - val_loss: 1.1158 - val_accuracy: 0.5886\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2589 - accuracy: 0.8965\n",
      "Epoch 00016: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00016: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 0.2589 - accuracy: 0.8965 - val_loss: 1.0624 - val_accuracy: 0.5820\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.9049\n",
      "Epoch 00017: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00017: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.2416 - accuracy: 0.9049 - val_loss: 1.2072 - val_accuracy: 0.5834\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9127\n",
      "Epoch 00018: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00018: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.2252 - accuracy: 0.9127 - val_loss: 1.2032 - val_accuracy: 0.5807\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9189\n",
      "Epoch 00019: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00019: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 68s 272ms/step - loss: 0.2135 - accuracy: 0.9189 - val_loss: 1.3242 - val_accuracy: 0.5854\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 0.9267\n",
      "Epoch 00020: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00020: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 73s 291ms/step - loss: 0.1984 - accuracy: 0.9267 - val_loss: 1.3475 - val_accuracy: 0.5806\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9319\n",
      "Epoch 00021: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00021: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.1861 - accuracy: 0.9319 - val_loss: 1.3898 - val_accuracy: 0.5794\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.9360\n",
      "Epoch 00022: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00022: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 68s 272ms/step - loss: 0.1731 - accuracy: 0.9360 - val_loss: 1.4003 - val_accuracy: 0.5826\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.9377\n",
      "Epoch 00023: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00023: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 68s 272ms/step - loss: 0.1701 - accuracy: 0.9377 - val_loss: 1.5007 - val_accuracy: 0.5759\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9432\n",
      "Epoch 00024: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00024: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 68s 270ms/step - loss: 0.1596 - accuracy: 0.9432 - val_loss: 1.4308 - val_accuracy: 0.5759\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.9465\n",
      "Epoch 00025: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00025: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.1526 - accuracy: 0.9465 - val_loss: 1.5400 - val_accuracy: 0.5804\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.9571\n",
      "Epoch 00026: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00026: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 63s 254ms/step - loss: 0.1281 - accuracy: 0.9571 - val_loss: 1.6238 - val_accuracy: 0.5803\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9637\n",
      "Epoch 00027: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00027: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 63s 253ms/step - loss: 0.1101 - accuracy: 0.9637 - val_loss: 1.6796 - val_accuracy: 0.5781\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9658\n",
      "Epoch 00028: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00028: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.1012 - accuracy: 0.9658 - val_loss: 1.7151 - val_accuracy: 0.5816\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9670\n",
      "Epoch 00029: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00029: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0965 - accuracy: 0.9670 - val_loss: 1.7136 - val_accuracy: 0.5757\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9687\n",
      "Epoch 00030: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00030: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0923 - accuracy: 0.9687 - val_loss: 1.9031 - val_accuracy: 0.5796\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.9696\n",
      "Epoch 00031: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00031: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0887 - accuracy: 0.9696 - val_loss: 1.9002 - val_accuracy: 0.5785\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9697\n",
      "Epoch 00032: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00032: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 63s 254ms/step - loss: 0.0865 - accuracy: 0.9697 - val_loss: 2.0640 - val_accuracy: 0.5825\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9723\n",
      "Epoch 00033: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00033: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0791 - accuracy: 0.9723 - val_loss: 2.0179 - val_accuracy: 0.5775\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9735\n",
      "Epoch 00034: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00034: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0717 - accuracy: 0.9735 - val_loss: 2.0422 - val_accuracy: 0.5830\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9748\n",
      "Epoch 00035: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00035: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0688 - accuracy: 0.9748 - val_loss: 2.0812 - val_accuracy: 0.5775\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9755\n",
      "Epoch 00036: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00036: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0674 - accuracy: 0.9755 - val_loss: 2.1469 - val_accuracy: 0.5745\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9777\n",
      "Epoch 00037: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00037: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 63s 253ms/step - loss: 0.0574 - accuracy: 0.9777 - val_loss: 2.3317 - val_accuracy: 0.5730\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9796\n",
      "Epoch 00038: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00038: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 63s 253ms/step - loss: 0.0534 - accuracy: 0.9796 - val_loss: 2.2714 - val_accuracy: 0.5751\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9806\n",
      "Epoch 00039: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00039: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0518 - accuracy: 0.9806 - val_loss: 2.2992 - val_accuracy: 0.5766\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9810\n",
      "Epoch 00040: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00040: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0518 - accuracy: 0.9810 - val_loss: 2.3591 - val_accuracy: 0.5720\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9831\n",
      "Epoch 00041: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00041: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 63s 254ms/step - loss: 0.0475 - accuracy: 0.9831 - val_loss: 2.4069 - val_accuracy: 0.5739\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9827\n",
      "Epoch 00042: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00042: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0437 - accuracy: 0.9827 - val_loss: 2.5107 - val_accuracy: 0.5779\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9857\n",
      "Epoch 00043: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00043: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.0397 - accuracy: 0.9857 - val_loss: 2.5191 - val_accuracy: 0.5769\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9868\n",
      "Epoch 00044: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00044: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0350 - accuracy: 0.9868 - val_loss: 2.6165 - val_accuracy: 0.5730\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9870\n",
      "Epoch 00045: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00045: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0346 - accuracy: 0.9870 - val_loss: 2.5905 - val_accuracy: 0.5760\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9867\n",
      "Epoch 00046: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00046: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 0.0326 - accuracy: 0.9867 - val_loss: 2.7873 - val_accuracy: 0.5766\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9882\n",
      "Epoch 00047: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00047: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 63s 254ms/step - loss: 0.0304 - accuracy: 0.9882 - val_loss: 2.8502 - val_accuracy: 0.5771\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9896\n",
      "Epoch 00048: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00048: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0271 - accuracy: 0.9896 - val_loss: 2.8672 - val_accuracy: 0.5739\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9879\n",
      "Epoch 00049: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00049: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0313 - accuracy: 0.9879 - val_loss: 2.7672 - val_accuracy: 0.5817\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9892\n",
      "Epoch 00050: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00050: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0291 - accuracy: 0.9892 - val_loss: 2.9192 - val_accuracy: 0.5732\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9928\n",
      "Epoch 00051: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00051: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0184 - accuracy: 0.9928 - val_loss: 2.9616 - val_accuracy: 0.5751\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9943\n",
      "Epoch 00052: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00052: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 63s 253ms/step - loss: 0.0139 - accuracy: 0.9943 - val_loss: 3.0591 - val_accuracy: 0.5757\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9949\n",
      "Epoch 00053: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00053: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 63s 253ms/step - loss: 0.0123 - accuracy: 0.9949 - val_loss: 3.1622 - val_accuracy: 0.5763\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9950\n",
      "Epoch 00054: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00054: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0115 - accuracy: 0.9950 - val_loss: 3.2655 - val_accuracy: 0.5770\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9954\n",
      "Epoch 00055: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00055: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0107 - accuracy: 0.9954 - val_loss: 3.3297 - val_accuracy: 0.5755\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9954\n",
      "Epoch 00056: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00056: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0101 - accuracy: 0.9954 - val_loss: 3.3780 - val_accuracy: 0.5756\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9956\n",
      "Epoch 00057: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00057: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 0.0096 - accuracy: 0.9956 - val_loss: 3.4702 - val_accuracy: 0.5759\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9958\n",
      "Epoch 00058: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00058: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0092 - accuracy: 0.9958 - val_loss: 3.5116 - val_accuracy: 0.5767\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9956\n",
      "Epoch 00059: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00059: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 263ms/step - loss: 0.0089 - accuracy: 0.9956 - val_loss: 3.5497 - val_accuracy: 0.5765\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9958\n",
      "Epoch 00060: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00060: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0083 - accuracy: 0.9958 - val_loss: 3.6302 - val_accuracy: 0.5757\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9958\n",
      "Epoch 00061: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00061: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0079 - accuracy: 0.9958 - val_loss: 3.6851 - val_accuracy: 0.5754\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9963\n",
      "Epoch 00062: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00062: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0076 - accuracy: 0.9963 - val_loss: 3.7081 - val_accuracy: 0.5771\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9961\n",
      "Epoch 00063: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00063: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0073 - accuracy: 0.9961 - val_loss: 3.7675 - val_accuracy: 0.5755\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9965\n",
      "Epoch 00064: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00064: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0069 - accuracy: 0.9965 - val_loss: 3.8421 - val_accuracy: 0.5767\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9965\n",
      "Epoch 00065: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00065: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0066 - accuracy: 0.9965 - val_loss: 3.9278 - val_accuracy: 0.5756\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9965\n",
      "Epoch 00066: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00066: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 263ms/step - loss: 0.0066 - accuracy: 0.9965 - val_loss: 3.8685 - val_accuracy: 0.5751\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9966\n",
      "Epoch 00067: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00067: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0066 - accuracy: 0.9966 - val_loss: 3.8977 - val_accuracy: 0.5759\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9959\n",
      "Epoch 00068: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00068: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0074 - accuracy: 0.9959 - val_loss: 3.9265 - val_accuracy: 0.5763\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9967\n",
      "Epoch 00069: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00069: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0064 - accuracy: 0.9967 - val_loss: 3.9515 - val_accuracy: 0.5756\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9967\n",
      "Epoch 00070: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00070: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0059 - accuracy: 0.9967 - val_loss: 4.0561 - val_accuracy: 0.5744\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9966\n",
      "Epoch 00071: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00071: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 0.0059 - accuracy: 0.9966 - val_loss: 3.9827 - val_accuracy: 0.5731\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9968\n",
      "Epoch 00072: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00072: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0057 - accuracy: 0.9968 - val_loss: 4.0516 - val_accuracy: 0.5744\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9963\n",
      "Epoch 00073: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00073: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0058 - accuracy: 0.9963 - val_loss: 4.0923 - val_accuracy: 0.5761\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9968\n",
      "Epoch 00074: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00074: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 263ms/step - loss: 0.0054 - accuracy: 0.9968 - val_loss: 4.0919 - val_accuracy: 0.5760\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9969\n",
      "Epoch 00075: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00075: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 263ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 4.1366 - val_accuracy: 0.5756\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9972\n",
      "Epoch 00076: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00076: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.0045 - accuracy: 0.9972 - val_loss: 4.1338 - val_accuracy: 0.5763\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9974\n",
      "Epoch 00077: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00077: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 67s 270ms/step - loss: 0.0044 - accuracy: 0.9974 - val_loss: 4.1465 - val_accuracy: 0.5750\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9972\n",
      "Epoch 00078: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00078: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 68s 271ms/step - loss: 0.0043 - accuracy: 0.9972 - val_loss: 4.2073 - val_accuracy: 0.5750\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9973\n",
      "Epoch 00079: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00079: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 68s 270ms/step - loss: 0.0043 - accuracy: 0.9973 - val_loss: 4.2241 - val_accuracy: 0.5750\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9973\n",
      "Epoch 00080: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00080: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.0043 - accuracy: 0.9973 - val_loss: 4.2376 - val_accuracy: 0.5755\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9971\n",
      "Epoch 00081: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00081: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 70s 279ms/step - loss: 0.0042 - accuracy: 0.9971 - val_loss: 4.2706 - val_accuracy: 0.5767\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9970\n",
      "Epoch 00082: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00082: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 69s 276ms/step - loss: 0.0043 - accuracy: 0.9970 - val_loss: 4.2660 - val_accuracy: 0.5757\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9974\n",
      "Epoch 00083: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00083: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 70s 281ms/step - loss: 0.0043 - accuracy: 0.9974 - val_loss: 4.2744 - val_accuracy: 0.5754\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9973\n",
      "Epoch 00084: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00084: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 70s 281ms/step - loss: 0.0042 - accuracy: 0.9973 - val_loss: 4.3048 - val_accuracy: 0.5756\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9973\n",
      "Epoch 00085: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00085: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 72s 288ms/step - loss: 0.0042 - accuracy: 0.9973 - val_loss: 4.3376 - val_accuracy: 0.5746\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9972\n",
      "Epoch 00086: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00086: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 72s 287ms/step - loss: 0.0042 - accuracy: 0.9972 - val_loss: 4.3783 - val_accuracy: 0.5754\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9974\n",
      "Epoch 00087: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00087: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 69s 276ms/step - loss: 0.0041 - accuracy: 0.9974 - val_loss: 4.3572 - val_accuracy: 0.5756\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9973\n",
      "Epoch 00088: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00088: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 69s 276ms/step - loss: 0.0042 - accuracy: 0.9973 - val_loss: 4.3761 - val_accuracy: 0.5750\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9971\n",
      "Epoch 00089: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00089: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.0045 - accuracy: 0.9971 - val_loss: 4.3081 - val_accuracy: 0.5740\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9971\n",
      "Epoch 00090: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00090: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 67s 269ms/step - loss: 0.0042 - accuracy: 0.9971 - val_loss: 4.3310 - val_accuracy: 0.5748\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9972\n",
      "Epoch 00091: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00091: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 262ms/step - loss: 0.0040 - accuracy: 0.9972 - val_loss: 4.3670 - val_accuracy: 0.5720\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9973\n",
      "Epoch 00092: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00092: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 262ms/step - loss: 0.0040 - accuracy: 0.9973 - val_loss: 4.3928 - val_accuracy: 0.5749\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9975\n",
      "Epoch 00093: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00093: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.0039 - accuracy: 0.9975 - val_loss: 4.3814 - val_accuracy: 0.5738\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9973\n",
      "Epoch 00094: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00094: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 68s 271ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 4.4195 - val_accuracy: 0.5753\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9975\n",
      "Epoch 00095: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00095: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 258ms/step - loss: 0.0039 - accuracy: 0.9975 - val_loss: 4.4085 - val_accuracy: 0.5734\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9974\n",
      "Epoch 00096: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00096: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0039 - accuracy: 0.9974 - val_loss: 4.4580 - val_accuracy: 0.5746\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9972\n",
      "Epoch 00097: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00097: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0039 - accuracy: 0.9972 - val_loss: 4.4149 - val_accuracy: 0.5739\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9972\n",
      "Epoch 00098: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00098: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0039 - accuracy: 0.9972 - val_loss: 4.4612 - val_accuracy: 0.5750\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9973\n",
      "Epoch 00099: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00099: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 4.4194 - val_accuracy: 0.5727\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9973\n",
      "Epoch 00100: val_accuracy did not improve from 0.61387\n",
      "\n",
      "Epoch 00100: saving model to models/ap-model_8_es.h5\n",
      "250/250 [==============================] - 65s 258ms/step - loss: 0.0041 - accuracy: 0.9973 - val_loss: 4.4425 - val_accuracy: 0.5731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4a1c2b4ac8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8_es = model8\n",
    "model_id = 'model_8_es'\n",
    "\n",
    "model_8_es.fit(x=train_padded_es_indv,\n",
    "               y=y_train_es_indv,               \n",
    "               batch_size=128,\n",
    "               validation_data=(valid_padded_es_indv, y_valid_es_indv),\n",
    "               shuffle=True,\n",
    "               verbose=1,                \n",
    "               epochs=epochs,\n",
    "               callbacks=[configure_callbacks(model_id), scheduler_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.87      0.65      0.74        20\n",
      "        hate       0.72      0.90      0.80        20\n",
      "\n",
      "    accuracy                           0.78        40\n",
      "   macro avg       0.79      0.78      0.77        40\n",
      "weighted avg       0.79      0.78      0.77        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_8_es = load_model('models/ap-model_8_es-0010-0.613875.h5')\n",
    "predictions = model_8_es.predict(valid_padded_es_indv)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### EN INDIVIDUAL TWEETS - TRAINABLE EMB COMPLEXER NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.9166\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58025, saving model to models/ap-model_8_en-0001-0.580250.h5\n",
      "\n",
      "Epoch 00001: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.2226 - accuracy: 0.9166 - val_loss: 1.3019 - val_accuracy: 0.5803\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9500\n",
      "Epoch 00002: val_accuracy did not improve from 0.58025\n",
      "\n",
      "Epoch 00002: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.1390 - accuracy: 0.9500 - val_loss: 1.6027 - val_accuracy: 0.5742\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9654\n",
      "Epoch 00003: val_accuracy improved from 0.58025 to 0.58300, saving model to models/ap-model_8_en-0003-0.583000.h5\n",
      "\n",
      "Epoch 00003: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0960 - accuracy: 0.9654 - val_loss: 1.9049 - val_accuracy: 0.5830\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9734\n",
      "Epoch 00004: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00004: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.0728 - accuracy: 0.9734 - val_loss: 2.0374 - val_accuracy: 0.5746\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9794\n",
      "Epoch 00005: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00005: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0595 - accuracy: 0.9794 - val_loss: 2.0936 - val_accuracy: 0.5763\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9808\n",
      "Epoch 00006: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00006: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0524 - accuracy: 0.9808 - val_loss: 2.2441 - val_accuracy: 0.5791\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9840\n",
      "Epoch 00007: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00007: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0445 - accuracy: 0.9840 - val_loss: 2.3084 - val_accuracy: 0.5753\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9848\n",
      "Epoch 00008: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00008: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0408 - accuracy: 0.9848 - val_loss: 2.3635 - val_accuracy: 0.5795\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9873\n",
      "Epoch 00009: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00009: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.0358 - accuracy: 0.9873 - val_loss: 2.4757 - val_accuracy: 0.5769\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9888\n",
      "Epoch 00010: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00010: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.0321 - accuracy: 0.9888 - val_loss: 2.5122 - val_accuracy: 0.5717\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9895\n",
      "Epoch 00011: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00011: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0291 - accuracy: 0.9895 - val_loss: 2.5553 - val_accuracy: 0.5785\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9902\n",
      "Epoch 00012: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00012: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0272 - accuracy: 0.9902 - val_loss: 2.7029 - val_accuracy: 0.5764\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9910\n",
      "Epoch 00013: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00013: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0247 - accuracy: 0.9910 - val_loss: 2.6552 - val_accuracy: 0.5738\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9916\n",
      "Epoch 00014: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00014: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0227 - accuracy: 0.9916 - val_loss: 2.9206 - val_accuracy: 0.5754\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9897\n",
      "Epoch 00015: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00015: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.0279 - accuracy: 0.9897 - val_loss: 2.7097 - val_accuracy: 0.5724\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9900\n",
      "Epoch 00016: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00016: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0278 - accuracy: 0.9900 - val_loss: 2.7711 - val_accuracy: 0.5765\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9923\n",
      "Epoch 00017: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00017: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0221 - accuracy: 0.9923 - val_loss: 2.9134 - val_accuracy: 0.5780\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9924\n",
      "Epoch 00018: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00018: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0199 - accuracy: 0.9924 - val_loss: 2.7495 - val_accuracy: 0.5731\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9938\n",
      "Epoch 00019: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00019: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0166 - accuracy: 0.9938 - val_loss: 3.0649 - val_accuracy: 0.5707\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9925\n",
      "Epoch 00020: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00020: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.0201 - accuracy: 0.9925 - val_loss: 2.8269 - val_accuracy: 0.5696\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9928\n",
      "Epoch 00021: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00021: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 2.7941 - val_accuracy: 0.5792\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9925\n",
      "Epoch 00022: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00022: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0208 - accuracy: 0.9925 - val_loss: 2.7282 - val_accuracy: 0.5796\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9936\n",
      "Epoch 00023: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00023: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0172 - accuracy: 0.9936 - val_loss: 3.0668 - val_accuracy: 0.5766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9933\n",
      "Epoch 00024: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00024: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 258ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 2.9177 - val_accuracy: 0.5792\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9931\n",
      "Epoch 00025: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00025: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 2.6301 - val_accuracy: 0.5798\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9957\n",
      "Epoch 00026: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00026: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0100 - accuracy: 0.9957 - val_loss: 3.0834 - val_accuracy: 0.5757\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9970\n",
      "Epoch 00027: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00027: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 68s 272ms/step - loss: 0.0064 - accuracy: 0.9970 - val_loss: 3.2490 - val_accuracy: 0.5767\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9972\n",
      "Epoch 00028: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00028: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0054 - accuracy: 0.9972 - val_loss: 3.3845 - val_accuracy: 0.5771\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9970\n",
      "Epoch 00029: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00029: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0053 - accuracy: 0.9970 - val_loss: 3.4160 - val_accuracy: 0.5753\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9972\n",
      "Epoch 00030: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00030: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0049 - accuracy: 0.9972 - val_loss: 3.4675 - val_accuracy: 0.5779\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9973\n",
      "Epoch 00031: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00031: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0048 - accuracy: 0.9973 - val_loss: 3.5334 - val_accuracy: 0.5792\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9973\n",
      "Epoch 00032: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00032: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 266ms/step - loss: 0.0049 - accuracy: 0.9973 - val_loss: 3.6207 - val_accuracy: 0.5749\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9971\n",
      "Epoch 00033: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00033: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.0055 - accuracy: 0.9971 - val_loss: 3.6124 - val_accuracy: 0.5795\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9973\n",
      "Epoch 00034: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00034: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 0.0049 - accuracy: 0.9973 - val_loss: 3.6660 - val_accuracy: 0.5790\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9966\n",
      "Epoch 00035: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00035: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0065 - accuracy: 0.9966 - val_loss: 3.5999 - val_accuracy: 0.5729\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9971\n",
      "Epoch 00036: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00036: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0055 - accuracy: 0.9971 - val_loss: 3.8083 - val_accuracy: 0.5785\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9964\n",
      "Epoch 00037: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00037: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 3.5911 - val_accuracy: 0.5819\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9964\n",
      "Epoch 00038: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00038: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 68s 271ms/step - loss: 0.0080 - accuracy: 0.9964 - val_loss: 3.5984 - val_accuracy: 0.5792\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9962\n",
      "Epoch 00039: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00039: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0078 - accuracy: 0.9962 - val_loss: 3.6116 - val_accuracy: 0.5770\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9969\n",
      "Epoch 00040: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00040: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 68s 272ms/step - loss: 0.0064 - accuracy: 0.9969 - val_loss: 3.7124 - val_accuracy: 0.5767\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9973\n",
      "Epoch 00041: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00041: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.0047 - accuracy: 0.9973 - val_loss: 3.7759 - val_accuracy: 0.5750\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9973\n",
      "Epoch 00042: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00042: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.0045 - accuracy: 0.9973 - val_loss: 3.9414 - val_accuracy: 0.5792\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9970\n",
      "Epoch 00043: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00043: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 266ms/step - loss: 0.0050 - accuracy: 0.9970 - val_loss: 3.9370 - val_accuracy: 0.5763\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9966\n",
      "Epoch 00044: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00044: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.0064 - accuracy: 0.9966 - val_loss: 3.8237 - val_accuracy: 0.5798\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9970\n",
      "Epoch 00045: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00045: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 68s 272ms/step - loss: 0.0052 - accuracy: 0.9970 - val_loss: 3.8496 - val_accuracy: 0.5801\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9972\n",
      "Epoch 00046: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00046: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 70s 279ms/step - loss: 0.0041 - accuracy: 0.9972 - val_loss: 3.9735 - val_accuracy: 0.5794\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9973\n",
      "Epoch 00047: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00047: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.0041 - accuracy: 0.9973 - val_loss: 3.9049 - val_accuracy: 0.5785\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9969\n",
      "Epoch 00048: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00048: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 4.0123 - val_accuracy: 0.5790\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9950\n",
      "Epoch 00049: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00049: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0114 - accuracy: 0.9950 - val_loss: 3.4569 - val_accuracy: 0.5778\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9958\n",
      "Epoch 00050: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00050: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 263ms/step - loss: 0.0101 - accuracy: 0.9958 - val_loss: 3.5321 - val_accuracy: 0.5766\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9976\n",
      "Epoch 00051: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00051: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 3.6421 - val_accuracy: 0.5778\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9977\n",
      "Epoch 00052: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00052: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0038 - accuracy: 0.9977 - val_loss: 3.6957 - val_accuracy: 0.5778\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9977\n",
      "Epoch 00053: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00053: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0036 - accuracy: 0.9977 - val_loss: 3.7427 - val_accuracy: 0.5785\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9976\n",
      "Epoch 00054: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00054: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 0.0035 - accuracy: 0.9976 - val_loss: 3.7929 - val_accuracy: 0.5789\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9974\n",
      "Epoch 00055: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00055: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0035 - accuracy: 0.9974 - val_loss: 3.8279 - val_accuracy: 0.5784\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9976\n",
      "Epoch 00056: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00056: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0034 - accuracy: 0.9976 - val_loss: 3.8730 - val_accuracy: 0.5785\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9976\n",
      "Epoch 00057: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00057: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0034 - accuracy: 0.9976 - val_loss: 3.8967 - val_accuracy: 0.5801\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9977\n",
      "Epoch 00058: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00058: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 0.0034 - accuracy: 0.9977 - val_loss: 3.9425 - val_accuracy: 0.5809\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9977\n",
      "Epoch 00059: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00059: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 263ms/step - loss: 0.0034 - accuracy: 0.9977 - val_loss: 3.9735 - val_accuracy: 0.5806\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9976\n",
      "Epoch 00060: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00060: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0034 - accuracy: 0.9976 - val_loss: 4.0017 - val_accuracy: 0.5782\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9975\n",
      "Epoch 00061: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00061: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 261ms/step - loss: 0.0033 - accuracy: 0.9975 - val_loss: 4.0244 - val_accuracy: 0.5806\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9974\n",
      "Epoch 00062: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00062: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.0033 - accuracy: 0.9974 - val_loss: 4.0520 - val_accuracy: 0.5810\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9976\n",
      "Epoch 00063: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00063: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0033 - accuracy: 0.9976 - val_loss: 4.0631 - val_accuracy: 0.5804\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9975\n",
      "Epoch 00064: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00064: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0033 - accuracy: 0.9975 - val_loss: 4.0925 - val_accuracy: 0.5809\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9976\n",
      "Epoch 00065: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00065: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 258ms/step - loss: 0.0033 - accuracy: 0.9976 - val_loss: 4.1059 - val_accuracy: 0.5809\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9975\n",
      "Epoch 00066: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00066: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0033 - accuracy: 0.9975 - val_loss: 4.1098 - val_accuracy: 0.5810\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9976\n",
      "Epoch 00067: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00067: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 0.0033 - accuracy: 0.9976 - val_loss: 4.1412 - val_accuracy: 0.5807\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9973\n",
      "Epoch 00068: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00068: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0033 - accuracy: 0.9973 - val_loss: 4.1555 - val_accuracy: 0.5795\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9974\n",
      "Epoch 00069: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00069: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0033 - accuracy: 0.9974 - val_loss: 4.1627 - val_accuracy: 0.5805\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9977\n",
      "Epoch 00070: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00070: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0033 - accuracy: 0.9977 - val_loss: 4.1913 - val_accuracy: 0.5814\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9975\n",
      "Epoch 00071: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00071: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0033 - accuracy: 0.9975 - val_loss: 4.2022 - val_accuracy: 0.5799\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9974\n",
      "Epoch 00072: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00072: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0033 - accuracy: 0.9974 - val_loss: 4.2111 - val_accuracy: 0.5810\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9974\n",
      "Epoch 00073: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00073: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0033 - accuracy: 0.9974 - val_loss: 4.2595 - val_accuracy: 0.5769\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9976\n",
      "Epoch 00074: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00074: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 67s 269ms/step - loss: 0.0033 - accuracy: 0.9976 - val_loss: 4.2028 - val_accuracy: 0.5796\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9974\n",
      "Epoch 00075: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00075: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 262ms/step - loss: 0.0033 - accuracy: 0.9974 - val_loss: 4.2366 - val_accuracy: 0.5776\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9976\n",
      "Epoch 00076: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00076: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0032 - accuracy: 0.9976 - val_loss: 4.2509 - val_accuracy: 0.5794\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9977\n",
      "Epoch 00077: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00077: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.0031 - accuracy: 0.9977 - val_loss: 4.2611 - val_accuracy: 0.5800\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9976\n",
      "Epoch 00078: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00078: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 67s 266ms/step - loss: 0.0031 - accuracy: 0.9976 - val_loss: 4.2806 - val_accuracy: 0.5796\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9976\n",
      "Epoch 00079: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00079: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.0031 - accuracy: 0.9976 - val_loss: 4.2875 - val_accuracy: 0.5796\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9974\n",
      "Epoch 00080: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00080: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.0031 - accuracy: 0.9974 - val_loss: 4.2955 - val_accuracy: 0.5799\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9973\n",
      "Epoch 00081: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00081: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0031 - accuracy: 0.9973 - val_loss: 4.3109 - val_accuracy: 0.5795\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9977\n",
      "Epoch 00082: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00082: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.0031 - accuracy: 0.9977 - val_loss: 4.3189 - val_accuracy: 0.5798\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9976\n",
      "Epoch 00083: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00083: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0031 - accuracy: 0.9976 - val_loss: 4.3304 - val_accuracy: 0.5803\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9974\n",
      "Epoch 00084: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00084: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0031 - accuracy: 0.9974 - val_loss: 4.3441 - val_accuracy: 0.5799\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9976\n",
      "Epoch 00085: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00085: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.0031 - accuracy: 0.9976 - val_loss: 4.3443 - val_accuracy: 0.5809\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9974\n",
      "Epoch 00086: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00086: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0031 - accuracy: 0.9974 - val_loss: 4.3510 - val_accuracy: 0.5792\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9975\n",
      "Epoch 00087: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00087: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 0.0031 - accuracy: 0.9975 - val_loss: 4.3463 - val_accuracy: 0.5817\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9975\n",
      "Epoch 00088: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00088: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 0.0031 - accuracy: 0.9975 - val_loss: 4.3541 - val_accuracy: 0.5815\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9974\n",
      "Epoch 00089: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00089: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 68s 273ms/step - loss: 0.0031 - accuracy: 0.9974 - val_loss: 4.3666 - val_accuracy: 0.5805\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9977\n",
      "Epoch 00090: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00090: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 74s 296ms/step - loss: 0.0031 - accuracy: 0.9977 - val_loss: 4.3737 - val_accuracy: 0.5792\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9976\n",
      "Epoch 00091: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00091: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 68s 274ms/step - loss: 0.0031 - accuracy: 0.9976 - val_loss: 4.3730 - val_accuracy: 0.5821\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9974\n",
      "Epoch 00092: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00092: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 67s 269ms/step - loss: 0.0031 - accuracy: 0.9974 - val_loss: 4.3819 - val_accuracy: 0.5807\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9974\n",
      "Epoch 00093: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00093: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 262ms/step - loss: 0.0031 - accuracy: 0.9974 - val_loss: 4.3914 - val_accuracy: 0.5803\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9975\n",
      "Epoch 00094: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00094: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 68s 271ms/step - loss: 0.0031 - accuracy: 0.9975 - val_loss: 4.3925 - val_accuracy: 0.5814\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9974\n",
      "Epoch 00095: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00095: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 68s 272ms/step - loss: 0.0031 - accuracy: 0.9974 - val_loss: 4.3945 - val_accuracy: 0.5804\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9977\n",
      "Epoch 00096: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00096: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0031 - accuracy: 0.9977 - val_loss: 4.4024 - val_accuracy: 0.5815\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9974\n",
      "Epoch 00097: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00097: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 266ms/step - loss: 0.0031 - accuracy: 0.9974 - val_loss: 4.4117 - val_accuracy: 0.5803\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9977\n",
      "Epoch 00098: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00098: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.0031 - accuracy: 0.9977 - val_loss: 4.4111 - val_accuracy: 0.5811\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9974\n",
      "Epoch 00099: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00099: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.0031 - accuracy: 0.9974 - val_loss: 4.4164 - val_accuracy: 0.5807\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9974\n",
      "Epoch 00100: val_accuracy did not improve from 0.58300\n",
      "\n",
      "Epoch 00100: saving model to models/ap-model_8_en.h5\n",
      "250/250 [==============================] - 68s 274ms/step - loss: 0.0031 - accuracy: 0.9974 - val_loss: 4.4172 - val_accuracy: 0.5809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4a0c479588>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8_en = model8\n",
    "model_id = 'model_8_en'\n",
    "\n",
    "model_8_en.fit(x=train_padded_en_indv,\n",
    "               y=y_train_en_indv,               \n",
    "               batch_size=128,\n",
    "               validation_data=(valid_padded_en_indv, y_valid_en_indv),\n",
    "               shuffle=True,\n",
    "               verbose=1,                \n",
    "               epochs=epochs,\n",
    "               callbacks=[configure_callbacks(model_id), scheduler_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.83      0.75      0.79        20\n",
      "        hate       0.77      0.85      0.81        20\n",
      "\n",
      "    accuracy                           0.80        40\n",
      "   macro avg       0.80      0.80      0.80        40\n",
      "weighted avg       0.80      0.80      0.80        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_8_en = load_model('models/ap-model_8_en-0003-0.583000.h5')\n",
    "predictions = model_8_en.predict(valid_padded_en_indv)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### ES 20 JOINED TWEETS - TRAINABLE EMB COMPLEXER NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_10_es = model10\n",
    "model_id = 'model_10_es'\n",
    "\n",
    "model_10_es.fit(x=train_padded_es_20,\n",
    "                y=y_train_es_20,\n",
    "                batch_size=128,\n",
    "                validation_data=(valid_padded_es_20, y_valid_es_20),\n",
    "                shuffle=True,\n",
    "                verbose=1,                \n",
    "                epochs=epochs,\n",
    "                callbacks=[configure_callbacks(model_id), scheduler_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.67      1.00      0.80        20\n",
      "        hate       1.00      0.50      0.67        20\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.83      0.75      0.73        40\n",
      "weighted avg       0.83      0.75      0.73        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_10_es = load_model('models/ap-model_10_es-0002-0.727500.h5')\n",
    "predictions = model_10_es.predict(valid_padded_es_20)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### EN 20 JOINED TWEETS - TRAINABLE EMB COMPLEXER NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_10_en = model10\n",
    "model_id = 'model_10_en'\n",
    "\n",
    "model_10_en.fit(x=train_padded_en_20,\n",
    "                y=y_train_en_20,\n",
    "                batch_size=128\n",
    "                validation_data=(valid_padded_en_20, y_valid_en_20),\n",
    "                shuffle=True,\n",
    "                verbose=1,                \n",
    "                epochs=epochs,\n",
    "                callbacks=[configure_callbacks(model_id), scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.65      1.00      0.78        20\n",
      "        hate       1.00      0.45      0.62        20\n",
      "\n",
      "    accuracy                           0.73        40\n",
      "   macro avg       0.82      0.72      0.70        40\n",
      "weighted avg       0.82      0.72      0.70        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_10_en = load_model('models/ap-model_10_en-0078-0.660000.h5')\n",
    "predictions = model_10_en.predict(valid_padded_en_20)\n",
    "author_profiling_report(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.43      0.38      0.40        50\n",
      "        hate       0.45      0.50      0.47        50\n",
      "\n",
      "    accuracy                           0.44       100\n",
      "   macro avg       0.44      0.44      0.44       100\n",
      "weighted avg       0.44      0.44      0.44       100\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.43      0.38      0.40        50\n",
      "        hate       0.45      0.50      0.47        50\n",
      "\n",
      "    accuracy                           0.44       100\n",
      "   macro avg       0.44      0.44      0.44       100\n",
      "weighted avg       0.44      0.44      0.44       100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "pipe = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(ngram_range=(3,6),\n",
    "                                 max_df=0.9,\n",
    "                                 min_df=1,\n",
    "                                 analyzer=\"char_wb\")),\n",
    "        (\"clf\", LogisticRegression(C=1))\n",
    "])\n",
    "\n",
    "pipe.fit(x_train_es, y_train_es)\n",
    "predictions = pipe.predict(x_test_es)\n",
    "author_profiling_report(predictions, number_authors=100)\n",
    "\n",
    "pipe.fit(x_train_en, y_train_en)\n",
    "predictions = pipe.predict(x_test_en)\n",
    "author_profiling_report(predictions, number_authors=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.50      0.16      0.24        50\n",
      "        hate       0.50      0.84      0.63        50\n",
      "\n",
      "    accuracy                           0.50       100\n",
      "   macro avg       0.50      0.50      0.43       100\n",
      "weighted avg       0.50      0.50      0.43       100\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.55      0.48      0.51        50\n",
      "        hate       0.54      0.60      0.57        50\n",
      "\n",
      "    accuracy                           0.54       100\n",
      "   macro avg       0.54      0.54      0.54       100\n",
      "weighted avg       0.54      0.54      0.54       100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 5 indv\n",
    "model_5_es = load_model('models/ap-model_5_es-0008-0.732500.h5')\n",
    "predictions = model_5_es.predict(test_padded_es_20)\n",
    "author_profiling_report(predictions, number_authors=100)\n",
    "\n",
    "model_5_en = load_model('models/ap-model_5_en-0002-0.687500.h5')\n",
    "predictions = model_5_en.predict(test_padded_en_20)\n",
    "author_profiling_report(predictions, number_authors=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.51      0.86      0.64        50\n",
      "        hate       0.56      0.18      0.27        50\n",
      "\n",
      "    accuracy                           0.52       100\n",
      "   macro avg       0.54      0.52      0.46       100\n",
      "weighted avg       0.54      0.52      0.46       100\n",
      "\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.48      0.66      0.55        50\n",
      "        hate       0.45      0.28      0.35        50\n",
      "\n",
      "    accuracy                           0.47       100\n",
      "   macro avg       0.46      0.47      0.45       100\n",
      "weighted avg       0.46      0.47      0.45       100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 8 20 joined\n",
    "model_8_es = load_model('models/ap-model_8_es-0010-0.613875.h5')\n",
    "predictions = model_8_es.predict(test_padded_en_indv)\n",
    "author_profiling_report(predictions, number_authors=100)\n",
    "\n",
    "model_8_en = load_model('models/ap-model_8_en-0003-0.583000.h5')\n",
    "predictions = model_8_en.predict(test_padded_en_indv)\n",
    "author_profiling_report(predictions, number_authors=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open('test_es_20.pickle', 'rb')\n",
    "test_es_20 = pickle.load(pickle_file)\n",
    "\n",
    "test_id_es, x_test_es = test_es_20[0], test_es_20[1]\n",
    "\n",
    "pickle_file = open('test_en_20.pickle', 'rb')\n",
    "test_en_20 = pickle.load(pickle_file)\n",
    "\n",
    "test_id_en, x_test_en = test_en_20[0], test_en_20[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5 indv\n",
    "model_5_es = load_model('models/ap-model_5_es-0008-0.732500.h5')\n",
    "predictions_es = model_5_es.predict(x_test_es)\n",
    "\n",
    "model_5_en = load_model('models/ap-model_5_en-0002-0.687500.h5')\n",
    "predictions_en = model_5_en.predict(x_test_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test_en), len(predictions_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.50      0.16      0.24        50\n",
      "        hate       0.50      0.84      0.63        50\n",
      "\n",
      "    accuracy                           0.50       100\n",
      "   macro avg       0.50      0.50      0.43       100\n",
      "weighted avg       0.50      0.50      0.43       100\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.55      0.48      0.51        50\n",
      "        hate       0.54      0.60      0.57        50\n",
      "\n",
      "    accuracy                           0.54       100\n",
      "   macro avg       0.54      0.54      0.54       100\n",
      "weighted avg       0.54      0.54      0.54       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_es = author_profiling_report(predictions_es, number_authors=100)\n",
    "predictions_en = author_profiling_report(predictions_en, number_authors=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = []\n",
    "for i in range(0, len(test_id_es), 10):\n",
    "    aux.append(test_id_es[i])\n",
    "test_id_es = aux\n",
    "len(test_id_es), len(predictions_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = []\n",
    "for i in range(0, len(test_id_en), 10):\n",
    "    aux.append(test_id_en[i])\n",
    "test_id_en = aux\n",
    "len(test_id_en), len(predictions_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 authors 100 tweets in test\n",
    "# txt output\n",
    "# <author id=\"author-id\" lang=\"en|es\" type=\"0|1\"/>\n",
    "def format_output(author_predictions, authors, lang):\n",
    "    for i in range(len(author_predictions)):\n",
    "        root = ET.Element(\"author\")\n",
    "        root.set(\"id\", str(authors[i]))\n",
    "        root.set(\"lang\", lang)\n",
    "        root.set(\"type\", str(author_predictions[i]))\n",
    "\n",
    "        tree = ET.ElementTree(root)\n",
    "        xml_str = ET.tostring(root).decode('utf8')\n",
    "\n",
    "        save_path_file = f'results/{lang}/{authors[i]}.xml'\n",
    "\n",
    "        with open(save_path_file, \"w\") as f:\n",
    "            f.write(xml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_output(predictions_es, test_id_es, \"es\")\n",
    "format_output(predictions_en, test_id_en, \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
