{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO: Regular Expressions (python 3.x)\n",
    "\n",
    "https://docs.python.org/3/library/re.html\n",
    "\n",
    "https://docs.python.org/3/howto/regex.html#regex-howto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# EJERCICIO 1: Quitar los signos de puntuación de la siguiente cadena:  ??. ppi. ¿casa?.. COSA. ??perro. ¿quesito? \"qüestió\" anar-hi.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 9), match='??. ppi. '>\n",
      "??. \n",
      "ppi\n",
      ". \n",
      "->name:  ??. \n",
      "(0, 9)\n",
      "0\n",
      "9\n",
      "cadena= ??. ppi. \n",
      "<_sre.SRE_Match object; span=(0, 9), match='la la lam'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "frase=\"??. ppi. PEPE ¿casa?.. COSA. ??perro. ¿quesito? qüestió anar-hi.\"\n",
    "x=re.match(r'(?P<principi>\\W*)(\\w+)(\\W*)', frase)\n",
    "print(x)\n",
    "print (x.group(1))\n",
    "print (x.group(2))\n",
    "print (x.group(3))\n",
    "print (\"->name: \",x.group('principi'))\n",
    "print (x.span())\n",
    "print (x.start())\n",
    "print (x.end())\n",
    "cadena=frase[x.start():x.end()]\n",
    "print (\"cadena=\",cadena)\n",
    "print (re.match(r'(la) \\1 (lam)',\"la la lam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "frase='\"t1 t2 t3 t4\"'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "t1\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Compilar la expresion\n",
    "pattern=re.compile (r'(\\W*)(\\w+)(\\W*)',re.I|re.U) \n",
    "#pattern es la expresión regular compilada, y sobre ella se pueden utilizar los métodos match, search, findall, ...\n",
    "\n",
    "#Match: al principio de la cadena\n",
    "\n",
    "mat=pattern.match(frase)\n",
    "if mat:\n",
    "    print (mat.group(1))\n",
    "    print (mat.group(2))\n",
    "    print (mat.group(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "t1\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Search: la primera que encuentra en la cadena\n",
    "sear=pattern.search(frase)\n",
    "if sear:\n",
    "    print (sear.group(1))\n",
    "    print (sear.group(2))\n",
    "    print (sear.group(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<_sre.SRE_Match object; span=(0, 4), match='\"t1 '>, <_sre.SRE_Match object; span=(4, 7), match='t2 '>, <_sre.SRE_Match object; span=(7, 10), match='t3 '>, <_sre.SRE_Match object; span=(10, 13), match='t4\"'>]\n"
     ]
    }
   ],
   "source": [
    "#Finditer: Todas las ocurrencias de la cadena\n",
    "fiiter=pattern.finditer(frase)\n",
    "print ([x for x in fiiter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "t1\n",
      " \n",
      "\n",
      "t2\n",
      " \n",
      "\n",
      "t3\n",
      " \n",
      "\n",
      "t4\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "#Finditer:\n",
    "fiiter=pattern.finditer(frase)\n",
    "for i in fiiter:\n",
    "    print (i.group(1))\n",
    "    print (i.group(2))\n",
    "    print (i.group(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\"', 't1', ' '), ('', 't2', ' '), ('', 't3', ' '), ('', 't4', '\"')]\n",
      "t1\n",
      "t2\n",
      "t3\n",
      "t4\n"
     ]
    }
   ],
   "source": [
    "# Findall: Totes las ocurrencias de la cadena\n",
    "fiall=pattern.findall(frase)\n",
    "print (fiall)\n",
    "for i in fiall:\n",
    "    print (i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 2: \"sustituye la palabra eso por  3 guiones, pero OJO con queso, o beso, o en ESO en mayúsculas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sustituye la palabra eso por  3 guiones, pero OJO con: queso, o beso; ESO en mayúsculas sí.\n",
      "sustituye la palabra --- por  3 guiones, pero OJO con: queso, o beso; --- en mayúsculas sí.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "frase1='sustituye la palabra eso por  3 guiones, pero OJO con: queso, o beso; ESO en mayúsculas sí.'\n",
    "print (frase1)\n",
    "susti=re.compile (r'(\\beso\\b)',re.I|re.U|re.X)\n",
    "x=re.sub(susti,\"---\",frase1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 3: encontrar fechas con formato dd/mm/aaaa, dd/mm. El separador también puede ser  un guión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "ejemplo=\"el 12/03/1987 el 23/03 o el 21-04 no \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=\"(\\d{2}(/|-)\\d{2}((/|-)\\d{4})?)\"\n",
    "pattern=re.compile (date,re.I|re.U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/03/1987\n",
      "23/03\n",
      "21-04\n"
     ]
    }
   ],
   "source": [
    "fiiter=pattern.finditer(ejemplo)\n",
    "for i in fiiter:\n",
    "    print (ejemplo[i.start():i.end()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 4: definir una RE que reconozca las instancias de \"Dani Alvez\" del texto del ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CON GRUPOS:\n",
      "----------\n",
      "('#dani', ' ', 'alves')\n",
      "('#daniel', ' ', 'alves')\n",
      "('#daniel', '', 'alves99_k')\n",
      "('@daniel_kk', ' ', 'alves')\n",
      "('', ' ', '#alves')\n",
      "('', ' ', 'alves')\n",
      "----------\n",
      "SIN GRUPOS:\n",
      "----------\n",
      "#dani alves\n",
      "#daniel alves\n",
      "#danielalves99_k\n",
      "@daniel_kk alves\n",
      " #alves\n",
      " alves\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "texto= \"#dani alves #daniel alves #danielalves99_k daniel @daniel_kk alves #alves alves\"\n",
    "pattern_con_grupos=re.compile(r'([#@]?dani\\S*)? (\\s)* ([#@]?alves\\S*)+',re.I|re.X)\n",
    "pattern_sin_grupos=re.compile(r'(?:[#@]?dani\\S*)? (?:\\s)* (?:[#@]?alves\\S*)+',re.I|re.X)\n",
    "#IMPORTANTE: poner la opciones:\n",
    "# re.I: para olvidarte de mayúsculas y minúsculas\n",
    "# re.X: para olvidarte de blancos y comentarios dentro de las expresiones regulares\n",
    "#        si no se pone y dejas un blanco, es una parte mas de regex\n",
    "# Ojo con los parentesis: cada vez que pones una expresión entre parentesis es un grupo \n",
    "# y a veces no interesa\n",
    "# Si pones por ejemplo (xxx) es un grupo, si no quieres grupo (?:xxx)\n",
    "\n",
    "#Con grupos\n",
    "print(\"CON GRUPOS:\")\n",
    "print(\"----------\") \n",
    "results_grupos=pattern_con_grupos.findall(texto)\n",
    "for f in results_grupos:\n",
    "    print (f)\n",
    "print(\"----------\")  \n",
    "\n",
    "#Sin grupos\n",
    "print(\"SIN GRUPOS:\")\n",
    "print(\"----------\") \n",
    "results_sin_grupos=pattern_sin_grupos.findall(texto)\n",
    "for f in results_sin_grupos:\n",
    "    print (f)\n",
    "print(\"----------\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Ejercicio 5: Elongated words and censured words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['soooo', 'hiiiii', 'whyyyy', 'callllllllla']\n"
     ]
    }
   ],
   "source": [
    "cad= 'soooo hiiiii whyyyy done calla callllllllla'\n",
    "import re \n",
    "elongated = re.compile(r\"(.)\\1{2}\")\n",
    "print ([word for word in cad.split() if elongated.search(word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so hi why done calla cala\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "frase1='soooo hiiiii whyyyy done calla callllllllla'\n",
    "norm=re.compile (r\"(.)\\1{2,}\",re.I|re.U|re.X)\n",
    "x=re.sub(norm,r\"\\1\",frase1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p**a', 'c**o', 'm*****n']\n"
     ]
    }
   ],
   "source": [
    "fraseC=\"p**a c**o puto m*****n\"\n",
    "censurado=re.compile (r'(?:\\b\\w+[*]+\\w+\\b)')\n",
    "print([word for word in fraseC.split() if censurado.search(word)])                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "\n",
    "Capture:\n",
    "\n",
    "* Dates eg 12/12/2021 or 12-12-2020 or 12 of March of 2020\n",
    "* Numbers with commans or decimal points or fractions\n",
    "* Punctuation\n",
    "* Compound words\n",
    "* Url\n",
    "* Email\n",
    "* Users\n",
    "* Hastag\n",
    "* Emoji\n",
    "* Acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Él, Antonio, no vendrá mañana: lo hará pasado mañana.  ¿¿¿¿Cuándo???? No te lo he dicho... ¡?Vale! no te he oido.\n",
      "De acuerdo; No iré. Pesa 44.44 kg y mide 32,32 m. El 12-12-2020, y el 13/12: habrá examen, el 14-12 ya veremos.\n",
      "El pseudo-código vale 30,6 sobre 100. El 15.5% no es suficiente. El \"bote\" está lleno, o 'vacio' no semi-vacio.\n",
      "¡Ay! el correo es fpla@dsic.upv.es y la web: http://users.dsic.upv.es/~fpla/ se me olvidaba, ha cambiado. Ahora es http://personales.upv.es/~fpla/ \n",
      "Mañana nos vemos a las 9:30 horas. 3/4 partes de la población come carne.\n",
      "el usuario @antonio_123 escribió un tweet con el hashtag #alc-2019 el viernes, https://haha.ls-ps.com\n",
      "El 14 de marzo de 2021 empiezan las clases de LNRI de prácticas y alguna cosa más.\n",
      "Todo lo que sigue son ejemplos de acrónimos que no se deberían separar: EE.UU., S.L., CC.OO., S.A., D., U.R.S.S., entre otros.\n",
      "Podéis probar con otros ejemplos, e incluso, plantear algún tipo de tokens que os interese: disfrutaaaddd!!!!! 🙂 \n",
      "'🤔 🙈 es así,bla, bla, bla  🎓 es, se . 😌 de...; 💕👭👙😊'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"input.txt\", \"r\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "text = text.split(\"\\n\")\n",
    "\n",
    "for s in text:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_list = [\n",
    "    # Dates eg 12/12/2021 or 12-12-2020 or 12 of March of 2020\n",
    "    '(\\d{2}\\s\\w+\\s\\w+\\s\\w+\\s\\d{4})',\n",
    "    '([0-9]+[-/][0-9]+[-/][0-9]+)',    \n",
    "    # Hour\n",
    "    '([0-9]+:[0-9]+)',\n",
    "    # Numbers with commans or decimal points or fractions\n",
    "    '([0-9]+[-/,.][0-9]+)',\n",
    "    # Punctuation\n",
    "    '(\\.{3}|[().,\"?¿!¡…;:%])',\n",
    "    # Url\n",
    "    '(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})',\n",
    "    # Email\n",
    "    '([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)',\n",
    "    # Users\n",
    "    '(@[a-zA-Z0-9_]+)',\n",
    "    # Hastag\n",
    "    '(#[a-zA-Z0-9_-]+)',    \n",
    "    # Acronyms\n",
    "    '([A-Z].\\.[A-Z]+\\.|(?:[a-zA-Z]\\.){2,}|[A-Z]\\.)',\n",
    "    # Emoji\n",
    "    '[^\\w\\s,]',\n",
    "    # Compound words\n",
    "    '([a-zA-Z]+-\\w+)',\n",
    "    # Words\n",
    "    '(\\w+)'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_all = '|'.join(regex_list)\n",
    "tokenizer = re.compile(regex_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.txt\", 'w') as file:\n",
    "    for frase in text:\n",
    "        file.write(frase + \"\\n\")\n",
    "        res = tokenizer.finditer(frase)\n",
    "        for i in res:\n",
    "            file.write('\\n' + str(i.group()))\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
