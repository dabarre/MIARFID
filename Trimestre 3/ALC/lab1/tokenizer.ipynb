{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "\n",
    "Capture:\n",
    "\n",
    "* Dates eg 12/12/2021 or 12-12-2020 or 12 of March of 2020\n",
    "* Numbers with commans or decimal points or fractions\n",
    "* Punctuation\n",
    "* Compound words\n",
    "* Url\n",
    "* Email\n",
    "* Users\n",
    "* Hastag\n",
    "* Emoji\n",
    "* Acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ã‰l, Antonio, no vendrÃ¡ maÃ±ana: lo harÃ¡ pasado maÃ±ana.  Â¿Â¿Â¿Â¿CuÃ¡ndo???? No te lo he dicho... Â¡?Vale! no te he oido.',\n",
       " 'De acuerdo; No irÃ©. Pesa 44.44 kg y mide 32,32 m. El 12-12-2020, y el 13/12: habrÃ¡ examen, el 14-12 ya veremos.',\n",
       " 'El pseudo-cÃ³digo vale 30,6 sobre 100. El 15.5% no es suficiente. El \"bote\" estÃ¡ lleno, o \\'vacio\\' no semi-vacio.',\n",
       " 'Â¡Ay! el correo es fpla@dsic.upv.es y la web: http://users.dsic.upv.es/~fpla/ se me olvidaba, ha cambiado. Ahora es http://personales.upv.es/~fpla/ ',\n",
       " 'MaÃ±ana nos vemos a las 9:30 horas. 3/4 partes de la poblaciÃ³n come carne.',\n",
       " 'el usuario @antonio_123 escribiÃ³ un tweet con el hashtag #alc-2019 el viernes, https://haha.ls-ps.com',\n",
       " 'El 14 de marzo de 2021 empiezan las clases de LNRI de prÃ¡cticas y alguna cosa mÃ¡s.',\n",
       " 'Todo lo que sigue son ejemplos de acrÃ³nimos que no se deberÃ­an separar: EE.UU., S.L., CC.OO., S.A., D., U.R.S.S., entre otros.',\n",
       " 'PodÃ©is probar con otros ejemplos, e incluso, plantear algÃºn tipo de tokens que os interese: disfrutaaaddd!!!!! ðŸ™‚ ',\n",
       " \"'ðŸ¤” ðŸ™ˆ es asÃ­,bla, bla, bla  ðŸŽ“ es, se . ðŸ˜Œ de...; ðŸ’•ðŸ‘­ðŸ‘™ðŸ˜Š'\",\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"input.txt\", \"r\")\n",
    "texts = file.read()\n",
    "file.close()\n",
    "texts = texts.split(\"\\n\")\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_list = [\n",
    "    # Dates eg 12/12/2021 or 12-12-2020 or 12 of March of 2020\n",
    "    '(\\d{2}\\s\\w+\\s\\w+\\s\\w+\\s\\d{4})',\n",
    "    '([0-9]+[-/][0-9]+[-/][0-9]+)',    \n",
    "    # Hour\n",
    "    '([0-9]+:[0-9]+)',\n",
    "    # Numbers with commans or decimal points or fractions\n",
    "    '([0-9]+[-/,.][0-9]+)',\n",
    "    # Punctuation\n",
    "    '(\\.{3}|[().,\"?Â¿!Â¡â€¦;:%])',\n",
    "    # Url\n",
    "    '(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})',\n",
    "    # Email\n",
    "    '([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)',\n",
    "    # Users\n",
    "    '(@[a-zA-Z0-9_]+)',\n",
    "    # Hastag\n",
    "    '(#[a-zA-Z0-9_-]+)',    \n",
    "    # Acronyms\n",
    "    '([A-Z].\\.[A-Z]+\\.|(?:[a-zA-Z]\\.){2,}|[A-Z]\\.)',\n",
    "    # Emoji\n",
    "    '[^\\w\\s,]',\n",
    "    # Compound words\n",
    "    '([a-zA-Z]+-\\w+)',\n",
    "    # Words\n",
    "    '(\\w+)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_all = '|'.join(regex_list)\n",
    "tokenizer = re.compile(regex_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.txt\", 'w') as file:\n",
    "    for sentence in texts:\n",
    "        file.write(sentence + \"\\n\")        \n",
    "        res = tokenizer.finditer(sentence)\n",
    "        for i in res:\n",
    "            file.write('\\n' + str(i.group()))\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261a262,263\r\n",
      "> \r\n",
      "> \r\n"
     ]
    }
   ],
   "source": [
    "!diff output.txt results.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
