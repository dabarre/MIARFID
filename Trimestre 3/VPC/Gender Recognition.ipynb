{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Recognition (3 points)\n",
    "\n",
    "Labeled Faces in the Wild dataset. RGB images 100x100 pixels\n",
    "\n",
    "## Goals:\n",
    "\n",
    "* \\>97% accuracy over test set\n",
    "* \\>92% accuracy with less than 100k parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-10 14:41:22--  https://www.dropbox.com/s/zcwlujrtz3izcw8/gender.tgz\n",
      "Resolviendo www.dropbox.com (www.dropbox.com)... 162.125.68.18, 2620:100:6024:18::a27d:4412\n",
      "Conectando con www.dropbox.com (www.dropbox.com)[162.125.68.18]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 301 Moved Permanently\n",
      "Ubicación: /s/raw/zcwlujrtz3izcw8/gender.tgz [siguiente]\n",
      "--2021-03-10 14:41:23--  https://www.dropbox.com/s/raw/zcwlujrtz3izcw8/gender.tgz\n",
      "Reutilizando la conexión con www.dropbox.com:443.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Ubicación: https://uc488111ef8610bfb26613dc5bbb.dl.dropboxusercontent.com/cd/0/inline/BKZlMGh4U8No7P8c1_mK-6LxQOOsJWgDOPSHZQgTWQh_iSjQbEojEMwU3_EyVuQXJJrmO6zQDev-UBcTZqK5rPP36g_iw-p9c-0dMt9OQ2yuku1Rscqu9K184-mzRR6k1Ak/file# [siguiente]\n",
      "--2021-03-10 14:41:23--  https://uc488111ef8610bfb26613dc5bbb.dl.dropboxusercontent.com/cd/0/inline/BKZlMGh4U8No7P8c1_mK-6LxQOOsJWgDOPSHZQgTWQh_iSjQbEojEMwU3_EyVuQXJJrmO6zQDev-UBcTZqK5rPP36g_iw-p9c-0dMt9OQ2yuku1Rscqu9K184-mzRR6k1Ak/file\n",
      "Resolviendo uc488111ef8610bfb26613dc5bbb.dl.dropboxusercontent.com (uc488111ef8610bfb26613dc5bbb.dl.dropboxusercontent.com)... 162.125.68.15, 2620:100:6024:15::a27d:440f\n",
      "Conectando con uc488111ef8610bfb26613dc5bbb.dl.dropboxusercontent.com (uc488111ef8610bfb26613dc5bbb.dl.dropboxusercontent.com)[162.125.68.15]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Ubicación: /cd/0/inline2/BKbTU2RuIej9F01SiWGoILA1zbZ29btQK45GZT0ZQfWy68-LVlQCLhBSZFRfWkS_mreQxPAx93lC9uXeGsdlgz0mceEjqt1vhPE6an-UQqjI5kYFOZubsuvjENOp_ENDr5rFMv1VV3-TiJDTSoZOhCmFJUtn8BLfYtKlN3KySQ9UehvUfxKYY10oCktfNFpz7GgWqnt9IM0UEMlWGln7VgDSCWS-hWflb4a87NgGPVAqigzsYjXn7gmfVARhMZ5OEm_Pv8woTW9JU-3f8qUMtt10LSvEvxJadN2zhB01rgMRuBX55jdZC_QqFuOG0YFzzX03GTIQS9o3EIsLiy36jJBCEFmXnu2YgjaZpooE1s-uAg/file [siguiente]\n",
      "--2021-03-10 14:41:24--  https://uc488111ef8610bfb26613dc5bbb.dl.dropboxusercontent.com/cd/0/inline2/BKbTU2RuIej9F01SiWGoILA1zbZ29btQK45GZT0ZQfWy68-LVlQCLhBSZFRfWkS_mreQxPAx93lC9uXeGsdlgz0mceEjqt1vhPE6an-UQqjI5kYFOZubsuvjENOp_ENDr5rFMv1VV3-TiJDTSoZOhCmFJUtn8BLfYtKlN3KySQ9UehvUfxKYY10oCktfNFpz7GgWqnt9IM0UEMlWGln7VgDSCWS-hWflb4a87NgGPVAqigzsYjXn7gmfVARhMZ5OEm_Pv8woTW9JU-3f8qUMtt10LSvEvxJadN2zhB01rgMRuBX55jdZC_QqFuOG0YFzzX03GTIQS9o3EIsLiy36jJBCEFmXnu2YgjaZpooE1s-uAg/file\n",
      "Reutilizando la conexión con uc488111ef8610bfb26613dc5bbb.dl.dropboxusercontent.com:443.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 348494455 (332M) [application/x-gtar]\n",
      "Guardando como: “dataset_gender/gender.tgz”\n",
      "\n",
      "gender.tgz          100%[===================>] 332,35M  2,39MB/s    en 2m 14s  \n",
      "\n",
      "2021-03-10 14:43:39 (2,48 MB/s) - “dataset_gender/gender.tgz” guardado [348494455/348494455]\n",
      "\n",
      "./._x_test.npy\n",
      "x_test.npy\n",
      "./._x_train.npy\n",
      "x_train.npy\n",
      "./._y_test.npy\n",
      "y_test.npy\n",
      "./._y_train.npy\n",
      "y_train.npy\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/zcwlujrtz3izcw8/gender.tgz -P dataset_gender\n",
    "!tar xvzf dataset_gender/gender.tgz -C dataset_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n8HTqho443XN"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Add, Concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization as BN\n",
    "from keras.layers import GaussianNoise as GN\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler as LRS\n",
    "from keras.callbacks import ReduceLROnPlateau as RLRP\n",
    "\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W07pmMxn43Xd"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 200\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vYOZdNfb43Xf"
   },
   "outputs": [],
   "source": [
    "def configure_callbacks(model_id, kpi_to_monitor='val_accuracy'):\n",
    "    # Without log/ or models/ subfolder as not possible to access unexisting folders\n",
    "    # If possible to train with jupyter revise\n",
    "    name = \"gr\"\n",
    "    log_filename = '%s-%s.log' % (name, model_id)\n",
    "    csv_logger = CSVLogger(log_filename)\n",
    "    \n",
    "    chk_1_model_filename = '%s-%s-{epoch:04d}-{%s:.6f}.h5' % (name, model_id, kpi_to_monitor)\n",
    "    chk_2_model_filename = '%s-%s.h5' % (name, model_id)\n",
    "    \n",
    "    # Save best model fully not only weights after each epoch (period=1) \n",
    "    # with best accuracy value (mode=max, save_best_only=True)\n",
    "    checkpoint1 = ModelCheckpoint(\n",
    "        chk_1_model_filename,\n",
    "        monitor=kpi_to_monitor,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False, \n",
    "        verbose=1, mode='max', period=1\n",
    "    )\n",
    "\n",
    "    checkpoint2 = ModelCheckpoint(\n",
    "        chk_2_model_filename, \n",
    "        monitor=kpi_to_monitor,\n",
    "        save_best_only=False,\n",
    "        save_weights_only=False, \n",
    "        verbose=1, mode='auto', period=1\n",
    "    )\n",
    "\n",
    "    callbacks = [csv_logger, checkpoint1, checkpoint2]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sz3V6ggH43Xm"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation with an ImageGenerator + more variations\n",
    "datagen = ImageDataGenerator(width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=False,\n",
    "                             zoom_range=[1.0,1.1],\n",
    "                             rotation_range=10.0,\n",
    "                             shear_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dh90v9Gf43Xs"
   },
   "outputs": [],
   "source": [
    "# Optimizer \n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dcdfG_Wx43Xj"
   },
   "outputs": [],
   "source": [
    "# Define a learning rate scheduler\n",
    "def scheduler(epoch):\n",
    "    if epoch < 50:\n",
    "        return 0.1\n",
    "    elif epoch < 75:\n",
    "        return 0.01\n",
    "    elif epoch < 150:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0005\n",
    "\n",
    "scheduler_lr = LRS(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTzJCRwm43Xn",
    "outputId": "a24d281a-ec67-4cbf-ff04-40c4ee9f7d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10585, 100, 100, 3)\n",
      "(2648, 100, 100, 3)\n",
      "2381 8204 0.22494095418044402\n",
      "596 2052 0.22507552870090636\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "path = 'dataset_gender/'\n",
    "x_train = np.load(path + 'x_train.npy')\n",
    "x_test = np.load(path + 'x_test.npy')\n",
    "\n",
    "y_train = np.load(path + 'y_train.npy')\n",
    "y_test = np.load(path + 'y_test.npy')\n",
    "\n",
    "# Stats\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(\"{} {} {}\".format(sum(y_train == 1), sum(y_train == 0),sum(y_train == 1)/y_train.shape[0]))\n",
    "print(\"{} {} {}\".format(sum(y_test == 1), sum(y_test == 0),sum(y_test == 1)/y_test.shape[0]))\n",
    "\n",
    "## Transforms and Normalize\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## View some images\n",
    "plt.imshow(x_train[0,:,:,:])\n",
    "plt.show()\n",
    "\n",
    "# Image size 100x100 to 96x96 pixels - better multiple of 2\n",
    "\n",
    "aux_train = np.zeros((x_train.shape[0], 96, 96, 3)).astype('float32')\n",
    "np.array([aux_train])\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    aux_train[i] = x_train[i,2:-2,2:-2,:]\n",
    "    \n",
    "aux_test = np.zeros((x_test.shape[0], 96, 96, 3)).astype('float32')\n",
    "np.array([aux_test])\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    aux_test[i] = x_test[i,2:-2,2:-2,:]\n",
    "    \n",
    "del(x_train)\n",
    "del(x_test)\n",
    "\n",
    "x_train = aux_train\n",
    "x_test = aux_test\n",
    "\n",
    "plt.imshow(aux_train[0,:,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hYcET62-43Xu"
   },
   "outputs": [],
   "source": [
    "def training_and_evaluation(model, model_id, scheduler):\n",
    "    # Compile Model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(x_train)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        shuffle=True,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test),                   \n",
    "                        callbacks=[configure_callbacks(model_id), scheduler])\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', accuracy)\n",
    "    print('Test error:', (1-accuracy))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBGN_FUNC(model, filters, gaussian_noise, kernel=(3,3)):\n",
    "    x = Conv2D(filters, kernel, padding='same')(model)\n",
    "    x = BN()(x)\n",
    "    x = GN(gaussian_noise)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "6yWxUfvM43Xv"
   },
   "source": [
    "## Extra funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "XsT5Jk7E43Xw"
   },
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "MClHCewU43Xx"
   },
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train)/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),                   \n",
    "                    callbacks=[configure_callbacks(model_id), scheduler_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "_Tetzjz943Xx"
   },
   "outputs": [],
   "source": [
    "history = model.fit(datagen_plus.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train)/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),                   \n",
    "                    callbacks=[configure_callbacks(model_id), reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "mjnHIY4x43Xy"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n",
    "print('Test error:', (1-accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "OQHhP-xf43Xz"
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)\n",
    "history = pd.read_csv(\"model-weights/model.log\")\n",
    "model = load_model(\"model-weights/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gIEYjpJ43Xz"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### > 100 parameter models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "IxgadTui43X2",
    "outputId": "0a96a8b0-ebd6-46d9-f0d1-d22bcaf725da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_46 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_249 (Conv2D)          (None, 96, 96, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_239 (Bat (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_239 (Gaussian (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_259 (Activation)  (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_250 (Conv2D)          (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_240 (Bat (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_240 (Gaussian (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_260 (Activation)  (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_251 (Conv2D)          (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_241 (Bat (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_241 (Gaussian (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_261 (Activation)  (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_252 (Conv2D)          (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_242 (Bat (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_242 (Gaussian (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_262 (Activation)  (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_253 (Conv2D)          (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_243 (Bat (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_243 (Gaussian (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_263 (Activation)  (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_254 (Conv2D)          (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_244 (Bat (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_244 (Gaussian (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_264 (Activation)  (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_255 (Conv2D)          (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_245 (Bat (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_245 (Gaussian (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_265 (Activation)  (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_256 (Conv2D)          (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_246 (Bat (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_246 (Gaussian (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_266 (Activation)  (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_257 (Conv2D)          (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_247 (Bat (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_247 (Gaussian (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_267 (Activation)  (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_258 (Conv2D)          (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_248 (Bat (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "gaussian_noise_248 (Gaussian (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "activation_268 (Activation)  (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_259 (Conv2D)          (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_249 (Bat (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "gaussian_noise_249 (Gaussian (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "activation_269 (Activation)  (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_260 (Conv2D)          (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_250 (Bat (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "gaussian_noise_250 (Gaussian (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "activation_270 (Activation)  (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_261 (Conv2D)          (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_251 (Bat (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "gaussian_noise_251 (Gaussian (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "activation_271 (Activation)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_262 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_252 (Bat (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "gaussian_noise_252 (Gaussian (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "activation_272 (Activation)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_263 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_253 (Bat (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "gaussian_noise_253 (Gaussian (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "activation_273 (Activation)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_20  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "activation_274 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 7,868,802\n",
      "Trainable params: 7,862,850\n",
      "Non-trainable params: 5,952\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Based on best model RNA lab\n",
    "\n",
    "inputs = keras.Input(x_train.shape[1:])\n",
    "x = CBGN_FUNC(inputs, 32, 0.1)\n",
    "x = CBGN_FUNC(x, 32, 0.2)\n",
    "x = CBGN_FUNC(x, 32, 0.2)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = CBGN_FUNC(x, 64, 0.3)\n",
    "x = CBGN_FUNC(x, 64, 0.3)\n",
    "x = CBGN_FUNC(x, 64, 0.3)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = CBGN_FUNC(x, 128, 0.3)\n",
    "x = CBGN_FUNC(x, 128, 0.3)\n",
    "x = CBGN_FUNC(x, 128, 0.3)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = CBGN_FUNC(x, 256, 0.3)\n",
    "x = CBGN_FUNC(x, 256, 0.3)\n",
    "x = CBGN_FUNC(x, 256, 0.3)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = CBGN_FUNC(x, 512, 0.3)\n",
    "x = CBGN_FUNC(x, 512, 0.3)\n",
    "x = CBGN_FUNC(x, 512, 0.3)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_vgg = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_48\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_50 (InputLayer)           [(None, 96, 96, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 96, 96, 32)   896         input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 96, 96, 32)   128         conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_284 (GaussianNoi (None, 96, 96, 32)   0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 96, 96, 32)   0           gaussian_noise_284[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 96, 96, 32)   9248        activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 96, 96, 32)   128         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_285 (GaussianNoi (None, 96, 96, 32)   0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 96, 96, 32)   0           gaussian_noise_285[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 96, 96, 32)   9248        activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 96, 96, 32)   128         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_286 (GaussianNoi (None, 96, 96, 32)   0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 96, 96, 32)   0           gaussian_noise_286[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 96, 96, 32)   0           activation_307[0][0]             \n",
      "                                                                 activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling2D) (None, 48, 48, 32)   0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 48, 48, 64)   18496       max_pooling2d_67[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 48, 48, 64)   256         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_287 (GaussianNoi (None, 48, 48, 64)   0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 48, 48, 64)   0           gaussian_noise_287[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 48, 48, 64)   36928       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 48, 48, 64)   256         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_288 (GaussianNoi (None, 48, 48, 64)   0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 48, 48, 64)   0           gaussian_noise_288[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 48, 48, 64)   36928       activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 48, 48, 64)   256         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_289 (GaussianNoi (None, 48, 48, 64)   0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 48, 48, 64)   0           gaussian_noise_289[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 48, 48, 64)   0           activation_310[0][0]             \n",
      "                                                                 activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling2D) (None, 24, 24, 64)   0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 24, 24, 128)  73856       max_pooling2d_68[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 24, 24, 128)  512         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_290 (GaussianNoi (None, 24, 24, 128)  0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 24, 24, 128)  0           gaussian_noise_290[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 24, 24, 128)  147584      activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 24, 24, 128)  512         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_291 (GaussianNoi (None, 24, 24, 128)  0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 24, 24, 128)  0           gaussian_noise_291[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 24, 24, 128)  147584      activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 24, 24, 128)  512         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_292 (GaussianNoi (None, 24, 24, 128)  0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 24, 24, 128)  0           gaussian_noise_292[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 24, 24, 128)  0           activation_313[0][0]             \n",
      "                                                                 activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling2D) (None, 12, 12, 128)  0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 12, 12, 256)  295168      max_pooling2d_69[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 12, 12, 256)  1024        conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_293 (GaussianNoi (None, 12, 12, 256)  0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 12, 12, 256)  0           gaussian_noise_293[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 12, 12, 256)  590080      activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 12, 12, 256)  1024        conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_294 (GaussianNoi (None, 12, 12, 256)  0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 12, 12, 256)  0           gaussian_noise_294[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 12, 12, 256)  590080      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 12, 12, 256)  1024        conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_295 (GaussianNoi (None, 12, 12, 256)  0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 12, 12, 256)  0           gaussian_noise_295[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 12, 12, 256)  0           activation_316[0][0]             \n",
      "                                                                 activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling2D) (None, 6, 6, 256)    0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 6, 6, 512)    1180160     max_pooling2d_70[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 6, 6, 512)    2048        conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_296 (GaussianNoi (None, 6, 6, 512)    0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 6, 6, 512)    0           gaussian_noise_296[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 6, 6, 512)    2359808     activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 6, 6, 512)    2048        conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_297 (GaussianNoi (None, 6, 6, 512)    0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 6, 6, 512)    0           gaussian_noise_297[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 6, 6, 512)    2359808     activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 6, 6, 512)    2048        conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_298 (GaussianNoi (None, 6, 6, 512)    0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 6, 6, 512)    0           gaussian_noise_298[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 6, 6, 512)    0           activation_319[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_23 (Gl (None, 512)          0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 512)          0           global_average_pooling2d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 2)            1026        activation_322[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 7,868,802\n",
      "Trainable params: 7,862,850\n",
      "Non-trainable params: 5,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Simple residual network\n",
    "\n",
    "inputs = keras.Input(x_train.shape[1:])\n",
    "\n",
    "x1 = CBGN_FUNC(inputs, 32, 0.1)\n",
    "x2 = CBGN_FUNC(x1, 32, 0.2)\n",
    "x3 = CBGN_FUNC(x2, 32, 0.2)\n",
    "x = Add()([x1, x3])\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x1 = CBGN_FUNC(x, 64, 0.3)\n",
    "x2 = CBGN_FUNC(x1, 64, 0.3)\n",
    "x3 = CBGN_FUNC(x2, 64, 0.3)\n",
    "x = Add()([x1, x3])\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x1 = CBGN_FUNC(x, 128, 0.3)\n",
    "x2 = CBGN_FUNC(x1, 128, 0.3)\n",
    "x3 = CBGN_FUNC(x2, 128, 0.3)\n",
    "x = Add()([x1, x3])\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x1 = CBGN_FUNC(x, 256, 0.3)\n",
    "x2 = CBGN_FUNC(x1, 256, 0.3)\n",
    "x3 = CBGN_FUNC(x2, 256, 0.3)\n",
    "x = Add()([x1, x3])\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x1 = CBGN_FUNC(x, 512, 0.3)\n",
    "x2 = CBGN_FUNC(x1, 512, 0.3)\n",
    "x3 = CBGN_FUNC(x2, 512, 0.3)\n",
    "x = Add()([x1, x3])\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_resnet = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_52\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_52 (InputLayer)           [(None, 96, 96, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 96, 96, 32)   896         input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 96, 96, 32)   128         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_314 (GaussianNoi (None, 96, 96, 32)   0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 96, 96, 32)   0           gaussian_noise_314[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 96, 96, 32)   9248        activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 96, 96, 32)   128         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_315 (GaussianNoi (None, 96, 96, 32)   0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 96, 96, 32)   0           gaussian_noise_315[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 96, 96, 32)   9248        activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 96, 96, 32)   128         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_316 (GaussianNoi (None, 96, 96, 32)   0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 96, 96, 32)   0           gaussian_noise_316[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 96, 96, 96)   0           activation_339[0][0]             \n",
      "                                                                 activation_340[0][0]             \n",
      "                                                                 activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling2D) (None, 48, 48, 96)   0           concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 48, 48, 32)   27680       max_pooling2d_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 48, 48, 32)   128         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_317 (GaussianNoi (None, 48, 48, 32)   0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 48, 48, 32)   0           gaussian_noise_317[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 48, 48, 32)   9248        activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 48, 48, 32)   128         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_318 (GaussianNoi (None, 48, 48, 32)   0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 48, 48, 32)   0           gaussian_noise_318[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 48, 48, 32)   9248        activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 48, 48, 32)   128         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_319 (GaussianNoi (None, 48, 48, 32)   0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 48, 48, 32)   0           gaussian_noise_319[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 48, 48, 96)   0           activation_342[0][0]             \n",
      "                                                                 activation_343[0][0]             \n",
      "                                                                 activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling2D) (None, 24, 24, 96)   0           concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 24, 24, 32)   27680       max_pooling2d_76[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 24, 24, 32)   128         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_320 (GaussianNoi (None, 24, 24, 32)   0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 24, 24, 32)   0           gaussian_noise_320[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 24, 24, 32)   9248        activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 24, 24, 32)   128         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_321 (GaussianNoi (None, 24, 24, 32)   0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 24, 24, 32)   0           gaussian_noise_321[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 24, 24, 32)   9248        activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 24, 24, 32)   128         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_322 (GaussianNoi (None, 24, 24, 32)   0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 24, 24, 32)   0           gaussian_noise_322[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 24, 24, 96)   0           activation_345[0][0]             \n",
      "                                                                 activation_346[0][0]             \n",
      "                                                                 activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling2D) (None, 12, 12, 96)   0           concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 12, 12, 64)   55360       max_pooling2d_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 12, 12, 64)   256         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_323 (GaussianNoi (None, 12, 12, 64)   0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 12, 12, 64)   0           gaussian_noise_323[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 12, 12, 64)   36928       activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 12, 12, 64)   256         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_324 (GaussianNoi (None, 12, 12, 64)   0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 12, 12, 64)   0           gaussian_noise_324[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 12, 12, 64)   36928       activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 12, 12, 64)   256         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_325 (GaussianNoi (None, 12, 12, 64)   0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 12, 12, 64)   0           gaussian_noise_325[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 12, 12, 192)  0           activation_348[0][0]             \n",
      "                                                                 activation_349[0][0]             \n",
      "                                                                 activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling2D) (None, 6, 6, 192)    0           concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 6, 6, 64)     110656      max_pooling2d_78[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 6, 6, 64)     256         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_326 (GaussianNoi (None, 6, 6, 64)     0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 6, 6, 64)     0           gaussian_noise_326[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 6, 6, 64)     36928       activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 6, 6, 64)     256         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_327 (GaussianNoi (None, 6, 6, 64)     0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 6, 6, 64)     0           gaussian_noise_327[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 6, 6, 64)     36928       activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 6, 6, 64)     256         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_328 (GaussianNoi (None, 6, 6, 64)     0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 6, 6, 64)     0           gaussian_noise_328[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 6, 6, 192)    0           activation_351[0][0]             \n",
      "                                                                 activation_352[0][0]             \n",
      "                                                                 activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_25 (Gl (None, 192)          0           concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 192)          0           global_average_pooling2d_25[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 2)            386         activation_354[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 428,546\n",
      "Trainable params: 427,202\n",
      "Non-trainable params: 1,344\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Simple dense network\n",
    "\n",
    "inputs = keras.Input(x_train.shape[1:])\n",
    "\n",
    "x1 = CBGN_FUNC(inputs, 32, 0.1)\n",
    "x2 = CBGN_FUNC(x1, 32, 0.2)\n",
    "x3 = CBGN_FUNC(x2, 32, 0.2)\n",
    "x = Concatenate()([x1, x2, x3])\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x1 = CBGN_FUNC(x, 32, 0.3)\n",
    "x2 = CBGN_FUNC(x1, 32, 0.3)\n",
    "x3 = CBGN_FUNC(x2, 32, 0.3)\n",
    "x = Concatenate()([x1, x2, x3])\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x1 = CBGN_FUNC(x, 32, 0.3)\n",
    "x2 = CBGN_FUNC(x1, 32, 0.3)\n",
    "x3 = CBGN_FUNC(x2, 32, 0.3)\n",
    "x = Concatenate()([x1, x2, x3])\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x1 = CBGN_FUNC(x, 64, 0.3)\n",
    "x2 = CBGN_FUNC(x1, 64, 0.3)\n",
    "x3 = CBGN_FUNC(x2, 64, 0.3)\n",
    "x = Concatenate()([x1, x2, x3])\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x1 = CBGN_FUNC(x, 64, 0.3)\n",
    "x2 = CBGN_FUNC(x1, 64, 0.3)\n",
    "x3 = CBGN_FUNC(x2, 64, 0.3)\n",
    "x = Concatenate()([x1, x2, x3])\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_densenet = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model_densenet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### < 100 parameter models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 96, 96, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNo (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_2 (GaussianNo (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_3 (GaussianNo (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_4 (GaussianNo (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_5 (GaussianNo (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_6 (GaussianNo (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 94,594\n",
      "Trainable params: 94,018\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(x_train.shape[1:])\n",
    "\n",
    "x = CBGN_FUNC(inputs, 32, 0.1)\n",
    "x = CBGN_FUNC(x, 32, 0.2)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = CBGN_FUNC(x, 32, 0.3)\n",
    "x = CBGN_FUNC(x, 32, 0.3)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = CBGN_FUNC(x, 32, 0.3)\n",
    "x = CBGN_FUNC(x, 64, 0.3)\n",
    "x = CBGN_FUNC(x, 64, 0.3)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_vgg_mini = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model_vgg_mini.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 96, 96, 32)   896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 96, 96, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_7 (GaussianNoise (None, 96, 96, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 96, 96, 32)   0           gaussian_noise_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 96, 96, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 96, 96, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_8 (GaussianNoise (None, 96, 96, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 96, 96, 32)   0           gaussian_noise_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 96, 96, 32)   0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 48, 48, 32)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 48, 48, 32)   9248        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 48, 48, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_9 (GaussianNoise (None, 48, 48, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 48, 48, 32)   0           gaussian_noise_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 48, 48, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 48, 48, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_10 (GaussianNois (None, 48, 48, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 48, 48, 32)   0           gaussian_noise_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 48, 48, 32)   0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 24, 24, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 24, 24, 48)   13872       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 24, 24, 48)   192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_11 (GaussianNois (None, 24, 24, 48)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 24, 24, 48)   0           gaussian_noise_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 24, 24, 64)   27712       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 24, 24, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_12 (GaussianNois (None, 24, 24, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 24, 24, 64)   0           gaussian_noise_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 24, 24, 48)   27696       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 24, 24, 48)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_13 (GaussianNois (None, 24, 24, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 24, 24, 48)   0           gaussian_noise_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24, 24, 48)   0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 48)           0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 48)           0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            98          activation_15[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 99,170\n",
      "Trainable params: 98,594\n",
      "Non-trainable params: 576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(x_train.shape[1:])\n",
    "\n",
    "x1 = CBGN_FUNC(inputs, 32, 0.1)\n",
    "x2 = CBGN_FUNC(x1, 32, 0.2)\n",
    "x = Add()([x1, x2])\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x1 = CBGN_FUNC(x, 32, 0.3)\n",
    "x2 = CBGN_FUNC(x1, 32, 0.3)\n",
    "x = Add()([x1, x2])\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x1 = CBGN_FUNC(x, 48, 0.3)\n",
    "x2 = CBGN_FUNC(x1, 64, 0.3)\n",
    "x3 = CBGN_FUNC(x2, 48, 0.3)\n",
    "x = Add()([x1, x3])\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_resnet_mini = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model_resnet_mini.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbU2A3HC43X4"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HoEbtvE643X5",
    "outputId": "fc599085-a616-45b4-9182-52dc4f56e18c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.5145 - accuracy: 0.7702\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77492, saving model to gr-model_1-0001-0.774924.h5\n",
      "\n",
      "Epoch 00001: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 274ms/step - loss: 0.5145 - accuracy: 0.7702 - val_loss: 0.9311 - val_accuracy: 0.7749\n",
      "Epoch 2/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.7924\n",
      "Epoch 00002: val_accuracy did not improve from 0.77492\n",
      "\n",
      "Epoch 00002: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 265ms/step - loss: 0.4577 - accuracy: 0.7924 - val_loss: 0.5649 - val_accuracy: 0.6922\n",
      "Epoch 3/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4293 - accuracy: 0.8065\n",
      "Epoch 00003: val_accuracy improved from 0.77492 to 0.78927, saving model to gr-model_1-0003-0.789275.h5\n",
      "\n",
      "Epoch 00003: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 271ms/step - loss: 0.4293 - accuracy: 0.8065 - val_loss: 0.7387 - val_accuracy: 0.7893\n",
      "Epoch 4/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.8195\n",
      "Epoch 00004: val_accuracy improved from 0.78927 to 0.80589, saving model to gr-model_1-0004-0.805891.h5\n",
      "\n",
      "Epoch 00004: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 46s 275ms/step - loss: 0.4047 - accuracy: 0.8195 - val_loss: 0.4903 - val_accuracy: 0.8059\n",
      "Epoch 5/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.8267\n",
      "Epoch 00005: val_accuracy did not improve from 0.80589\n",
      "\n",
      "Epoch 00005: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.3859 - accuracy: 0.8267 - val_loss: 0.5968 - val_accuracy: 0.7851\n",
      "Epoch 6/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3735 - accuracy: 0.8296\n",
      "Epoch 00006: val_accuracy did not improve from 0.80589\n",
      "\n",
      "Epoch 00006: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.3735 - accuracy: 0.8296 - val_loss: 0.4602 - val_accuracy: 0.7738\n",
      "Epoch 7/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.8488\n",
      "Epoch 00007: val_accuracy improved from 0.80589 to 0.84139, saving model to gr-model_1-0007-0.841390.h5\n",
      "\n",
      "Epoch 00007: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.3421 - accuracy: 0.8488 - val_loss: 0.3870 - val_accuracy: 0.8414\n",
      "Epoch 8/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.8811\n",
      "Epoch 00008: val_accuracy did not improve from 0.84139\n",
      "\n",
      "Epoch 00008: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.2851 - accuracy: 0.8811 - val_loss: 0.6092 - val_accuracy: 0.6567\n",
      "Epoch 9/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.9046\n",
      "Epoch 00009: val_accuracy improved from 0.84139 to 0.86065, saving model to gr-model_1-0009-0.860650.h5\n",
      "\n",
      "Epoch 00009: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.2352 - accuracy: 0.9046 - val_loss: 0.3398 - val_accuracy: 0.8606\n",
      "Epoch 10/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.9179\n",
      "Epoch 00010: val_accuracy improved from 0.86065 to 0.87500, saving model to gr-model_1-0010-0.875000.h5\n",
      "\n",
      "Epoch 00010: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.2035 - accuracy: 0.9179 - val_loss: 0.2771 - val_accuracy: 0.8750\n",
      "Epoch 11/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.9256\n",
      "Epoch 00011: val_accuracy did not improve from 0.87500\n",
      "\n",
      "Epoch 00011: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 268ms/step - loss: 0.1871 - accuracy: 0.9256 - val_loss: 0.4391 - val_accuracy: 0.8017\n",
      "Epoch 12/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.9303\n",
      "Epoch 00012: val_accuracy did not improve from 0.87500\n",
      "\n",
      "Epoch 00012: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.1796 - accuracy: 0.9303 - val_loss: 1.4408 - val_accuracy: 0.4826\n",
      "Epoch 13/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.9379\n",
      "Epoch 00013: val_accuracy improved from 0.87500 to 0.95053, saving model to gr-model_1-0013-0.950529.h5\n",
      "\n",
      "Epoch 00013: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.1562 - accuracy: 0.9379 - val_loss: 0.1236 - val_accuracy: 0.9505\n",
      "Epoch 14/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.9418\n",
      "Epoch 00014: val_accuracy improved from 0.95053 to 0.95393, saving model to gr-model_1-0014-0.953928.h5\n",
      "\n",
      "Epoch 00014: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 268ms/step - loss: 0.1524 - accuracy: 0.9418 - val_loss: 0.1291 - val_accuracy: 0.9539\n",
      "Epoch 15/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1415 - accuracy: 0.9442\n",
      "Epoch 00015: val_accuracy did not improve from 0.95393\n",
      "\n",
      "Epoch 00015: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.1415 - accuracy: 0.9442 - val_loss: 0.1913 - val_accuracy: 0.9199\n",
      "Epoch 16/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.9498\n",
      "Epoch 00016: val_accuracy did not improve from 0.95393\n",
      "\n",
      "Epoch 00016: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.1343 - accuracy: 0.9498 - val_loss: 0.1524 - val_accuracy: 0.9441\n",
      "Epoch 17/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9457\n",
      "Epoch 00017: val_accuracy did not improve from 0.95393\n",
      "\n",
      "Epoch 00017: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.1368 - accuracy: 0.9457 - val_loss: 0.1415 - val_accuracy: 0.9486\n",
      "Epoch 18/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9547\n",
      "Epoch 00018: val_accuracy did not improve from 0.95393\n",
      "\n",
      "Epoch 00018: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.1226 - accuracy: 0.9547 - val_loss: 0.1771 - val_accuracy: 0.9316\n",
      "Epoch 19/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 0.9551\n",
      "Epoch 00019: val_accuracy improved from 0.95393 to 0.95997, saving model to gr-model_1-0019-0.959970.h5\n",
      "\n",
      "Epoch 00019: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 268ms/step - loss: 0.1202 - accuracy: 0.9551 - val_loss: 0.1037 - val_accuracy: 0.9600\n",
      "Epoch 20/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9601\n",
      "Epoch 00020: val_accuracy did not improve from 0.95997\n",
      "\n",
      "Epoch 00020: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.1080 - accuracy: 0.9601 - val_loss: 0.1403 - val_accuracy: 0.9350\n",
      "Epoch 21/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9600\n",
      "Epoch 00021: val_accuracy did not improve from 0.95997\n",
      "\n",
      "Epoch 00021: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.1093 - accuracy: 0.9600 - val_loss: 0.1537 - val_accuracy: 0.9502\n",
      "Epoch 22/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9577\n",
      "Epoch 00022: val_accuracy did not improve from 0.95997\n",
      "\n",
      "Epoch 00022: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.1099 - accuracy: 0.9577 - val_loss: 0.2569 - val_accuracy: 0.9139\n",
      "Epoch 23/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9609\n",
      "Epoch 00023: val_accuracy did not improve from 0.95997\n",
      "\n",
      "Epoch 00023: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.1072 - accuracy: 0.9609 - val_loss: 0.1234 - val_accuracy: 0.9498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9643\n",
      "Epoch 00024: val_accuracy did not improve from 0.95997\n",
      "\n",
      "Epoch 00024: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 263ms/step - loss: 0.0958 - accuracy: 0.9643 - val_loss: 0.5797 - val_accuracy: 0.7640\n",
      "Epoch 25/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9615\n",
      "Epoch 00025: val_accuracy did not improve from 0.95997\n",
      "\n",
      "Epoch 00025: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 262ms/step - loss: 0.1005 - accuracy: 0.9615 - val_loss: 0.1744 - val_accuracy: 0.9358\n",
      "Epoch 26/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9656\n",
      "Epoch 00026: val_accuracy did not improve from 0.95997\n",
      "\n",
      "Epoch 00026: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 262ms/step - loss: 0.0946 - accuracy: 0.9656 - val_loss: 0.7360 - val_accuracy: 0.8656\n",
      "Epoch 27/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9668\n",
      "Epoch 00027: val_accuracy did not improve from 0.95997\n",
      "\n",
      "Epoch 00027: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 263ms/step - loss: 0.0848 - accuracy: 0.9668 - val_loss: 0.3233 - val_accuracy: 0.8803\n",
      "Epoch 28/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9680\n",
      "Epoch 00028: val_accuracy did not improve from 0.95997\n",
      "\n",
      "Epoch 00028: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 262ms/step - loss: 0.0866 - accuracy: 0.9680 - val_loss: 0.5105 - val_accuracy: 0.7844\n",
      "Epoch 29/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9661\n",
      "Epoch 00029: val_accuracy did not improve from 0.95997\n",
      "\n",
      "Epoch 00029: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 262ms/step - loss: 0.0878 - accuracy: 0.9661 - val_loss: 0.1298 - val_accuracy: 0.9498\n",
      "Epoch 30/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9679\n",
      "Epoch 00030: val_accuracy improved from 0.95997 to 0.96828, saving model to gr-model_1-0030-0.968278.h5\n",
      "\n",
      "Epoch 00030: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 264ms/step - loss: 0.0849 - accuracy: 0.9679 - val_loss: 0.1100 - val_accuracy: 0.9683\n",
      "Epoch 31/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9684\n",
      "Epoch 00031: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00031: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 273ms/step - loss: 0.0831 - accuracy: 0.9684 - val_loss: 0.5448 - val_accuracy: 0.8172\n",
      "Epoch 32/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9741\n",
      "Epoch 00032: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00032: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0714 - accuracy: 0.9741 - val_loss: 0.1940 - val_accuracy: 0.9241\n",
      "Epoch 33/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9684\n",
      "Epoch 00033: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00033: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0836 - accuracy: 0.9684 - val_loss: 0.0980 - val_accuracy: 0.9649\n",
      "Epoch 34/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9721\n",
      "Epoch 00034: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00034: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0748 - accuracy: 0.9721 - val_loss: 0.1989 - val_accuracy: 0.9335\n",
      "Epoch 35/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9728\n",
      "Epoch 00035: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00035: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0737 - accuracy: 0.9728 - val_loss: 0.1059 - val_accuracy: 0.9626\n",
      "Epoch 36/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9708\n",
      "Epoch 00036: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00036: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.0729 - accuracy: 0.9708 - val_loss: 0.2365 - val_accuracy: 0.9120\n",
      "Epoch 37/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9750\n",
      "Epoch 00037: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00037: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0688 - accuracy: 0.9750 - val_loss: 0.9063 - val_accuracy: 0.6968\n",
      "Epoch 38/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9706\n",
      "Epoch 00038: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00038: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0763 - accuracy: 0.9706 - val_loss: 0.0953 - val_accuracy: 0.9664\n",
      "Epoch 39/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9751\n",
      "Epoch 00039: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00039: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0691 - accuracy: 0.9751 - val_loss: 0.2228 - val_accuracy: 0.9237\n",
      "Epoch 40/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9789\n",
      "Epoch 00040: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00040: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0590 - accuracy: 0.9789 - val_loss: 0.1148 - val_accuracy: 0.9607\n",
      "Epoch 41/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9751\n",
      "Epoch 00041: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00041: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0618 - accuracy: 0.9751 - val_loss: 0.2110 - val_accuracy: 0.9354\n",
      "Epoch 42/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9781\n",
      "Epoch 00042: val_accuracy improved from 0.96828 to 0.96941, saving model to gr-model_1-0042-0.969411.h5\n",
      "\n",
      "Epoch 00042: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 270ms/step - loss: 0.0595 - accuracy: 0.9781 - val_loss: 0.1070 - val_accuracy: 0.9694\n",
      "Epoch 43/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9752\n",
      "Epoch 00043: val_accuracy did not improve from 0.96941\n",
      "\n",
      "Epoch 00043: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0618 - accuracy: 0.9752 - val_loss: 0.4670 - val_accuracy: 0.8671\n",
      "Epoch 44/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9729\n",
      "Epoch 00044: val_accuracy did not improve from 0.96941\n",
      "\n",
      "Epoch 00044: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0692 - accuracy: 0.9729 - val_loss: 0.1254 - val_accuracy: 0.9558\n",
      "Epoch 45/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9776\n",
      "Epoch 00045: val_accuracy improved from 0.96941 to 0.97356, saving model to gr-model_1-0045-0.973565.h5\n",
      "\n",
      "Epoch 00045: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0612 - accuracy: 0.9776 - val_loss: 0.0720 - val_accuracy: 0.9736\n",
      "Epoch 46/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9771\n",
      "Epoch 00046: val_accuracy did not improve from 0.97356\n",
      "\n",
      "Epoch 00046: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0568 - accuracy: 0.9771 - val_loss: 0.1928 - val_accuracy: 0.9400\n",
      "Epoch 47/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9778\n",
      "Epoch 00047: val_accuracy did not improve from 0.97356\n",
      "\n",
      "Epoch 00047: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 270ms/step - loss: 0.0584 - accuracy: 0.9778 - val_loss: 0.8084 - val_accuracy: 0.7296\n",
      "Epoch 48/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9797\n",
      "Epoch 00048: val_accuracy did not improve from 0.97356\n",
      "\n",
      "Epoch 00048: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 269ms/step - loss: 0.0531 - accuracy: 0.9797 - val_loss: 0.2484 - val_accuracy: 0.9162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9791\n",
      "Epoch 00049: val_accuracy did not improve from 0.97356\n",
      "\n",
      "Epoch 00049: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 262ms/step - loss: 0.0590 - accuracy: 0.9791 - val_loss: 0.1872 - val_accuracy: 0.9445\n",
      "Epoch 50/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9786\n",
      "Epoch 00050: val_accuracy improved from 0.97356 to 0.97470, saving model to gr-model_1-0050-0.974698.h5\n",
      "\n",
      "Epoch 00050: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 263ms/step - loss: 0.0540 - accuracy: 0.9786 - val_loss: 0.0726 - val_accuracy: 0.9747\n",
      "Epoch 51/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9838\n",
      "Epoch 00051: val_accuracy improved from 0.97470 to 0.97659, saving model to gr-model_1-0051-0.976586.h5\n",
      "\n",
      "Epoch 00051: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 263ms/step - loss: 0.0413 - accuracy: 0.9838 - val_loss: 0.0644 - val_accuracy: 0.9766\n",
      "Epoch 52/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9880\n",
      "Epoch 00052: val_accuracy improved from 0.97659 to 0.97998, saving model to gr-model_1-0052-0.979985.h5\n",
      "\n",
      "Epoch 00052: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 263ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.0631 - val_accuracy: 0.9800\n",
      "Epoch 53/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9874\n",
      "Epoch 00053: val_accuracy did not improve from 0.97998\n",
      "\n",
      "Epoch 00053: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 262ms/step - loss: 0.0338 - accuracy: 0.9874 - val_loss: 0.0606 - val_accuracy: 0.9789\n",
      "Epoch 54/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9878\n",
      "Epoch 00054: val_accuracy did not improve from 0.97998\n",
      "\n",
      "Epoch 00054: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 262ms/step - loss: 0.0343 - accuracy: 0.9878 - val_loss: 0.0628 - val_accuracy: 0.9789\n",
      "Epoch 55/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9890\n",
      "Epoch 00055: val_accuracy did not improve from 0.97998\n",
      "\n",
      "Epoch 00055: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 265ms/step - loss: 0.0294 - accuracy: 0.9890 - val_loss: 0.0658 - val_accuracy: 0.9777\n",
      "Epoch 56/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9883\n",
      "Epoch 00056: val_accuracy did not improve from 0.97998\n",
      "\n",
      "Epoch 00056: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0316 - accuracy: 0.9883 - val_loss: 0.0633 - val_accuracy: 0.9785\n",
      "Epoch 57/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9890\n",
      "Epoch 00057: val_accuracy did not improve from 0.97998\n",
      "\n",
      "Epoch 00057: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0325 - accuracy: 0.9890 - val_loss: 0.0679 - val_accuracy: 0.9792\n",
      "Epoch 58/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9890\n",
      "Epoch 00058: val_accuracy did not improve from 0.97998\n",
      "\n",
      "Epoch 00058: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 0.0637 - val_accuracy: 0.9800\n",
      "Epoch 59/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9912\n",
      "Epoch 00059: val_accuracy did not improve from 0.97998\n",
      "\n",
      "Epoch 00059: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.0678 - val_accuracy: 0.9781\n",
      "Epoch 60/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9905\n",
      "Epoch 00060: val_accuracy did not improve from 0.97998\n",
      "\n",
      "Epoch 00060: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.0685 - val_accuracy: 0.9781\n",
      "Epoch 61/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9884\n",
      "Epoch 00061: val_accuracy improved from 0.97998 to 0.98187, saving model to gr-model_1-0061-0.981873.h5\n",
      "\n",
      "Epoch 00061: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 261ms/step - loss: 0.0319 - accuracy: 0.9884 - val_loss: 0.0678 - val_accuracy: 0.9819\n",
      "Epoch 62/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9892\n",
      "Epoch 00062: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00062: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0288 - accuracy: 0.9892 - val_loss: 0.0671 - val_accuracy: 0.9807\n",
      "Epoch 63/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9904\n",
      "Epoch 00063: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00063: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0270 - accuracy: 0.9904 - val_loss: 0.0650 - val_accuracy: 0.9792\n",
      "Epoch 64/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9899\n",
      "Epoch 00064: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00064: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0296 - accuracy: 0.9899 - val_loss: 0.0715 - val_accuracy: 0.9777\n",
      "Epoch 65/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9915\n",
      "Epoch 00065: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00065: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.0652 - val_accuracy: 0.9796\n",
      "Epoch 66/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9915\n",
      "Epoch 00066: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00066: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.0663 - val_accuracy: 0.9781\n",
      "Epoch 67/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9908\n",
      "Epoch 00067: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00067: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0251 - accuracy: 0.9908 - val_loss: 0.0703 - val_accuracy: 0.9785\n",
      "Epoch 68/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9903\n",
      "Epoch 00068: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00068: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0262 - accuracy: 0.9903 - val_loss: 0.0684 - val_accuracy: 0.9770\n",
      "Epoch 69/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9906\n",
      "Epoch 00069: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00069: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0263 - accuracy: 0.9906 - val_loss: 0.0731 - val_accuracy: 0.9781\n",
      "Epoch 70/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9911\n",
      "Epoch 00070: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00070: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0245 - accuracy: 0.9911 - val_loss: 0.0672 - val_accuracy: 0.9792\n",
      "Epoch 71/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9905\n",
      "Epoch 00071: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00071: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.0765 - val_accuracy: 0.9766\n",
      "Epoch 72/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9895\n",
      "Epoch 00072: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00072: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0269 - accuracy: 0.9895 - val_loss: 0.0700 - val_accuracy: 0.9789\n",
      "Epoch 73/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9912\n",
      "Epoch 00073: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00073: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 0.0730 - val_accuracy: 0.9789\n",
      "Epoch 74/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9912\n",
      "Epoch 00074: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00074: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.0690 - val_accuracy: 0.9785\n",
      "Epoch 75/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9912\n",
      "Epoch 00075: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00075: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 0.0857 - val_accuracy: 0.9747\n",
      "Epoch 76/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9910\n",
      "Epoch 00076: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00076: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0246 - accuracy: 0.9910 - val_loss: 0.0709 - val_accuracy: 0.9804\n",
      "Epoch 77/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9906\n",
      "Epoch 00077: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00077: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 262ms/step - loss: 0.0244 - accuracy: 0.9906 - val_loss: 0.0698 - val_accuracy: 0.9792\n",
      "Epoch 78/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9899\n",
      "Epoch 00078: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00078: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 268ms/step - loss: 0.0260 - accuracy: 0.9899 - val_loss: 0.0694 - val_accuracy: 0.9796\n",
      "Epoch 79/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9925\n",
      "Epoch 00079: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00079: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.0686 - val_accuracy: 0.9796\n",
      "Epoch 80/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9925\n",
      "Epoch 00080: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00080: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.0698 - val_accuracy: 0.9796\n",
      "Epoch 81/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9914\n",
      "Epoch 00081: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00081: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0233 - accuracy: 0.9914 - val_loss: 0.0705 - val_accuracy: 0.9792\n",
      "Epoch 82/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9926\n",
      "Epoch 00082: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00082: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.0701 - val_accuracy: 0.9796\n",
      "Epoch 83/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9910\n",
      "Epoch 00083: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00083: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0227 - accuracy: 0.9910 - val_loss: 0.0700 - val_accuracy: 0.9792\n",
      "Epoch 84/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9923\n",
      "Epoch 00084: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00084: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 270ms/step - loss: 0.0219 - accuracy: 0.9923 - val_loss: 0.0694 - val_accuracy: 0.9796\n",
      "Epoch 85/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9899\n",
      "Epoch 00085: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00085: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0259 - accuracy: 0.9899 - val_loss: 0.0688 - val_accuracy: 0.9796\n",
      "Epoch 86/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9918\n",
      "Epoch 00086: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00086: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0223 - accuracy: 0.9918 - val_loss: 0.0695 - val_accuracy: 0.9792\n",
      "Epoch 87/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9911\n",
      "Epoch 00087: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00087: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0245 - accuracy: 0.9911 - val_loss: 0.0697 - val_accuracy: 0.9800\n",
      "Epoch 88/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9925\n",
      "Epoch 00088: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00088: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.0704 - val_accuracy: 0.9792\n",
      "Epoch 89/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9910\n",
      "Epoch 00089: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00089: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0230 - accuracy: 0.9910 - val_loss: 0.0696 - val_accuracy: 0.9792\n",
      "Epoch 90/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9930\n",
      "Epoch 00090: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00090: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.0693 - val_accuracy: 0.9792\n",
      "Epoch 91/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9929\n",
      "Epoch 00091: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00091: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.0700 - val_accuracy: 0.9789\n",
      "Epoch 92/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9924\n",
      "Epoch 00092: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00092: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.0705 - val_accuracy: 0.9792\n",
      "Epoch 93/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9920\n",
      "Epoch 00093: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00093: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0228 - accuracy: 0.9920 - val_loss: 0.0704 - val_accuracy: 0.9796\n",
      "Epoch 94/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9932\n",
      "Epoch 00094: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00094: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.0701 - val_accuracy: 0.9785\n",
      "Epoch 95/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9918\n",
      "Epoch 00095: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00095: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.0700 - val_accuracy: 0.9785\n",
      "Epoch 96/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9919\n",
      "Epoch 00096: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00096: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0230 - accuracy: 0.9919 - val_loss: 0.0707 - val_accuracy: 0.9789\n",
      "Epoch 97/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9917\n",
      "Epoch 00097: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00097: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0228 - accuracy: 0.9917 - val_loss: 0.0701 - val_accuracy: 0.9785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9904\n",
      "Epoch 00098: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00098: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 263ms/step - loss: 0.0243 - accuracy: 0.9904 - val_loss: 0.0690 - val_accuracy: 0.9781\n",
      "Epoch 99/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9923\n",
      "Epoch 00099: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00099: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.0694 - val_accuracy: 0.9785\n",
      "Epoch 100/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9922\n",
      "Epoch 00100: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00100: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0691 - val_accuracy: 0.9789\n",
      "Epoch 101/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9927\n",
      "Epoch 00101: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00101: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.0686 - val_accuracy: 0.9781\n",
      "Epoch 102/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9919\n",
      "Epoch 00102: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00102: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0222 - accuracy: 0.9919 - val_loss: 0.0694 - val_accuracy: 0.9789\n",
      "Epoch 103/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9934\n",
      "Epoch 00103: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00103: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.0700 - val_accuracy: 0.9785\n",
      "Epoch 104/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9929\n",
      "Epoch 00104: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00104: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0699 - val_accuracy: 0.9785\n",
      "Epoch 105/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9920\n",
      "Epoch 00105: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00105: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0217 - accuracy: 0.9920 - val_loss: 0.0714 - val_accuracy: 0.9789\n",
      "Epoch 106/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9911\n",
      "Epoch 00106: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00106: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 269ms/step - loss: 0.0243 - accuracy: 0.9911 - val_loss: 0.0705 - val_accuracy: 0.9796\n",
      "Epoch 107/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9921\n",
      "Epoch 00107: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00107: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.0695 - val_accuracy: 0.9796\n",
      "Epoch 108/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9923\n",
      "Epoch 00108: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00108: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 265ms/step - loss: 0.0214 - accuracy: 0.9923 - val_loss: 0.0698 - val_accuracy: 0.9792\n",
      "Epoch 109/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9931\n",
      "Epoch 00109: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00109: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 265ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 0.0705 - val_accuracy: 0.9796\n",
      "Epoch 110/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9912\n",
      "Epoch 00110: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00110: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 265ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 0.0698 - val_accuracy: 0.9796\n",
      "Epoch 111/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9907\n",
      "Epoch 00111: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00111: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 265ms/step - loss: 0.0250 - accuracy: 0.9907 - val_loss: 0.0700 - val_accuracy: 0.9792\n",
      "Epoch 112/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9913\n",
      "Epoch 00112: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00112: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 265ms/step - loss: 0.0232 - accuracy: 0.9913 - val_loss: 0.0697 - val_accuracy: 0.9789\n",
      "Epoch 113/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9929\n",
      "Epoch 00113: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00113: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 265ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.0712 - val_accuracy: 0.9785\n",
      "Epoch 114/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9915\n",
      "Epoch 00114: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00114: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 265ms/step - loss: 0.0225 - accuracy: 0.9915 - val_loss: 0.0700 - val_accuracy: 0.9777\n",
      "Epoch 115/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9922\n",
      "Epoch 00115: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00115: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 265ms/step - loss: 0.0225 - accuracy: 0.9922 - val_loss: 0.0708 - val_accuracy: 0.9773\n",
      "Epoch 116/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9939\n",
      "Epoch 00116: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00116: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 265ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.0713 - val_accuracy: 0.9781\n",
      "Epoch 117/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9913\n",
      "Epoch 00117: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00117: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 270ms/step - loss: 0.0228 - accuracy: 0.9913 - val_loss: 0.0714 - val_accuracy: 0.9785\n",
      "Epoch 118/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9937\n",
      "Epoch 00118: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00118: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 274ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0707 - val_accuracy: 0.9781\n",
      "Epoch 119/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9918\n",
      "Epoch 00119: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00119: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.0219 - accuracy: 0.9918 - val_loss: 0.0705 - val_accuracy: 0.9777\n",
      "Epoch 120/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9903\n",
      "Epoch 00120: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00120: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.0238 - accuracy: 0.9903 - val_loss: 0.0698 - val_accuracy: 0.9777\n",
      "Epoch 121/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9920\n",
      "Epoch 00121: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00121: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.0228 - accuracy: 0.9920 - val_loss: 0.0705 - val_accuracy: 0.9785\n",
      "Epoch 122/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9921\n",
      "Epoch 00122: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00122: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.0707 - val_accuracy: 0.9785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9925\n",
      "Epoch 00123: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00123: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 262ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.0715 - val_accuracy: 0.9773\n",
      "Epoch 124/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9927\n",
      "Epoch 00124: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00124: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 262ms/step - loss: 0.0211 - accuracy: 0.9927 - val_loss: 0.0719 - val_accuracy: 0.9777\n",
      "Epoch 125/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9930\n",
      "Epoch 00125: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00125: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0199 - accuracy: 0.9930 - val_loss: 0.0705 - val_accuracy: 0.9789\n",
      "Epoch 126/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9924\n",
      "Epoch 00126: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00126: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0189 - accuracy: 0.9924 - val_loss: 0.0704 - val_accuracy: 0.9789\n",
      "Epoch 127/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9913\n",
      "Epoch 00127: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00127: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0216 - accuracy: 0.9913 - val_loss: 0.0709 - val_accuracy: 0.9792\n",
      "Epoch 128/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9934\n",
      "Epoch 00128: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00128: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.0717 - val_accuracy: 0.9792\n",
      "Epoch 129/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9931\n",
      "Epoch 00129: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00129: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0708 - val_accuracy: 0.9785\n",
      "Epoch 130/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9930\n",
      "Epoch 00130: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00130: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0192 - accuracy: 0.9930 - val_loss: 0.0719 - val_accuracy: 0.9781\n",
      "Epoch 131/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9940\n",
      "Epoch 00131: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00131: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0713 - val_accuracy: 0.9789\n",
      "Epoch 132/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9919\n",
      "Epoch 00132: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00132: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0213 - accuracy: 0.9919 - val_loss: 0.0709 - val_accuracy: 0.9781\n",
      "Epoch 133/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9924\n",
      "Epoch 00133: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00133: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0199 - accuracy: 0.9924 - val_loss: 0.0716 - val_accuracy: 0.9781\n",
      "Epoch 134/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9929\n",
      "Epoch 00134: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00134: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0199 - accuracy: 0.9929 - val_loss: 0.0718 - val_accuracy: 0.9789\n",
      "Epoch 135/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9923\n",
      "Epoch 00135: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00135: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0210 - accuracy: 0.9923 - val_loss: 0.0706 - val_accuracy: 0.9785\n",
      "Epoch 136/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9916\n",
      "Epoch 00136: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00136: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0225 - accuracy: 0.9916 - val_loss: 0.0702 - val_accuracy: 0.9781\n",
      "Epoch 137/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9917\n",
      "Epoch 00137: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00137: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0225 - accuracy: 0.9917 - val_loss: 0.0704 - val_accuracy: 0.9785\n",
      "Epoch 138/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9937\n",
      "Epoch 00138: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00138: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.0712 - val_accuracy: 0.9785\n",
      "Epoch 139/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9930\n",
      "Epoch 00139: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00139: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 0.0704 - val_accuracy: 0.9781\n",
      "Epoch 140/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9929\n",
      "Epoch 00140: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00140: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.0704 - val_accuracy: 0.9789\n",
      "Epoch 141/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9914\n",
      "Epoch 00141: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00141: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.0708 - val_accuracy: 0.9785\n",
      "Epoch 142/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9922\n",
      "Epoch 00142: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00142: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.0705 - val_accuracy: 0.9789\n",
      "Epoch 143/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9932\n",
      "Epoch 00143: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00143: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.0714 - val_accuracy: 0.9789\n",
      "Epoch 144/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9917\n",
      "Epoch 00144: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00144: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0224 - accuracy: 0.9917 - val_loss: 0.0704 - val_accuracy: 0.9785\n",
      "Epoch 145/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9911\n",
      "Epoch 00145: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00145: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0248 - accuracy: 0.9911 - val_loss: 0.0710 - val_accuracy: 0.9785\n",
      "Epoch 146/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9921\n",
      "Epoch 00146: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00146: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.0720 - val_accuracy: 0.9781\n",
      "Epoch 147/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9920\n",
      "Epoch 00147: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00147: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0221 - accuracy: 0.9920 - val_loss: 0.0712 - val_accuracy: 0.9789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9920\n",
      "Epoch 00148: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00148: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0204 - accuracy: 0.9920 - val_loss: 0.0711 - val_accuracy: 0.9792\n",
      "Epoch 149/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9931\n",
      "Epoch 00149: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00149: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.0700 - val_accuracy: 0.9781\n",
      "Epoch 150/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9931\n",
      "Epoch 00150: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00150: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.0707 - val_accuracy: 0.9777\n",
      "Epoch 151/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9928\n",
      "Epoch 00151: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00151: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 0.0715 - val_accuracy: 0.9789\n",
      "Epoch 152/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9939\n",
      "Epoch 00152: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00152: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.0721 - val_accuracy: 0.9785\n",
      "Epoch 153/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9924\n",
      "Epoch 00153: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00153: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0213 - accuracy: 0.9924 - val_loss: 0.0711 - val_accuracy: 0.9785\n",
      "Epoch 154/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9930\n",
      "Epoch 00154: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00154: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 0.0708 - val_accuracy: 0.9785\n",
      "Epoch 155/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9918\n",
      "Epoch 00155: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00155: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0212 - accuracy: 0.9918 - val_loss: 0.0716 - val_accuracy: 0.9792\n",
      "Epoch 156/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9927\n",
      "Epoch 00156: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00156: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.0719 - val_accuracy: 0.9792\n",
      "Epoch 157/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9919\n",
      "Epoch 00157: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00157: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0218 - accuracy: 0.9919 - val_loss: 0.0714 - val_accuracy: 0.9785\n",
      "Epoch 158/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9920\n",
      "Epoch 00158: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00158: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0211 - accuracy: 0.9920 - val_loss: 0.0714 - val_accuracy: 0.9792\n",
      "Epoch 159/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9929\n",
      "Epoch 00159: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00159: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.0717 - val_accuracy: 0.9789\n",
      "Epoch 160/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9918\n",
      "Epoch 00160: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00160: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0219 - accuracy: 0.9918 - val_loss: 0.0713 - val_accuracy: 0.9789\n",
      "Epoch 161/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9929\n",
      "Epoch 00161: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00161: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0200 - accuracy: 0.9929 - val_loss: 0.0714 - val_accuracy: 0.9789\n",
      "Epoch 162/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9912\n",
      "Epoch 00162: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00162: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0210 - accuracy: 0.9912 - val_loss: 0.0713 - val_accuracy: 0.9789\n",
      "Epoch 163/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9942\n",
      "Epoch 00163: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00163: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.0707 - val_accuracy: 0.9789\n",
      "Epoch 164/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9922\n",
      "Epoch 00164: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00164: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 270ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.0711 - val_accuracy: 0.9789\n",
      "Epoch 165/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9936\n",
      "Epoch 00165: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00165: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0716 - val_accuracy: 0.9792\n",
      "Epoch 166/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9928\n",
      "Epoch 00166: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00166: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 0.0705 - val_accuracy: 0.9785\n",
      "Epoch 167/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9932\n",
      "Epoch 00167: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00167: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.0709 - val_accuracy: 0.9785\n",
      "Epoch 168/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9933\n",
      "Epoch 00168: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00168: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0715 - val_accuracy: 0.9789\n",
      "Epoch 169/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9923\n",
      "Epoch 00169: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00169: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.0221 - accuracy: 0.9923 - val_loss: 0.0716 - val_accuracy: 0.9789\n",
      "Epoch 170/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9929\n",
      "Epoch 00170: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00170: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.0191 - accuracy: 0.9929 - val_loss: 0.0713 - val_accuracy: 0.9789\n",
      "Epoch 171/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9910\n",
      "Epoch 00171: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00171: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 270ms/step - loss: 0.0220 - accuracy: 0.9910 - val_loss: 0.0714 - val_accuracy: 0.9789\n",
      "Epoch 172/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9920\n",
      "Epoch 00172: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00172: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0203 - accuracy: 0.9920 - val_loss: 0.0714 - val_accuracy: 0.9789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9930\n",
      "Epoch 00173: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00173: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.0712 - val_accuracy: 0.9789\n",
      "Epoch 174/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9930\n",
      "Epoch 00174: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00174: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 261ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0709 - val_accuracy: 0.9785\n",
      "Epoch 175/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9923\n",
      "Epoch 00175: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00175: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.0711 - val_accuracy: 0.9785\n",
      "Epoch 176/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9911\n",
      "Epoch 00176: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00176: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0222 - accuracy: 0.9911 - val_loss: 0.0718 - val_accuracy: 0.9792\n",
      "Epoch 177/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9933\n",
      "Epoch 00177: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00177: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 0.0713 - val_accuracy: 0.9789\n",
      "Epoch 178/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9911\n",
      "Epoch 00178: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00178: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0224 - accuracy: 0.9911 - val_loss: 0.0714 - val_accuracy: 0.9789\n",
      "Epoch 179/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9930\n",
      "Epoch 00179: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00179: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0202 - accuracy: 0.9930 - val_loss: 0.0716 - val_accuracy: 0.9785\n",
      "Epoch 180/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9918\n",
      "Epoch 00180: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00180: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0211 - accuracy: 0.9918 - val_loss: 0.0712 - val_accuracy: 0.9792\n",
      "Epoch 181/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9914\n",
      "Epoch 00181: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00181: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0225 - accuracy: 0.9914 - val_loss: 0.0715 - val_accuracy: 0.9792\n",
      "Epoch 182/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9926\n",
      "Epoch 00182: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00182: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0197 - accuracy: 0.9926 - val_loss: 0.0716 - val_accuracy: 0.9792\n",
      "Epoch 183/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9935\n",
      "Epoch 00183: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00183: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.0712 - val_accuracy: 0.9789\n",
      "Epoch 184/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9926\n",
      "Epoch 00184: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00184: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.0716 - val_accuracy: 0.9789\n",
      "Epoch 185/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9932\n",
      "Epoch 00185: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00185: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.0715 - val_accuracy: 0.9789\n",
      "Epoch 186/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9940\n",
      "Epoch 00186: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00186: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0722 - val_accuracy: 0.9792\n",
      "Epoch 187/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9935\n",
      "Epoch 00187: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00187: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0189 - accuracy: 0.9935 - val_loss: 0.0719 - val_accuracy: 0.9792\n",
      "Epoch 188/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9944\n",
      "Epoch 00188: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00188: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 268ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0720 - val_accuracy: 0.9792\n",
      "Epoch 189/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9930\n",
      "Epoch 00189: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00189: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0202 - accuracy: 0.9930 - val_loss: 0.0719 - val_accuracy: 0.9792\n",
      "Epoch 190/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9919\n",
      "Epoch 00190: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00190: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0234 - accuracy: 0.9919 - val_loss: 0.0721 - val_accuracy: 0.9792\n",
      "Epoch 191/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9923\n",
      "Epoch 00191: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00191: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.0207 - accuracy: 0.9923 - val_loss: 0.0714 - val_accuracy: 0.9789\n",
      "Epoch 192/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9941\n",
      "Epoch 00192: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00192: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0721 - val_accuracy: 0.9789\n",
      "Epoch 193/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9916\n",
      "Epoch 00193: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00193: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 268ms/step - loss: 0.0214 - accuracy: 0.9916 - val_loss: 0.0720 - val_accuracy: 0.9789\n",
      "Epoch 194/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9921\n",
      "Epoch 00194: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00194: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 45s 270ms/step - loss: 0.0213 - accuracy: 0.9921 - val_loss: 0.0721 - val_accuracy: 0.9785\n",
      "Epoch 195/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9923\n",
      "Epoch 00195: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00195: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 267ms/step - loss: 0.0212 - accuracy: 0.9923 - val_loss: 0.0723 - val_accuracy: 0.9785\n",
      "Epoch 196/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9922\n",
      "Epoch 00196: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00196: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.0721 - val_accuracy: 0.9785\n",
      "Epoch 197/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9926\n",
      "Epoch 00197: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00197: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 44s 266ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.0723 - val_accuracy: 0.9789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9934\n",
      "Epoch 00198: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00198: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0195 - accuracy: 0.9934 - val_loss: 0.0723 - val_accuracy: 0.9789\n",
      "Epoch 199/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9940\n",
      "Epoch 00199: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00199: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.0723 - val_accuracy: 0.9785\n",
      "Epoch 200/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9922\n",
      "Epoch 00200: val_accuracy did not improve from 0.98187\n",
      "\n",
      "Epoch 00200: saving model to gr-model_1.h5\n",
      "166/165 [==============================] - 43s 260ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.0722 - val_accuracy: 0.9789\n",
      "Test loss: 0.07220654934644699\n",
      "Test accuracy: 0.9788519740104675\n",
      "Test error: 0.02114802598953247\n"
     ]
    }
   ],
   "source": [
    "model_1 = model_vgg_mini\n",
    "model_1 = training_and_evaluation(model=model_1,\n",
    "                                  model_id='model_1',\n",
    "                                  scheduler=scheduler_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.5428 - accuracy: 0.7650\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66314, saving model to gr-model_2-0001-0.663142.h5\n",
      "\n",
      "Epoch 00001: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 49s 294ms/step - loss: 0.5428 - accuracy: 0.7650 - val_loss: 0.6159 - val_accuracy: 0.6631\n",
      "Epoch 2/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.7940\n",
      "Epoch 00002: val_accuracy improved from 0.66314 to 0.76586, saving model to gr-model_2-0002-0.765861.h5\n",
      "\n",
      "Epoch 00002: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 285ms/step - loss: 0.4516 - accuracy: 0.7940 - val_loss: 0.4838 - val_accuracy: 0.7659\n",
      "Epoch 3/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4195 - accuracy: 0.8023\n",
      "Epoch 00003: val_accuracy improved from 0.76586 to 0.78361, saving model to gr-model_2-0003-0.783610.h5\n",
      "\n",
      "Epoch 00003: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 284ms/step - loss: 0.4195 - accuracy: 0.8023 - val_loss: 0.5030 - val_accuracy: 0.7836\n",
      "Epoch 4/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.8170\n",
      "Epoch 00004: val_accuracy did not improve from 0.78361\n",
      "\n",
      "Epoch 00004: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 282ms/step - loss: 0.4020 - accuracy: 0.8170 - val_loss: 0.4793 - val_accuracy: 0.7572\n",
      "Epoch 5/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3759 - accuracy: 0.8270\n",
      "Epoch 00005: val_accuracy did not improve from 0.78361\n",
      "\n",
      "Epoch 00005: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 282ms/step - loss: 0.3759 - accuracy: 0.8270 - val_loss: 0.5820 - val_accuracy: 0.6975\n",
      "Epoch 6/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.8582\n",
      "Epoch 00006: val_accuracy did not improve from 0.78361\n",
      "\n",
      "Epoch 00006: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 282ms/step - loss: 0.3255 - accuracy: 0.8582 - val_loss: 0.6461 - val_accuracy: 0.6854\n",
      "Epoch 7/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2829 - accuracy: 0.8796\n",
      "Epoch 00007: val_accuracy did not improve from 0.78361\n",
      "\n",
      "Epoch 00007: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.2829 - accuracy: 0.8796 - val_loss: 2.7518 - val_accuracy: 0.4328\n",
      "Epoch 8/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.9032\n",
      "Epoch 00008: val_accuracy improved from 0.78361 to 0.87953, saving model to gr-model_2-0008-0.879532.h5\n",
      "\n",
      "Epoch 00008: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 284ms/step - loss: 0.2418 - accuracy: 0.9032 - val_loss: 0.3316 - val_accuracy: 0.8795\n",
      "Epoch 9/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.9169\n",
      "Epoch 00009: val_accuracy improved from 0.87953 to 0.92560, saving model to gr-model_2-0009-0.925604.h5\n",
      "\n",
      "Epoch 00009: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.2065 - accuracy: 0.9169 - val_loss: 0.1870 - val_accuracy: 0.9256\n",
      "Epoch 10/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9221\n",
      "Epoch 00010: val_accuracy did not improve from 0.92560\n",
      "\n",
      "Epoch 00010: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.1885 - accuracy: 0.9221 - val_loss: 0.4422 - val_accuracy: 0.8308\n",
      "Epoch 11/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9308\n",
      "Epoch 00011: val_accuracy did not improve from 0.92560\n",
      "\n",
      "Epoch 00011: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.1721 - accuracy: 0.9308 - val_loss: 0.5166 - val_accuracy: 0.7711\n",
      "Epoch 12/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9388\n",
      "Epoch 00012: val_accuracy improved from 0.92560 to 0.94713, saving model to gr-model_2-0012-0.947130.h5\n",
      "\n",
      "Epoch 00012: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 284ms/step - loss: 0.1565 - accuracy: 0.9388 - val_loss: 0.1383 - val_accuracy: 0.9471\n",
      "Epoch 13/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1494 - accuracy: 0.9400\n",
      "Epoch 00013: val_accuracy did not improve from 0.94713\n",
      "\n",
      "Epoch 00013: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.1494 - accuracy: 0.9400 - val_loss: 0.2116 - val_accuracy: 0.9313\n",
      "Epoch 14/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 0.9431\n",
      "Epoch 00014: val_accuracy did not improve from 0.94713\n",
      "\n",
      "Epoch 00014: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.1424 - accuracy: 0.9431 - val_loss: 0.1709 - val_accuracy: 0.9430\n",
      "Epoch 15/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9494\n",
      "Epoch 00015: val_accuracy improved from 0.94713 to 0.95733, saving model to gr-model_2-0015-0.957326.h5\n",
      "\n",
      "Epoch 00015: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 284ms/step - loss: 0.1304 - accuracy: 0.9494 - val_loss: 0.1146 - val_accuracy: 0.9573\n",
      "Epoch 16/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1292 - accuracy: 0.9495\n",
      "Epoch 00016: val_accuracy did not improve from 0.95733\n",
      "\n",
      "Epoch 00016: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.1292 - accuracy: 0.9495 - val_loss: 0.3092 - val_accuracy: 0.8890\n",
      "Epoch 17/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9547\n",
      "Epoch 00017: val_accuracy did not improve from 0.95733\n",
      "\n",
      "Epoch 00017: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.1169 - accuracy: 0.9547 - val_loss: 1.7345 - val_accuracy: 0.5819\n",
      "Epoch 18/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9560\n",
      "Epoch 00018: val_accuracy did not improve from 0.95733\n",
      "\n",
      "Epoch 00018: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.1137 - accuracy: 0.9560 - val_loss: 0.6559 - val_accuracy: 0.8576\n",
      "Epoch 19/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9573\n",
      "Epoch 00019: val_accuracy did not improve from 0.95733\n",
      "\n",
      "Epoch 00019: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.1089 - accuracy: 0.9573 - val_loss: 0.1231 - val_accuracy: 0.9524\n",
      "Epoch 20/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9584\n",
      "Epoch 00020: val_accuracy did not improve from 0.95733\n",
      "\n",
      "Epoch 00020: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.1096 - accuracy: 0.9584 - val_loss: 0.2460 - val_accuracy: 0.9139\n",
      "Epoch 21/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9592\n",
      "Epoch 00021: val_accuracy did not improve from 0.95733\n",
      "\n",
      "Epoch 00021: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.1069 - accuracy: 0.9592 - val_loss: 1.0594 - val_accuracy: 0.6624\n",
      "Epoch 22/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9632\n",
      "Epoch 00022: val_accuracy did not improve from 0.95733\n",
      "\n",
      "Epoch 00022: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.0948 - accuracy: 0.9632 - val_loss: 0.1922 - val_accuracy: 0.9275\n",
      "Epoch 23/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9626\n",
      "Epoch 00023: val_accuracy improved from 0.95733 to 0.96715, saving model to gr-model_2-0023-0.967145.h5\n",
      "\n",
      "Epoch 00023: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 284ms/step - loss: 0.0938 - accuracy: 0.9626 - val_loss: 0.0890 - val_accuracy: 0.9671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9639\n",
      "Epoch 00024: val_accuracy did not improve from 0.96715\n",
      "\n",
      "Epoch 00024: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0974 - accuracy: 0.9639 - val_loss: 0.1801 - val_accuracy: 0.9264\n",
      "Epoch 25/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.9617\n",
      "Epoch 00025: val_accuracy did not improve from 0.96715\n",
      "\n",
      "Epoch 00025: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0981 - accuracy: 0.9617 - val_loss: 0.3194 - val_accuracy: 0.9267\n",
      "Epoch 26/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9650\n",
      "Epoch 00026: val_accuracy did not improve from 0.96715\n",
      "\n",
      "Epoch 00026: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0891 - accuracy: 0.9650 - val_loss: 0.1647 - val_accuracy: 0.9551\n",
      "Epoch 27/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9661\n",
      "Epoch 00027: val_accuracy did not improve from 0.96715\n",
      "\n",
      "Epoch 00027: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0941 - accuracy: 0.9661 - val_loss: 0.1797 - val_accuracy: 0.9524\n",
      "Epoch 28/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.9697\n",
      "Epoch 00028: val_accuracy did not improve from 0.96715\n",
      "\n",
      "Epoch 00028: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0813 - accuracy: 0.9697 - val_loss: 0.1494 - val_accuracy: 0.9377\n",
      "Epoch 29/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9636\n",
      "Epoch 00029: val_accuracy improved from 0.96715 to 0.96790, saving model to gr-model_2-0029-0.967900.h5\n",
      "\n",
      "Epoch 00029: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0918 - accuracy: 0.9636 - val_loss: 0.0944 - val_accuracy: 0.9679\n",
      "Epoch 30/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9712\n",
      "Epoch 00030: val_accuracy improved from 0.96790 to 0.96828, saving model to gr-model_2-0030-0.968278.h5\n",
      "\n",
      "Epoch 00030: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0767 - accuracy: 0.9712 - val_loss: 0.1158 - val_accuracy: 0.9683\n",
      "Epoch 31/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9716\n",
      "Epoch 00031: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00031: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0785 - accuracy: 0.9716 - val_loss: 0.1548 - val_accuracy: 0.9434\n",
      "Epoch 32/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9707\n",
      "Epoch 00032: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00032: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0781 - accuracy: 0.9707 - val_loss: 0.2389 - val_accuracy: 0.9483\n",
      "Epoch 33/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9724\n",
      "Epoch 00033: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00033: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0723 - accuracy: 0.9724 - val_loss: 0.3558 - val_accuracy: 0.8720\n",
      "Epoch 34/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9726\n",
      "Epoch 00034: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00034: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0766 - accuracy: 0.9726 - val_loss: 0.2906 - val_accuracy: 0.9203\n",
      "Epoch 35/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9737\n",
      "Epoch 00035: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00035: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0676 - accuracy: 0.9737 - val_loss: 0.2392 - val_accuracy: 0.9275\n",
      "Epoch 36/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9737\n",
      "Epoch 00036: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00036: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0687 - accuracy: 0.9737 - val_loss: 0.4212 - val_accuracy: 0.8395\n",
      "Epoch 37/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9769\n",
      "Epoch 00037: val_accuracy did not improve from 0.96828\n",
      "\n",
      "Epoch 00037: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0644 - accuracy: 0.9769 - val_loss: 0.1709 - val_accuracy: 0.9350\n",
      "Epoch 38/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9741\n",
      "Epoch 00038: val_accuracy improved from 0.96828 to 0.96979, saving model to gr-model_2-0038-0.969788.h5\n",
      "\n",
      "Epoch 00038: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0658 - accuracy: 0.9741 - val_loss: 0.1018 - val_accuracy: 0.9698\n",
      "Epoch 39/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9753\n",
      "Epoch 00039: val_accuracy did not improve from 0.96979\n",
      "\n",
      "Epoch 00039: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0639 - accuracy: 0.9753 - val_loss: 0.1470 - val_accuracy: 0.9513\n",
      "Epoch 40/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9744\n",
      "Epoch 00040: val_accuracy did not improve from 0.96979\n",
      "\n",
      "Epoch 00040: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 281ms/step - loss: 0.0656 - accuracy: 0.9744 - val_loss: 0.1305 - val_accuracy: 0.9592\n",
      "Epoch 41/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9768\n",
      "Epoch 00041: val_accuracy improved from 0.96979 to 0.97130, saving model to gr-model_2-0041-0.971299.h5\n",
      "\n",
      "Epoch 00041: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 48s 288ms/step - loss: 0.0594 - accuracy: 0.9768 - val_loss: 0.0840 - val_accuracy: 0.9713\n",
      "Epoch 42/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9784\n",
      "Epoch 00042: val_accuracy did not improve from 0.97130\n",
      "\n",
      "Epoch 00042: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 48s 289ms/step - loss: 0.0584 - accuracy: 0.9784 - val_loss: 0.0898 - val_accuracy: 0.9649\n",
      "Epoch 43/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9777\n",
      "Epoch 00043: val_accuracy did not improve from 0.97130\n",
      "\n",
      "Epoch 00043: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 280ms/step - loss: 0.0601 - accuracy: 0.9777 - val_loss: 0.8045 - val_accuracy: 0.7353\n",
      "Epoch 44/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9770\n",
      "Epoch 00044: val_accuracy did not improve from 0.97130\n",
      "\n",
      "Epoch 00044: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 48s 287ms/step - loss: 0.0607 - accuracy: 0.9770 - val_loss: 0.2800 - val_accuracy: 0.9407\n",
      "Epoch 45/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9783\n",
      "Epoch 00045: val_accuracy improved from 0.97130 to 0.97168, saving model to gr-model_2-0045-0.971677.h5\n",
      "\n",
      "Epoch 00045: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 286ms/step - loss: 0.0554 - accuracy: 0.9783 - val_loss: 0.0923 - val_accuracy: 0.9717\n",
      "Epoch 46/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9797\n",
      "Epoch 00046: val_accuracy did not improve from 0.97168\n",
      "\n",
      "Epoch 00046: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.0554 - accuracy: 0.9797 - val_loss: 0.1036 - val_accuracy: 0.9702\n",
      "Epoch 47/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9799\n",
      "Epoch 00047: val_accuracy did not improve from 0.97168\n",
      "\n",
      "Epoch 00047: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 47s 283ms/step - loss: 0.0556 - accuracy: 0.9799 - val_loss: 0.3532 - val_accuracy: 0.8946\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/165 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9799\n",
      "Epoch 00048: val_accuracy did not improve from 0.97168\n",
      "\n",
      "Epoch 00048: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0508 - accuracy: 0.9799 - val_loss: 0.2380 - val_accuracy: 0.9354\n",
      "Epoch 49/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9817\n",
      "Epoch 00049: val_accuracy did not improve from 0.97168\n",
      "\n",
      "Epoch 00049: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0485 - accuracy: 0.9817 - val_loss: 0.2817 - val_accuracy: 0.9063\n",
      "Epoch 50/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9790\n",
      "Epoch 00050: val_accuracy improved from 0.97168 to 0.97659, saving model to gr-model_2-0050-0.976586.h5\n",
      "\n",
      "Epoch 00050: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0545 - accuracy: 0.9790 - val_loss: 0.0768 - val_accuracy: 0.9766\n",
      "Epoch 51/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9848\n",
      "Epoch 00051: val_accuracy improved from 0.97659 to 0.97810, saving model to gr-model_2-0051-0.978097.h5\n",
      "\n",
      "Epoch 00051: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0369 - accuracy: 0.9848 - val_loss: 0.0691 - val_accuracy: 0.9781\n",
      "Epoch 52/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9898\n",
      "Epoch 00052: val_accuracy did not improve from 0.97810\n",
      "\n",
      "Epoch 00052: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0309 - accuracy: 0.9898 - val_loss: 0.0780 - val_accuracy: 0.9739\n",
      "Epoch 53/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9882\n",
      "Epoch 00053: val_accuracy did not improve from 0.97810\n",
      "\n",
      "Epoch 00053: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0310 - accuracy: 0.9882 - val_loss: 0.0796 - val_accuracy: 0.9736\n",
      "Epoch 54/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9875\n",
      "Epoch 00054: val_accuracy improved from 0.97810 to 0.97847, saving model to gr-model_2-0054-0.978474.h5\n",
      "\n",
      "Epoch 00054: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0328 - accuracy: 0.9875 - val_loss: 0.0721 - val_accuracy: 0.9785\n",
      "Epoch 55/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9906\n",
      "Epoch 00055: val_accuracy did not improve from 0.97847\n",
      "\n",
      "Epoch 00055: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.0744 - val_accuracy: 0.9755\n",
      "Epoch 56/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9899\n",
      "Epoch 00056: val_accuracy did not improve from 0.97847\n",
      "\n",
      "Epoch 00056: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0302 - accuracy: 0.9899 - val_loss: 0.0691 - val_accuracy: 0.9770\n",
      "Epoch 57/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9908\n",
      "Epoch 00057: val_accuracy did not improve from 0.97847\n",
      "\n",
      "Epoch 00057: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.0849 - val_accuracy: 0.9721\n",
      "Epoch 58/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9906\n",
      "Epoch 00058: val_accuracy did not improve from 0.97847\n",
      "\n",
      "Epoch 00058: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0268 - accuracy: 0.9906 - val_loss: 0.0676 - val_accuracy: 0.9762\n",
      "Epoch 59/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9909\n",
      "Epoch 00059: val_accuracy did not improve from 0.97847\n",
      "\n",
      "Epoch 00059: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0257 - accuracy: 0.9909 - val_loss: 0.0730 - val_accuracy: 0.9777\n",
      "Epoch 60/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9917\n",
      "Epoch 00060: val_accuracy did not improve from 0.97847\n",
      "\n",
      "Epoch 00060: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.0704 - val_accuracy: 0.9785\n",
      "Epoch 61/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9921\n",
      "Epoch 00061: val_accuracy did not improve from 0.97847\n",
      "\n",
      "Epoch 00061: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.0701 - val_accuracy: 0.9781\n",
      "Epoch 62/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9917\n",
      "Epoch 00062: val_accuracy did not improve from 0.97847\n",
      "\n",
      "Epoch 00062: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0978 - val_accuracy: 0.9721\n",
      "Epoch 63/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9923\n",
      "Epoch 00063: val_accuracy did not improve from 0.97847\n",
      "\n",
      "Epoch 00063: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0753 - val_accuracy: 0.9773\n",
      "Epoch 64/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9935\n",
      "Epoch 00064: val_accuracy did not improve from 0.97847\n",
      "\n",
      "Epoch 00064: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.0765 - val_accuracy: 0.9762\n",
      "Epoch 65/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9919\n",
      "Epoch 00065: val_accuracy did not improve from 0.97847\n",
      "\n",
      "Epoch 00065: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.0918 - val_accuracy: 0.9732\n",
      "Epoch 66/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9933\n",
      "Epoch 00066: val_accuracy improved from 0.97847 to 0.97885, saving model to gr-model_2-0066-0.978852.h5\n",
      "\n",
      "Epoch 00066: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0763 - val_accuracy: 0.9789\n",
      "Epoch 67/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9904\n",
      "Epoch 00067: val_accuracy did not improve from 0.97885\n",
      "\n",
      "Epoch 00067: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0239 - accuracy: 0.9904 - val_loss: 0.0726 - val_accuracy: 0.9777\n",
      "Epoch 68/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9913\n",
      "Epoch 00068: val_accuracy did not improve from 0.97885\n",
      "\n",
      "Epoch 00068: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.0801 - val_accuracy: 0.9766\n",
      "Epoch 69/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9906\n",
      "Epoch 00069: val_accuracy did not improve from 0.97885\n",
      "\n",
      "Epoch 00069: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0240 - accuracy: 0.9906 - val_loss: 0.0777 - val_accuracy: 0.9777\n",
      "Epoch 70/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9915\n",
      "Epoch 00070: val_accuracy did not improve from 0.97885\n",
      "\n",
      "Epoch 00070: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.0795 - val_accuracy: 0.9781\n",
      "Epoch 71/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9911\n",
      "Epoch 00071: val_accuracy did not improve from 0.97885\n",
      "\n",
      "Epoch 00071: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0241 - accuracy: 0.9911 - val_loss: 0.0813 - val_accuracy: 0.9747\n",
      "Epoch 72/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9910\n",
      "Epoch 00072: val_accuracy did not improve from 0.97885\n",
      "\n",
      "Epoch 00072: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0224 - accuracy: 0.9910 - val_loss: 0.0831 - val_accuracy: 0.9747\n",
      "Epoch 73/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9922\n",
      "Epoch 00073: val_accuracy did not improve from 0.97885\n",
      "\n",
      "Epoch 00073: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.0806 - val_accuracy: 0.9766\n",
      "Epoch 74/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9926\n",
      "Epoch 00074: val_accuracy did not improve from 0.97885\n",
      "\n",
      "Epoch 00074: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0212 - accuracy: 0.9926 - val_loss: 0.0790 - val_accuracy: 0.9755\n",
      "Epoch 75/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9921\n",
      "Epoch 00075: val_accuracy did not improve from 0.97885\n",
      "\n",
      "Epoch 00075: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0217 - accuracy: 0.9921 - val_loss: 0.0776 - val_accuracy: 0.9773\n",
      "Epoch 76/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9925\n",
      "Epoch 00076: val_accuracy improved from 0.97885 to 0.97923, saving model to gr-model_2-0076-0.979230.h5\n",
      "\n",
      "Epoch 00076: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0207 - accuracy: 0.9925 - val_loss: 0.0772 - val_accuracy: 0.9792\n",
      "Epoch 77/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9920\n",
      "Epoch 00077: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00077: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0205 - accuracy: 0.9920 - val_loss: 0.0785 - val_accuracy: 0.9785\n",
      "Epoch 78/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9940\n",
      "Epoch 00078: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00078: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0168 - accuracy: 0.9940 - val_loss: 0.0784 - val_accuracy: 0.9781\n",
      "Epoch 79/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9921\n",
      "Epoch 00079: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00079: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.0780 - val_accuracy: 0.9789\n",
      "Epoch 80/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9926\n",
      "Epoch 00080: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00080: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0208 - accuracy: 0.9926 - val_loss: 0.0779 - val_accuracy: 0.9785\n",
      "Epoch 81/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9935\n",
      "Epoch 00081: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00081: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.0794 - val_accuracy: 0.9781\n",
      "Epoch 82/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9935\n",
      "Epoch 00082: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00082: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0803 - val_accuracy: 0.9781\n",
      "Epoch 83/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9940\n",
      "Epoch 00083: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00083: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.0804 - val_accuracy: 0.9781\n",
      "Epoch 84/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9917\n",
      "Epoch 00084: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00084: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0199 - accuracy: 0.9917 - val_loss: 0.0805 - val_accuracy: 0.9781\n",
      "Epoch 85/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9917\n",
      "Epoch 00085: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00085: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0221 - accuracy: 0.9917 - val_loss: 0.0810 - val_accuracy: 0.9777\n",
      "Epoch 86/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9928\n",
      "Epoch 00086: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00086: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0196 - accuracy: 0.9928 - val_loss: 0.0798 - val_accuracy: 0.9781\n",
      "Epoch 87/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9940\n",
      "Epoch 00087: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00087: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0795 - val_accuracy: 0.9781\n",
      "Epoch 88/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9923\n",
      "Epoch 00088: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00088: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0194 - accuracy: 0.9923 - val_loss: 0.0792 - val_accuracy: 0.9777\n",
      "Epoch 89/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9924\n",
      "Epoch 00089: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00089: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0218 - accuracy: 0.9924 - val_loss: 0.0812 - val_accuracy: 0.9781\n",
      "Epoch 90/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9929\n",
      "Epoch 00090: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00090: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.0801 - val_accuracy: 0.9781\n",
      "Epoch 91/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9935\n",
      "Epoch 00091: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00091: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.0794 - val_accuracy: 0.9781\n",
      "Epoch 92/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9941\n",
      "Epoch 00092: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00092: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.0805 - val_accuracy: 0.9781\n",
      "Epoch 93/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9936\n",
      "Epoch 00093: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00093: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0792 - val_accuracy: 0.9785\n",
      "Epoch 94/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9928\n",
      "Epoch 00094: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00094: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0210 - accuracy: 0.9928 - val_loss: 0.0808 - val_accuracy: 0.9781\n",
      "Epoch 95/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9923\n",
      "Epoch 00095: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00095: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0213 - accuracy: 0.9923 - val_loss: 0.0792 - val_accuracy: 0.9789\n",
      "Epoch 96/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9931\n",
      "Epoch 00096: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00096: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 0.0802 - val_accuracy: 0.9785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9943\n",
      "Epoch 00097: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00097: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0802 - val_accuracy: 0.9785\n",
      "Epoch 98/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9940\n",
      "Epoch 00098: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00098: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0808 - val_accuracy: 0.9785\n",
      "Epoch 99/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9931\n",
      "Epoch 00099: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00099: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 0.0781 - val_accuracy: 0.9785\n",
      "Epoch 100/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9931\n",
      "Epoch 00100: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00100: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 0.0802 - val_accuracy: 0.9781\n",
      "Epoch 101/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9939\n",
      "Epoch 00101: val_accuracy did not improve from 0.97923\n",
      "\n",
      "Epoch 00101: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.0798 - val_accuracy: 0.9789\n",
      "Epoch 102/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9942\n",
      "Epoch 00102: val_accuracy improved from 0.97923 to 0.97961, saving model to gr-model_2-0102-0.979607.h5\n",
      "\n",
      "Epoch 00102: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.0796 - val_accuracy: 0.9796\n",
      "Epoch 103/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9932\n",
      "Epoch 00103: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00103: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.0796 - val_accuracy: 0.9785\n",
      "Epoch 104/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9935\n",
      "Epoch 00104: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00104: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.0793 - val_accuracy: 0.9792\n",
      "Epoch 105/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9938\n",
      "Epoch 00105: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00105: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 0.0807 - val_accuracy: 0.9781\n",
      "Epoch 106/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9933\n",
      "Epoch 00106: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00106: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.0798 - val_accuracy: 0.9789\n",
      "Epoch 107/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9930\n",
      "Epoch 00107: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00107: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 0.0814 - val_accuracy: 0.9785\n",
      "Epoch 108/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9935\n",
      "Epoch 00108: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00108: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.0802 - val_accuracy: 0.9789\n",
      "Epoch 109/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9936\n",
      "Epoch 00109: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00109: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.0815 - val_accuracy: 0.9777\n",
      "Epoch 110/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9937\n",
      "Epoch 00110: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00110: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.0815 - val_accuracy: 0.9789\n",
      "Epoch 111/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9931\n",
      "Epoch 00111: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00111: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0185 - accuracy: 0.9931 - val_loss: 0.0815 - val_accuracy: 0.9777\n",
      "Epoch 112/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9935\n",
      "Epoch 00112: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00112: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0182 - accuracy: 0.9935 - val_loss: 0.0818 - val_accuracy: 0.9792\n",
      "Epoch 113/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9936\n",
      "Epoch 00113: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00113: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0175 - accuracy: 0.9936 - val_loss: 0.0801 - val_accuracy: 0.9796\n",
      "Epoch 114/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9944\n",
      "Epoch 00114: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00114: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.0806 - val_accuracy: 0.9785\n",
      "Epoch 115/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9940\n",
      "Epoch 00115: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00115: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0802 - val_accuracy: 0.9781\n",
      "Epoch 116/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9917\n",
      "Epoch 00116: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00116: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0200 - accuracy: 0.9917 - val_loss: 0.0817 - val_accuracy: 0.9777\n",
      "Epoch 117/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9935\n",
      "Epoch 00117: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00117: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.0806 - val_accuracy: 0.9785\n",
      "Epoch 118/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9937\n",
      "Epoch 00118: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00118: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.0820 - val_accuracy: 0.9777\n",
      "Epoch 119/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9938\n",
      "Epoch 00119: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00119: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0822 - val_accuracy: 0.9777\n",
      "Epoch 120/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9938\n",
      "Epoch 00120: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00120: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.0816 - val_accuracy: 0.9773\n",
      "Epoch 121/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9936\n",
      "Epoch 00121: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00121: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.0820 - val_accuracy: 0.9781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9929\n",
      "Epoch 00122: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00122: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0189 - accuracy: 0.9929 - val_loss: 0.0826 - val_accuracy: 0.9777\n",
      "Epoch 123/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9922\n",
      "Epoch 00123: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00123: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0204 - accuracy: 0.9922 - val_loss: 0.0815 - val_accuracy: 0.9773\n",
      "Epoch 124/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9933\n",
      "Epoch 00124: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00124: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.0815 - val_accuracy: 0.9773\n",
      "Epoch 125/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9939\n",
      "Epoch 00125: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00125: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.0811 - val_accuracy: 0.9789\n",
      "Epoch 126/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9935\n",
      "Epoch 00126: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00126: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.0802 - val_accuracy: 0.9785\n",
      "Epoch 127/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9921\n",
      "Epoch 00127: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00127: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0206 - accuracy: 0.9921 - val_loss: 0.0809 - val_accuracy: 0.9770\n",
      "Epoch 128/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9929\n",
      "Epoch 00128: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00128: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0196 - accuracy: 0.9929 - val_loss: 0.0806 - val_accuracy: 0.9785\n",
      "Epoch 129/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9926\n",
      "Epoch 00129: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00129: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0206 - accuracy: 0.9926 - val_loss: 0.0824 - val_accuracy: 0.9781\n",
      "Epoch 130/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9942\n",
      "Epoch 00130: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00130: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.0828 - val_accuracy: 0.9773\n",
      "Epoch 131/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9935\n",
      "Epoch 00131: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00131: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0175 - accuracy: 0.9935 - val_loss: 0.0811 - val_accuracy: 0.9773\n",
      "Epoch 132/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9925\n",
      "Epoch 00132: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00132: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0196 - accuracy: 0.9925 - val_loss: 0.0824 - val_accuracy: 0.9781\n",
      "Epoch 133/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9944\n",
      "Epoch 00133: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00133: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0819 - val_accuracy: 0.9781\n",
      "Epoch 134/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9932\n",
      "Epoch 00134: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00134: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 0.0807 - val_accuracy: 0.9789\n",
      "Epoch 135/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9918\n",
      "Epoch 00135: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00135: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0200 - accuracy: 0.9918 - val_loss: 0.0825 - val_accuracy: 0.9773\n",
      "Epoch 136/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9923\n",
      "Epoch 00136: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00136: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0192 - accuracy: 0.9923 - val_loss: 0.0841 - val_accuracy: 0.9770\n",
      "Epoch 137/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9934\n",
      "Epoch 00137: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00137: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.0811 - val_accuracy: 0.9785\n",
      "Epoch 138/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9946\n",
      "Epoch 00138: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00138: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.0803 - val_accuracy: 0.9789\n",
      "Epoch 139/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9943\n",
      "Epoch 00139: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00139: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.0822 - val_accuracy: 0.9781\n",
      "Epoch 140/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9933\n",
      "Epoch 00140: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00140: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.0826 - val_accuracy: 0.9781\n",
      "Epoch 141/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9929\n",
      "Epoch 00141: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00141: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0197 - accuracy: 0.9929 - val_loss: 0.0828 - val_accuracy: 0.9777\n",
      "Epoch 142/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9950\n",
      "Epoch 00142: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00142: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.0823 - val_accuracy: 0.9781\n",
      "Epoch 143/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9945\n",
      "Epoch 00143: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00143: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0828 - val_accuracy: 0.9785\n",
      "Epoch 144/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9948\n",
      "Epoch 00144: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00144: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.0825 - val_accuracy: 0.9785\n",
      "Epoch 145/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9937\n",
      "Epoch 00145: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00145: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.0846 - val_accuracy: 0.9785\n",
      "Epoch 146/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9946\n",
      "Epoch 00146: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00146: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.0839 - val_accuracy: 0.9781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9939\n",
      "Epoch 00147: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00147: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.0834 - val_accuracy: 0.9781\n",
      "Epoch 148/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9945\n",
      "Epoch 00148: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00148: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0832 - val_accuracy: 0.9789\n",
      "Epoch 149/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9930\n",
      "Epoch 00149: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00149: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0189 - accuracy: 0.9930 - val_loss: 0.0839 - val_accuracy: 0.9777\n",
      "Epoch 150/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 00150: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00150: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.0847 - val_accuracy: 0.9789\n",
      "Epoch 151/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9935\n",
      "Epoch 00151: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00151: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0167 - accuracy: 0.9935 - val_loss: 0.0845 - val_accuracy: 0.9777\n",
      "Epoch 152/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9933\n",
      "Epoch 00152: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00152: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.0845 - val_accuracy: 0.9781\n",
      "Epoch 153/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9934\n",
      "Epoch 00153: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00153: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0174 - accuracy: 0.9934 - val_loss: 0.0832 - val_accuracy: 0.9789\n",
      "Epoch 154/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9934\n",
      "Epoch 00154: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00154: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 0.0830 - val_accuracy: 0.9789\n",
      "Epoch 155/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9936\n",
      "Epoch 00155: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00155: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0174 - accuracy: 0.9936 - val_loss: 0.0833 - val_accuracy: 0.9789\n",
      "Epoch 156/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9925\n",
      "Epoch 00156: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00156: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0192 - accuracy: 0.9925 - val_loss: 0.0825 - val_accuracy: 0.9789\n",
      "Epoch 157/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9954\n",
      "Epoch 00157: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00157: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0827 - val_accuracy: 0.9789\n",
      "Epoch 158/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9939\n",
      "Epoch 00158: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00158: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.0827 - val_accuracy: 0.9789\n",
      "Epoch 159/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 00159: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00159: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.0825 - val_accuracy: 0.9789\n",
      "Epoch 160/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9943\n",
      "Epoch 00160: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00160: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.0829 - val_accuracy: 0.9789\n",
      "Epoch 161/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9934\n",
      "Epoch 00161: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00161: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0178 - accuracy: 0.9934 - val_loss: 0.0827 - val_accuracy: 0.9789\n",
      "Epoch 162/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9937\n",
      "Epoch 00162: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00162: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.0838 - val_accuracy: 0.9785\n",
      "Epoch 163/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9930\n",
      "Epoch 00163: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00163: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.0832 - val_accuracy: 0.9785\n",
      "Epoch 164/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9942\n",
      "Epoch 00164: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00164: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.0830 - val_accuracy: 0.9785\n",
      "Epoch 165/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9938\n",
      "Epoch 00165: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00165: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.0825 - val_accuracy: 0.9789\n",
      "Epoch 166/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9940\n",
      "Epoch 00166: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00166: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0825 - val_accuracy: 0.9789\n",
      "Epoch 167/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9936\n",
      "Epoch 00167: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00167: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.0826 - val_accuracy: 0.9789\n",
      "Epoch 168/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9940\n",
      "Epoch 00168: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00168: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0827 - val_accuracy: 0.9789\n",
      "Epoch 169/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9939\n",
      "Epoch 00169: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00169: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.0829 - val_accuracy: 0.9792\n",
      "Epoch 170/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9946\n",
      "Epoch 00170: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00170: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.0831 - val_accuracy: 0.9792\n",
      "Epoch 171/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9940\n",
      "Epoch 00171: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00171: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 0.0833 - val_accuracy: 0.9785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9936\n",
      "Epoch 00172: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00172: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.0826 - val_accuracy: 0.9785\n",
      "Epoch 173/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9937\n",
      "Epoch 00173: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00173: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 0.0832 - val_accuracy: 0.9785\n",
      "Epoch 174/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9931\n",
      "Epoch 00174: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00174: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 0.0833 - val_accuracy: 0.9785\n",
      "Epoch 175/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9926\n",
      "Epoch 00175: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00175: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0185 - accuracy: 0.9926 - val_loss: 0.0829 - val_accuracy: 0.9789\n",
      "Epoch 176/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9930\n",
      "Epoch 00176: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00176: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0185 - accuracy: 0.9930 - val_loss: 0.0831 - val_accuracy: 0.9789\n",
      "Epoch 177/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9940\n",
      "Epoch 00177: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00177: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0831 - val_accuracy: 0.9785\n",
      "Epoch 178/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9941\n",
      "Epoch 00178: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00178: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.0829 - val_accuracy: 0.9792\n",
      "Epoch 179/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9915\n",
      "Epoch 00179: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00179: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0207 - accuracy: 0.9915 - val_loss: 0.0820 - val_accuracy: 0.9789\n",
      "Epoch 180/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9941\n",
      "Epoch 00180: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00180: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0162 - accuracy: 0.9941 - val_loss: 0.0831 - val_accuracy: 0.9789\n",
      "Epoch 181/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9934\n",
      "Epoch 00181: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00181: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0177 - accuracy: 0.9934 - val_loss: 0.0836 - val_accuracy: 0.9789\n",
      "Epoch 182/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9942\n",
      "Epoch 00182: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00182: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.0831 - val_accuracy: 0.9789\n",
      "Epoch 183/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 00183: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00183: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.0827 - val_accuracy: 0.9789\n",
      "Epoch 184/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9942\n",
      "Epoch 00184: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00184: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.0833 - val_accuracy: 0.9789\n",
      "Epoch 185/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9936\n",
      "Epoch 00185: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00185: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0166 - accuracy: 0.9936 - val_loss: 0.0830 - val_accuracy: 0.9789\n",
      "Epoch 186/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9936\n",
      "Epoch 00186: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00186: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0177 - accuracy: 0.9936 - val_loss: 0.0828 - val_accuracy: 0.9792\n",
      "Epoch 187/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9936\n",
      "Epoch 00187: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00187: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.0833 - val_accuracy: 0.9792\n",
      "Epoch 188/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9954\n",
      "Epoch 00188: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00188: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0835 - val_accuracy: 0.9792\n",
      "Epoch 189/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9940\n",
      "Epoch 00189: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00189: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.0831 - val_accuracy: 0.9792\n",
      "Epoch 190/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9939\n",
      "Epoch 00190: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00190: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.0833 - val_accuracy: 0.9789\n",
      "Epoch 191/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9933\n",
      "Epoch 00191: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00191: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.0842 - val_accuracy: 0.9789\n",
      "Epoch 192/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9921\n",
      "Epoch 00192: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00192: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0206 - accuracy: 0.9921 - val_loss: 0.0847 - val_accuracy: 0.9785\n",
      "Epoch 193/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9936\n",
      "Epoch 00193: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00193: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.0835 - val_accuracy: 0.9792\n",
      "Epoch 194/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9940\n",
      "Epoch 00194: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00194: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0839 - val_accuracy: 0.9792\n",
      "Epoch 195/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9940\n",
      "Epoch 00195: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00195: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.0843 - val_accuracy: 0.9789\n",
      "Epoch 196/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9936\n",
      "Epoch 00196: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00196: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 278ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.0845 - val_accuracy: 0.9789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9934\n",
      "Epoch 00197: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00197: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0190 - accuracy: 0.9934 - val_loss: 0.0839 - val_accuracy: 0.9785\n",
      "Epoch 198/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9944\n",
      "Epoch 00198: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00198: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.0850 - val_accuracy: 0.9785\n",
      "Epoch 199/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9932\n",
      "Epoch 00199: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00199: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.0849 - val_accuracy: 0.9789\n",
      "Epoch 200/200\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9935\n",
      "Epoch 00200: val_accuracy did not improve from 0.97961\n",
      "\n",
      "Epoch 00200: saving model to gr-model_2.h5\n",
      "166/165 [==============================] - 46s 277ms/step - loss: 0.0180 - accuracy: 0.9935 - val_loss: 0.0855 - val_accuracy: 0.9781\n",
      "Test loss: 0.08547690510749817\n",
      "Test accuracy: 0.9780966639518738\n",
      "Test error: 0.02190333604812622\n"
     ]
    }
   ],
   "source": [
    "model_2 = model_resnet_mini\n",
    "model_2 = training_and_evaluation(model=model_2,\n",
    "                                  model_id='model_2',\n",
    "                                  scheduler=scheduler_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CIFAR.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
